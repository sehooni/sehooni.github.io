---
layout: single
title:  "[ML] CNN 정리(Conv2d, MaxPool2d)"
excerpt: "CNN"
toc: true
toc_sticky: true

categories:
  - ML
tags: [ML]
use_math: true

last_modified_at: 2022-04-28T14:35:00-16:04:00
classes: wide
---
봄이 어느덧 지나가고, 중간고사 기간이 빠르게 찾아왔다.
linear regression 이후 CNN에 대해 살펴보자.
본 포스팅에서는 **Pytorch** 를 이용하여 실행하게 된다.

# CNN Implementation

다음 그림과 같은 모양으로 CNN 학습을 진행한다.

##그림 1. CNN Implementation
![cnn implementation](https://user-images.githubusercontent.com/84653623/163127806-018be86d-286a-4fdf-b773-4d85b1b75214.png)

이때의 코드는 다음과 같다.
    import torch
    import torch.nn as nn

    input = torch.Tensor(1, 1, 28, 28)
    conv1 = nn.Conv2d(1, 5, 5)
    pool - nn.MaxPool2d(2)

    out = conv1(input)
    out2 = pool(out)

    out.size()
    out2.size()

이와 관련된 코드는 [example.py](https://github.com/sehooni/ML-Pytorch/blob/master/CNN/CNN%20Implementation/example.py)에서 확인할 수 있다.

그렇다면 위에 명시된 코드 `nn.Conv2d`와 `nn.MaxPool2d`는 무엇이며 어떠한 방식으로 진행이 될까?

# CNN pytorch 관련 내용

## Pytorch nn.Conv2d
    conv = torch.nn.Conv2d(in_channels=, out_channels=, kernel_size=,
                 stride = 1, padding=0, dilation=1, groups=1,bias=True)
이때 `stride, padding, dilation, groups` 는 default value이다.
 
ex) 입력채널 1 / 출력채널 1 / 커널크기 3*3
    conv = nn.Conv2d(1, 1, 3)

input type : torch.Tensor
input shape : (N * C * H * W)
              (batch_size, channel, height, width)

### Output Volume Caculations
    Output size = (input size - filter size + (2 * padding))/stride + 1

다음 예제들을 수기로 풀면 다음과 같다.
#### 예제 1)
    input image size : 227 * 227
    filter size : 11 * 11
    stride = 4
    padding = 0
    output image size = ?
    공식에 따라 계산하면 (227-11+2*0)/4 + 1 = 55
                        55 * 55

#### 예제 2)
    input image size : 64 * 64
    filter size : 7 * 7
    stride = 2
    padding = 0
    output image size = ?
    공식에 따라 계산하면 (64-7+2*0)/2 + 1 = 29.5 = 29
                        29 * 29

#### 예제 3)
    input image size : 32 * 32
    filter size : 5 * 5
    stride = 1
    padding = 2
    output image size = ?
    공식에 따라 계산하면 (32-5+2*2)/1 + 1 = 32
                        32 * 32

#### 예제 4)
    input image size : 32 * 64
    filter size : 5 * 5
    stride = 1
    padding = 0
    output image size = ?
    공식에 따라 계산하면 (32-5+2*0)/1 + 1 = 28, (64-5+2*0)/1 + 1 = 60
                        28 * 60

#### 예제 5)
    input image size : 64 * 32
    filter size : 3 * 3
    stride = 1
    padding = 1
    output image size = ?
    공식에 따라 계산하면 (64-3+2*1)/1 + 1 = 64, (32-3+2*1)/1 + 1 = 32
                        64 * 32

위 예제들을 pytorch를 이용하여 계산할 수 있다.
[Pytorch_nn_Conv2d.py](https://github.com/sehooni/ML-Pytorch/blob/master/CNN/Conv/Pytorch_nn_Conv2d.py)에서 확인 가능하다.

## Pytorch nn.Conv2d
    max_pool = torch.nn.MaxPool2d(kernel_size=,
                 stride = None, padding=0, dilation=1, return_indices = False,ceil_mode=False)
이때 `stride, padding, dilation, return_indices, ceil_mode` 는 default value이다.

---
# 글을 요약하자면..

결국 CNN에서는 기존 Perceptron과 Multi-layer-Perceptron과 달리 Convolution layer와 Pooling layer가 추가되었다는 점에서 차이를 보인다.
이를 통해 계산 시간은 단축이 되었으며, 매개변수를 구하는 과정이 단축됨에 따라 용량도 줄었다는 장점을 가진다.
---

이번 기회를 통해 수업내용도 정리하고 코드 적용도 학습해보았다.
이후 관련 논문과 코드구현 내용도 업로드 예정이니 많은 관심 부탁드리며.. 글을 마무리해본다.
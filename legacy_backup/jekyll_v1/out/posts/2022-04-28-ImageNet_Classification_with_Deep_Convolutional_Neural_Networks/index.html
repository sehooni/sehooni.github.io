<!DOCTYPE html><!--oAIH0_g3w6LOdbw_0qDiA--><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/8fa8e9b5e3e9b2cd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/cbd55ab9639e1e66.js"/><script src="/_next/static/chunks/1abc3924204d7dd0.js" async=""></script><script src="/_next/static/chunks/9c23f44fff36548a.js" async=""></script><script src="/_next/static/chunks/5944084dd90310d5.js" async=""></script><script src="/_next/static/chunks/turbopack-aeaf7046609aeecd.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/_next/static/chunks/a8f82a9835eb887b.js" async=""></script><title>[PaperReview] ImageNet Classification with Deep Convolutional Neural Networks(CNN)</title><meta name="description" content="CNN_Paper 리뷰"/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen"><div hidden=""><!--$--><!--/$--></div><aside class="w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block"><div class="mb-8"><h1 class="text-2xl font-bold font-sans tracking-tight"><a href="/">Sehoon&#x27;s Workspace</a></h1><p class="text-sm text-gray-500 mt-2">Tech &amp; Study Blog</p></div><nav class="space-y-8"><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Menu</h3><ul class="space-y-1"><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/">Recent Posts</a></li><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/about/">About</a></li></ul></div><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Categories</h3><ul class="space-y-1"><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/proteomics/"><span>proteomics</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->9<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/nlp/"><span>NLP</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->6<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/blog/"><span>Blog</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->5<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jetson/"><span>Jetson</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/paperreview/"><span>PaperReview</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/neural_style_transfer/"><span>Neural_Style_Transfer</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->3<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jekyll/"><span>jekyll</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/ml/"><span>ML</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/algorithms/"><span>algorithms</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/contest/"><span>Contest</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/capstone/"><span>Capstone</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/linux/"><span>Linux</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/etc/"><span>ETC</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/datastructure/"><span>DataStructure</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/dl/"><span>DL</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li></ul></div></nav><div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800"><div class="flex space-x-4"></div></div></aside><main class="flex-1 min-w-0"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10"><div class="relative"><article class="prose prose-lg dark:prose-invert max-w-none"><header class="mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8"><div class="mb-4 text-sm text-gray-500 flex items-center space-x-2"><a class="font-medium text-blue-600 hover:underline" href="/category/paperreview/">PaperReview</a><span>•</span><time></time></div><h1 class="text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4">[PaperReview] ImageNet Classification with Deep Convolutional Neural Networks(CNN)</h1></header><div><h1>CNN이란?</h1>
<p>CNN이란, <strong>Convolutional Neural Network</strong>의 준말로 합성곱 신경망이라 불린다.
입력 이미지로부터 특징을 추출하여 입력이미지가 어떤 이미지인지 클래스를 분류하게 되는 것이다.
대게 이미지 및 비디오 인식, 추천 시스템, 이미지 분류, 의료 이미지 분석 및 자연어처리에 이용된다.</p>
<h2>ANN과 CNN</h2>
<p>ANN은 <strong>Artificial Neural Network</strong>의 준말로 사람의 신경망 원리와 구조를 모방하여 만든 기계학습 알고리즘이다. 이와 관련한 내용은 <a href="https://sehooni.github.io/dl/ANN,DNN,CNN,RNN/">[DL] ANN, DNN, CNN, RNN 개념과 차이</a> 에 명시해두었다.</p>
<p>본론으로 돌아와 ANN과 비교하여 CNN을 알아보자면, 일반 신경망, ANN은 이미지 전체를 하나의 데이터로 입력하기 때문에
이미지의 특성을 찾지 못하고 이미지의 위치가 변형되거나 왜곡된 경우에는 올바른 성능을 기대할 수 없게 된다. 즉, <code>데이터의 형상이 무시되는 것이다.</code></p>
<p>이에 반해 합성곱 신경망, CNN은 이미지를 하나의 데이터가 아닌 여러개로 분할하여 처리한다. 이에 따라 이미지가 왜곡되더라도 이미지의 부분적 특성을 추출할 수 있어 올바른 성능을 낼 수 있다.</p>
<h3>그림 1. ANN과 CNN</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165703614-c50e182f-25fa-4c5e-a45c-001cbe4d11c6.png" alt="ANN과 CNN"></p>
<p>이와 관련한 내용은 위의 그림을 통해서 쉽게 확인 가능하다.</p>
<h3>그림 2. CNN의 진행순서</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165703938-4905c417-1e76-4617-b4dd-cbdc3fd33f66.png" alt="CNN의 진행순서"></p>
<p>위의 그림은 CNN의 진행순서를 간략하게 도식화한 것이다. 데이터가 입력되면 <code>Convolution</code>, <code>ReLu function</code>, <code>Pooling</code>과정을 거쳐 특징을 분석하게 된다.
이후 <code>flatten</code>, <code>fully connected</code>, <code>Softmax function</code>을 통해 classification을 진행하게 된다.</p>
<h1>CNN의 구조</h1>
<p>기존 신경망의 구조는 인접하는 계층의 모든 뉴런이 결합된 완전연결로 <code>affine 계층으로 구성</code>된다.
그러나 CNN의 경우, 신경망 구조에서 합성곱 계층과 풀링층이 추가되었다. 또한 풀링층은 때에 따라 생략이 가능하다.</p>
<h2>CNN의 구조</h2>
<h3>그림 3. CNN의 구조 1</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165707470-339d138e-a0df-43d1-832b-38ee36f1f8ab.png" alt="CNN의 구조"></p>
<h3>그림 4. CNN의 구조 2</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165729172-47445bfc-969e-4f30-a876-f273960f5f5e.png" alt="CNN의 구조2"></p>
<p>위의 &#x3C;그림 3>과 &#x3C;그림 4>를 통해 CNN의 구조를 확인할 수 있다.</p>
<h1>Convolution</h1>
<p>본 내용을 설명하기에 앞서 bias는 편향을 의미한다. 합성곱 연산, <strong>Convolution</strong>의 bias는 데이터에 bias가 더해지는 과정이다.
덧셈연산이라고 생각하면 이해하기 쉽다. 완전 연결 신경망에는 가중치(Weight) 매개변수와 bias가 존재하게 된다.
<code>CNN에서는 이와 유사하게 필터와 bias가 학습을 시킬 매개변수이다. </code>
<code>다시 말해, 이미지 처리에서 말하는 필터 연산에 해당하는 것이다.</code></p>
<h2>stride</h2>
<p>stride는 지정된 간격으로 필터를 순회하는 간격을 의미한다. 아래의 &#x3C;그림 6>에서는 stride가 1로 설정된 것이며,
stride가 2로 설정되면 필터는 2칸씩 이동하면서 합성곱을 계산한다.</p>
<h3>그림 5. 합성곱 연산 과정 1</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165711865-7153cc40-3954-45d9-9db4-31715447b868.png" alt="합성곱 연산과정 1"></p>
<p>위의 그림과 같이 bias는 항상 하나의 값(1*1)으로 존재하며 필터를 적용한 후 모든 원소에 더해지게 된다.
즉 CNN을 통해 학습이 거듭되며 필터의 원소값과 bias가 매번 갱신되는 것이다.</p>
<h3>그림 6. 합성곱 연산 과정 2</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165712067-9aa6e8fb-6d79-492a-9664-e866786d09cd.jpg" alt="합성곱 연산과정 2"></p>
<p>2차원의 입력 데이터가 들어오면, 필터의 윈도우가 일정 간격으로 이동해가며 연산이 적용된다.
이때 이 이동과정을 <code>Stride</code>라고 한다.
이 과정을 모든 장소에서 진행하고, 위의 사진 오른쪽과 같은 합성곱 연산의 출력이 완성된다.</p>
<h1>Padding</h1>
<p><strong>Padding</strong>은 기존 데이터 주변에 값들을 채워넣어 크기를 키우는 것이다.
Convolution 과정은 특징을 추출하는 것을 목표로 한다.</p>
<p>그러나, Padding이 없이 진행되면 Convolution 연산 후에는 <em>'의도치 않게'</em> 이미지의 크기가 작아지게 된다.
이는 Edge 성분이 점차 사라지게 되고, 이에 따라 Edge 근처의 특징을 누락할 수 있다.
따라서 Padding을 통해 Convolution 연산을 하게 되더라도, 그 결과 이미지가 입력 이미지와 그 크기를 동일하게 유지하면서 특징을 추출할 수 있다.</p>
<h2>Padding의 종류</h2>
<p>데이터 주변에 어떠한 값을 채우느냐에 따라 padding의 종류가 나뉜다.</p>
<ul>
<li>Zero Padding : 최외각을 모두 pixel 0으로 설정</li>
<li>Same Padding : 최외각을 모두 이미지 외곽의 pixel 값으로 사용</li>
</ul>
<h3>그림 7. Zero Padding 원리</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165729269-37476345-7114-4ddb-a790-735ece84d5f7.jpg" alt="padding"></p>
<p>&#x3C;그림 7>은 zero padding의 원리를 설명한 그림이다.</p>
<h1>Pooling</h1>
<p>CNN의 구조를 살펴보면 <code>Conv → Pooling → Conv → Pooling~~</code>의 순서로 진행된다.</p>
<p>Convolution 연산 후, FC Layer(Fully-Connected Layer)로 바로 연결될 경우, 입력 이미지를 그대로 가져와 연산을 진행하게 된다.
이 때문에 FC Layer에서의 연산량이 기하급수적으로 증가하게 된다. <code>이러한 연산량을 줄이기 위해 Pooling이라는 과정을 추가하여, 연산 후 크기를 '적당히' 줄이고 특정 feature를 강조한다.</code>
그렇다면 특정 feature를 강조한다는 것은 무슨 의미일까?</p>
<p>특정 feature를 강조한다는 것은 <code>Convolution 이미지의 특징을 추출하고, 그 결과 속에서 특정 특징을 강조한다</code>는 의미이다.</p>
<p>Convolution이 행렬(matrix)의 연산이라면, Pooling은 각 Pixel에서 하나의 값을 뽑아내는 것이다.</p>
<h2>Pooling의 종류</h2>
<p>pooling은 두 가지 종류로 구성된다.</p>
<ul>
<li>Max Pooling : 윈도우 창 내에서 각 원소들 중 가장 큰 값을 추출</li>
<li>Average Pooling : 윈도우 창 내에서 각 원소들의 평균 값을 추출</li>
</ul>
<h3>그림 8. Pooling의 원리</h3>
<p><img src="https://user-images.githubusercontent.com/84653623/165735542-9f473be7-2f0a-4c3f-9de8-211121dce50f.png" alt="pooling"></p>
<p>&#x3C;그림 8>을 통해 Pooling의 원리를 살펴볼 수 있다.</p>
<h1>요약하자면...</h1>
<p>CNN(Convolution Neural Network)은 이미지의 공간정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식하고 강조하는 방식으로 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분으로 구성된다.
특징 추출 영역은 필터를 사용하여 공유 파라미터 수를 최소화하면서 이미지의 특징을 찾는 Convolution Layer와 특징을 강화하고 모으는 Pooling Layer로 구성된다.</p>
<p>CNN은 필터의 크기를 비롯하여 Stride, Padding과 Pooling의 크기로 출력 데이터 크기를 조절하고, 필터의 개수로 출력 데이터의 채널을 결정한다.</p>
<p>CNN은 같은 레이어 크기의 FCNN과 비교해 볼 때 학습 파라미터의 양이 현저히 적다. 은닉층이 깊어질 수록 그 차이는 더 커지게 된다.
<code>즉, CNN은 더 작은 학습 파라미터로 더 높은 인식률을 제공</code>하는 것이다.</p>
<p>본 논문에는 특징 추출과 분류로 구성이 되어있으나, 이번 포스팅에서는 특징 추출 부분에 포커스를 맞추어 진행하였다.</p>
<hr>
<p>PS. 추가 문의사항 및 질문은 환영합니다. 그를 통해 저도 더 성장할 수 있을테니까요. 긴 글 읽어주셔서 감사합니다.</p>
<h1>Reference</h1>
<ul>
<li>논문: <a href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">ImageNet Classification with Deep Convolutional Neural Networks</a></li>
<li>'기계학습(Machine Learning)/오일석 저자' 강의 자료</li>
</ul>
</div></article></div><!--$--><!--/$--></div></main><script src="/_next/static/chunks/cbd55ab9639e1e66.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"oAIH0-g3w6LOdbw_0qDiA\",\"c\":[\"\",\"posts\",\"2022-04-28-ImageNet_Classification_with_Deep_Convolutional_Neural_Networks\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"2022-04-28-ImageNet_Classification_with_Deep_Convolutional_Neural_Networks\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen\",\"children\":[\"$L2\",[\"$\",\"main\",null,{\"className\":\"flex-1 min-w-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/a8f82a9835eb887b.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"2:[\"$\",\"aside\",null,{\"className\":\"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-2xl font-bold font-sans tracking-tight\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"Sehoon's Workspace\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-500 mt-2\",\"children\":\"Tech \u0026 Study Blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"space-y-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Menu\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"Recent Posts\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/about\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"About\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Categories\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",\"proteomics\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/proteomics\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"proteomics\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",9,\")\"]}]]}]}],[\"$\",\"li\",\"NLP\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",6,\")\"]}]]}]}],[\"$\",\"li\",\"Blog\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/blog\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Blog\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",5,\")\"]}]]}]}],[\"$\",\"li\",\"Jetson\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jetson\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Jetson\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"PaperReview\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/paperreview\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"PaperReview\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"Neural_Style_Transfer\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/neural_style_transfer\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Neural_Style_Transfer\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",3,\")\"]}]]}]}],[\"$\",\"li\",\"jekyll\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jekyll\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"jekyll\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]]}]}],[\"$\",\"li\",\"ML\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/ml\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[\"$Lf\",\"$L10\"]}]}],\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\"]}]]}]]}],\"$L18\"]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"span\",null,{\"children\":\"ML\"}]\n10:[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]\n11:[\"$\",\"li\",\"algorithms\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/algorithms\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"algorithms\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n12:[\"$\",\"li\",\"Contest\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/contest\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Contest\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n13:[\"$\",\"li\",\"Capstone\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/capstone\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Capstone\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n14:[\"$\",\"li\",\"Linux\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/linux\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Linux\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n15:[\"$\",\"li\",\"ETC\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/etc\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"ETC\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n16:[\"$\",\"li\",\"DataStructure\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/datastructure\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DataStructure\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n17:[\"$\",\"li\",\"DL\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/dl\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DL\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n18:[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex space-x-4\"}]}]\n"])</script><script>self.__next_f.push([1,"19:T2350,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eCNN이란?\u003c/h1\u003e\n\u003cp\u003eCNN이란, \u003cstrong\u003eConvolutional Neural Network\u003c/strong\u003e의 준말로 합성곱 신경망이라 불린다.\n입력 이미지로부터 특징을 추출하여 입력이미지가 어떤 이미지인지 클래스를 분류하게 되는 것이다.\n대게 이미지 및 비디오 인식, 추천 시스템, 이미지 분류, 의료 이미지 분석 및 자연어처리에 이용된다.\u003c/p\u003e\n\u003ch2\u003eANN과 CNN\u003c/h2\u003e\n\u003cp\u003eANN은 \u003cstrong\u003eArtificial Neural Network\u003c/strong\u003e의 준말로 사람의 신경망 원리와 구조를 모방하여 만든 기계학습 알고리즘이다. 이와 관련한 내용은 \u003ca href=\"https://sehooni.github.io/dl/ANN,DNN,CNN,RNN/\"\u003e[DL] ANN, DNN, CNN, RNN 개념과 차이\u003c/a\u003e 에 명시해두었다.\u003c/p\u003e\n\u003cp\u003e본론으로 돌아와 ANN과 비교하여 CNN을 알아보자면, 일반 신경망, ANN은 이미지 전체를 하나의 데이터로 입력하기 때문에\n이미지의 특성을 찾지 못하고 이미지의 위치가 변형되거나 왜곡된 경우에는 올바른 성능을 기대할 수 없게 된다. 즉, \u003ccode\u003e데이터의 형상이 무시되는 것이다.\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e이에 반해 합성곱 신경망, CNN은 이미지를 하나의 데이터가 아닌 여러개로 분할하여 처리한다. 이에 따라 이미지가 왜곡되더라도 이미지의 부분적 특성을 추출할 수 있어 올바른 성능을 낼 수 있다.\u003c/p\u003e\n\u003ch3\u003e그림 1. ANN과 CNN\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165703614-c50e182f-25fa-4c5e-a45c-001cbe4d11c6.png\" alt=\"ANN과 CNN\"\u003e\u003c/p\u003e\n\u003cp\u003e이와 관련한 내용은 위의 그림을 통해서 쉽게 확인 가능하다.\u003c/p\u003e\n\u003ch3\u003e그림 2. CNN의 진행순서\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165703938-4905c417-1e76-4617-b4dd-cbdc3fd33f66.png\" alt=\"CNN의 진행순서\"\u003e\u003c/p\u003e\n\u003cp\u003e위의 그림은 CNN의 진행순서를 간략하게 도식화한 것이다. 데이터가 입력되면 \u003ccode\u003eConvolution\u003c/code\u003e, \u003ccode\u003eReLu function\u003c/code\u003e, \u003ccode\u003ePooling\u003c/code\u003e과정을 거쳐 특징을 분석하게 된다.\n이후 \u003ccode\u003eflatten\u003c/code\u003e, \u003ccode\u003efully connected\u003c/code\u003e, \u003ccode\u003eSoftmax function\u003c/code\u003e을 통해 classification을 진행하게 된다.\u003c/p\u003e\n\u003ch1\u003eCNN의 구조\u003c/h1\u003e\n\u003cp\u003e기존 신경망의 구조는 인접하는 계층의 모든 뉴런이 결합된 완전연결로 \u003ccode\u003eaffine 계층으로 구성\u003c/code\u003e된다.\n그러나 CNN의 경우, 신경망 구조에서 합성곱 계층과 풀링층이 추가되었다. 또한 풀링층은 때에 따라 생략이 가능하다.\u003c/p\u003e\n\u003ch2\u003eCNN의 구조\u003c/h2\u003e\n\u003ch3\u003e그림 3. CNN의 구조 1\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165707470-339d138e-a0df-43d1-832b-38ee36f1f8ab.png\" alt=\"CNN의 구조\"\u003e\u003c/p\u003e\n\u003ch3\u003e그림 4. CNN의 구조 2\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165729172-47445bfc-969e-4f30-a876-f273960f5f5e.png\" alt=\"CNN의 구조2\"\u003e\u003c/p\u003e\n\u003cp\u003e위의 \u0026#x3C;그림 3\u003e과 \u0026#x3C;그림 4\u003e를 통해 CNN의 구조를 확인할 수 있다.\u003c/p\u003e\n\u003ch1\u003eConvolution\u003c/h1\u003e\n\u003cp\u003e본 내용을 설명하기에 앞서 bias는 편향을 의미한다. 합성곱 연산, \u003cstrong\u003eConvolution\u003c/strong\u003e의 bias는 데이터에 bias가 더해지는 과정이다.\n덧셈연산이라고 생각하면 이해하기 쉽다. 완전 연결 신경망에는 가중치(Weight) 매개변수와 bias가 존재하게 된다.\n\u003ccode\u003eCNN에서는 이와 유사하게 필터와 bias가 학습을 시킬 매개변수이다. \u003c/code\u003e\n\u003ccode\u003e다시 말해, 이미지 처리에서 말하는 필터 연산에 해당하는 것이다.\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003estride\u003c/h2\u003e\n\u003cp\u003estride는 지정된 간격으로 필터를 순회하는 간격을 의미한다. 아래의 \u0026#x3C;그림 6\u003e에서는 stride가 1로 설정된 것이며,\nstride가 2로 설정되면 필터는 2칸씩 이동하면서 합성곱을 계산한다.\u003c/p\u003e\n\u003ch3\u003e그림 5. 합성곱 연산 과정 1\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165711865-7153cc40-3954-45d9-9db4-31715447b868.png\" alt=\"합성곱 연산과정 1\"\u003e\u003c/p\u003e\n\u003cp\u003e위의 그림과 같이 bias는 항상 하나의 값(1*1)으로 존재하며 필터를 적용한 후 모든 원소에 더해지게 된다.\n즉 CNN을 통해 학습이 거듭되며 필터의 원소값과 bias가 매번 갱신되는 것이다.\u003c/p\u003e\n\u003ch3\u003e그림 6. 합성곱 연산 과정 2\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165712067-9aa6e8fb-6d79-492a-9664-e866786d09cd.jpg\" alt=\"합성곱 연산과정 2\"\u003e\u003c/p\u003e\n\u003cp\u003e2차원의 입력 데이터가 들어오면, 필터의 윈도우가 일정 간격으로 이동해가며 연산이 적용된다.\n이때 이 이동과정을 \u003ccode\u003eStride\u003c/code\u003e라고 한다.\n이 과정을 모든 장소에서 진행하고, 위의 사진 오른쪽과 같은 합성곱 연산의 출력이 완성된다.\u003c/p\u003e\n\u003ch1\u003ePadding\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003ePadding\u003c/strong\u003e은 기존 데이터 주변에 값들을 채워넣어 크기를 키우는 것이다.\nConvolution 과정은 특징을 추출하는 것을 목표로 한다.\u003c/p\u003e\n\u003cp\u003e그러나, Padding이 없이 진행되면 Convolution 연산 후에는 \u003cem\u003e'의도치 않게'\u003c/em\u003e 이미지의 크기가 작아지게 된다.\n이는 Edge 성분이 점차 사라지게 되고, 이에 따라 Edge 근처의 특징을 누락할 수 있다.\n따라서 Padding을 통해 Convolution 연산을 하게 되더라도, 그 결과 이미지가 입력 이미지와 그 크기를 동일하게 유지하면서 특징을 추출할 수 있다.\u003c/p\u003e\n\u003ch2\u003ePadding의 종류\u003c/h2\u003e\n\u003cp\u003e데이터 주변에 어떠한 값을 채우느냐에 따라 padding의 종류가 나뉜다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eZero Padding : 최외각을 모두 pixel 0으로 설정\u003c/li\u003e\n\u003cli\u003eSame Padding : 최외각을 모두 이미지 외곽의 pixel 값으로 사용\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e그림 7. Zero Padding 원리\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165729269-37476345-7114-4ddb-a790-735ece84d5f7.jpg\" alt=\"padding\"\u003e\u003c/p\u003e\n\u003cp\u003e\u0026#x3C;그림 7\u003e은 zero padding의 원리를 설명한 그림이다.\u003c/p\u003e\n\u003ch1\u003ePooling\u003c/h1\u003e\n\u003cp\u003eCNN의 구조를 살펴보면 \u003ccode\u003eConv → Pooling → Conv → Pooling~~\u003c/code\u003e의 순서로 진행된다.\u003c/p\u003e\n\u003cp\u003eConvolution 연산 후, FC Layer(Fully-Connected Layer)로 바로 연결될 경우, 입력 이미지를 그대로 가져와 연산을 진행하게 된다.\n이 때문에 FC Layer에서의 연산량이 기하급수적으로 증가하게 된다. \u003ccode\u003e이러한 연산량을 줄이기 위해 Pooling이라는 과정을 추가하여, 연산 후 크기를 '적당히' 줄이고 특정 feature를 강조한다.\u003c/code\u003e\n그렇다면 특정 feature를 강조한다는 것은 무슨 의미일까?\u003c/p\u003e\n\u003cp\u003e특정 feature를 강조한다는 것은 \u003ccode\u003eConvolution 이미지의 특징을 추출하고, 그 결과 속에서 특정 특징을 강조한다\u003c/code\u003e는 의미이다.\u003c/p\u003e\n\u003cp\u003eConvolution이 행렬(matrix)의 연산이라면, Pooling은 각 Pixel에서 하나의 값을 뽑아내는 것이다.\u003c/p\u003e\n\u003ch2\u003ePooling의 종류\u003c/h2\u003e\n\u003cp\u003epooling은 두 가지 종류로 구성된다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMax Pooling : 윈도우 창 내에서 각 원소들 중 가장 큰 값을 추출\u003c/li\u003e\n\u003cli\u003eAverage Pooling : 윈도우 창 내에서 각 원소들의 평균 값을 추출\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e그림 8. Pooling의 원리\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/165735542-9f473be7-2f0a-4c3f-9de8-211121dce50f.png\" alt=\"pooling\"\u003e\u003c/p\u003e\n\u003cp\u003e\u0026#x3C;그림 8\u003e을 통해 Pooling의 원리를 살펴볼 수 있다.\u003c/p\u003e\n\u003ch1\u003e요약하자면...\u003c/h1\u003e\n\u003cp\u003eCNN(Convolution Neural Network)은 이미지의 공간정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식하고 강조하는 방식으로 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분으로 구성된다.\n특징 추출 영역은 필터를 사용하여 공유 파라미터 수를 최소화하면서 이미지의 특징을 찾는 Convolution Layer와 특징을 강화하고 모으는 Pooling Layer로 구성된다.\u003c/p\u003e\n\u003cp\u003eCNN은 필터의 크기를 비롯하여 Stride, Padding과 Pooling의 크기로 출력 데이터 크기를 조절하고, 필터의 개수로 출력 데이터의 채널을 결정한다.\u003c/p\u003e\n\u003cp\u003eCNN은 같은 레이어 크기의 FCNN과 비교해 볼 때 학습 파라미터의 양이 현저히 적다. 은닉층이 깊어질 수록 그 차이는 더 커지게 된다.\n\u003ccode\u003e즉, CNN은 더 작은 학습 파라미터로 더 높은 인식률을 제공\u003c/code\u003e하는 것이다.\u003c/p\u003e\n\u003cp\u003e본 논문에는 특징 추출과 분류로 구성이 되어있으나, 이번 포스팅에서는 특징 추출 부분에 포커스를 맞추어 진행하였다.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003ePS. 추가 문의사항 및 질문은 환영합니다. 그를 통해 저도 더 성장할 수 있을테니까요. 긴 글 읽어주셔서 감사합니다.\u003c/p\u003e\n\u003ch1\u003eReference\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e논문: \u003ca href=\"https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\"\u003eImageNet Classification with Deep Convolutional Neural Networks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e'기계학습(Machine Learning)/오일석 저자' 강의 자료\u003c/li\u003e\n\u003c/ul\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"relative\",\"children\":[[\"$\",\"article\",null,{\"className\":\"prose prose-lg dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 text-sm text-gray-500 flex items-center space-x-2\",\"children\":[[[\"$\",\"$Le\",null,{\"href\":\"/category/paperreview\",\"className\":\"font-medium text-blue-600 hover:underline\",\"children\":\"PaperReview\"}],[\"$\",\"span\",null,{\"children\":\"•\"}]],[\"$\",\"time\",null,{\"children\":\"$undefined\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4\",\"children\":\"[PaperReview] ImageNet Classification with Deep Convolutional Neural Networks(CNN)\"}]]}],[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}]]}],\"$L1a\"]}]\n"])</script><script>self.__next_f.push([1,"1b:I[50718,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"default\"]\n1a:[\"$\",\"$L1b\",null,{}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1c:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"[PaperReview] ImageNet Classification with Deep Convolutional Neural Networks(CNN)\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"CNN_Paper 리뷰\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1c\",\"3\",{}]]\n8:null\n"])</script></body></html>
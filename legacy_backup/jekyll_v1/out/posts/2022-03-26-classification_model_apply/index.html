<!DOCTYPE html><!--oAIH0_g3w6LOdbw_0qDiA--><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/8fa8e9b5e3e9b2cd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/cbd55ab9639e1e66.js"/><script src="/_next/static/chunks/1abc3924204d7dd0.js" async=""></script><script src="/_next/static/chunks/9c23f44fff36548a.js" async=""></script><script src="/_next/static/chunks/5944084dd90310d5.js" async=""></script><script src="/_next/static/chunks/turbopack-aeaf7046609aeecd.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/_next/static/chunks/a8f82a9835eb887b.js" async=""></script><title>[NLP] 문서 분류 모델 실전 투입</title><meta name="description" content="학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다."/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen"><div hidden=""><!--$--><!--/$--></div><aside class="w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block"><div class="mb-8"><h1 class="text-2xl font-bold font-sans tracking-tight"><a href="/">Sehoon&#x27;s Workspace</a></h1><p class="text-sm text-gray-500 mt-2">Tech &amp; Study Blog</p></div><nav class="space-y-8"><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Menu</h3><ul class="space-y-1"><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/">Recent Posts</a></li><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/about/">About</a></li></ul></div><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Categories</h3><ul class="space-y-1"><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/proteomics/"><span>proteomics</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->9<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/nlp/"><span>NLP</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->6<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/blog/"><span>Blog</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->5<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jetson/"><span>Jetson</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/paperreview/"><span>PaperReview</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/neural_style_transfer/"><span>Neural_Style_Transfer</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->3<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jekyll/"><span>jekyll</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/ml/"><span>ML</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/algorithms/"><span>algorithms</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/contest/"><span>Contest</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/capstone/"><span>Capstone</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/linux/"><span>Linux</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/etc/"><span>ETC</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/datastructure/"><span>DataStructure</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/dl/"><span>DL</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li></ul></div></nav><div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800"><div class="flex space-x-4"></div></div></aside><main class="flex-1 min-w-0"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10"><div class="relative"><article class="prose prose-lg dark:prose-invert max-w-none"><header class="mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8"><div class="mb-4 text-sm text-gray-500 flex items-center space-x-2"><a class="font-medium text-blue-600 hover:underline" href="/category/nlp/">NLP</a><span>•</span><time>2022-03-26</time></div><h1 class="text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4">[NLP] 문서 분류 모델 실전 투입</h1></header><div><p>자, 그럼 학습을 마친 모델을 어떻게 사용할까?</p>
<p>본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)</p>
<h1>학습 마친 모델을 실전 투입하기</h1>
<p>이번 실습에서는 <strong>학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다</strong>.</p>
<p>문장을 받아 해당 문장이 긍정인지 부정인지 답변하는 웹 서비스로, 문장을 토큰화한 뒤 모델 입력값으로 만들고 이를 모델에 입력해 [<em>해당 문장이 긍정일 확률, 해당 문장이 부정일 확률</em> ]을 계산하게 만든다. 이후 약간의 후처리 과정을 거쳐 응답하게 만드는 방식이다.</p>
<p>웹 서비스란 네트워크에서 컴퓨터 간에 상호작용을 하기 위해 만들어진 소프트웨어 시스템이다. 본 노트에서는 원격 사용자가 보낸 문장을 수신해 해당 문장이 긍정인지 부정인지 응답을 만들고 이 응답을 원격 사용자에게 전달하는 웹 서비스를 만드는 것이다.</p>
<h2>1. 환경 설정하기</h2>
<h3>의존성 패키지 설치</h3>
<p>pip 명령어를 통해 의존성 있는 패키지를 설치한다.</p>
<h4>code 2-0</h4>
<pre><code class="language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2022.2.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.3.0)
Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)
Requirement already satisfied: PyYAML&#x3C;=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (5.4.1)
Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.7.2)
Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.62.3)
Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.18.2)
Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.5)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2.23.0)
Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.4.0)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.0.47)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.6.0)
Requirement already satisfied: tokenizers&#x3C;0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.10.3)
Requirement already satisfied: click&#x3C;8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)
Requirement already satisfied: itsdangerous&#x3C;2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)
Requirement already satisfied: Jinja2&#x3C;3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&#x3C;2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0->ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&#x3C;3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)
Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.7)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2021.10.8)
Requirement already satisfied: chardet&#x3C;4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (3.0.4)
Requirement already satisfied: idna&#x3C;3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&#x3C;1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)
Requirement already satisfied: google-auth-oauthlib&#x3C;0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)
Requirement already satisfied: google-auth&#x3C;3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)
Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.43.0)
Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)
Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.6)
Requirement already satisfied: tensorboard-data-server&#x3C;0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)
Requirement already satisfied: cachetools&#x3C;5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)
Requirement already satisfied: rsa&#x3C;5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&#x3C;0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.2.0)
Requirement already satisfied: yarl&#x3C;2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.7.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (0.13.0)
Requirement already satisfied: multidict&#x3C;7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (6.0.2)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.0)
Requirement already satisfied: charset-normalizer&#x3C;3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)
Requirement already satisfied: async-timeout&#x3C;5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (4.0.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)
</code></pre>
<h3>구글 드라이브 연동</h3>
<p>모델 체크포인트는 구글 드라이브에 저장해 두었다. 코랩 노트북과 자신의 구글 드라이브를 연동한다.</p>
<h4>code 2-1</h4>
<pre><code class="language-python">from google.colab import drive
drive.mount('/gdrive', force_remount=True)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3>인퍼런스 설정</h3>
<p>각종 인자( 모델 하이퍼파라미터(hyperparameter)와 저장 위치 등 )를 설정한다.</p>
<h4>code 2-2</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.classification import ClassificationDeployArguments
args = ClassificationDeployArguments(
    pretrained_model_name="beomi/kcbert-base",
    downstream_model_dir="/gdrive/My Drive/nlpbook/checkpoint-doccls",
    max_seq_length=128,
)
</code></pre>
<pre><code>downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.28.ckpt
</code></pre>
<p>각 인자의 역할과 내용은 다음과 같다.</p>
<ul>
<li><strong>pretrained_model_name</strong>: <code>training_section.ipynb</code>에서 적용한 <code>pretrained_model_name</code>(단, 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 한다.)</li>
<li><strong>downstream_model_dir</strong>:  <code>training_section.ipynb</code>에서 파인튜닝한 모델의 체크포인트 저장 위치(확장자가 <code>ckpt</code>인 파일이 하나 이상 있어야 한다.)</li>
<li><strong>max_seq_length</strong>: 토큰 기준 입력 문장 최대 길이. 아무것도 입력하지 않으면 128.</li>
</ul>
<h2>2. 토크나이저 및 모델 불러오기</h2>
<h3>토크나이저 로드</h3>
<p>code 2-3을 실행해 토크나이저를 초기화 한다.</p>
<h4>code 2-3</h4>
<pre><code class="language-python">from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=False,
)
</code></pre>
<pre><code>Downloading:   0%|          | 0.00/250k [00:00&#x3C;?, ?B/s]



Downloading:   0%|          | 0.00/49.0 [00:00&#x3C;?, ?B/s]



Downloading:   0%|          | 0.00/619 [00:00&#x3C;?, ?B/s]
</code></pre>
<h3>체크포인트 로드</h3>
<p>code 2-4는 <code>training_section.ipynb</code>에서 파인튜닝한 모델의 체크포인트를 읽어들인다.</p>
<h4>code 2-4</h4>
<pre><code class="language-python">import torch
fine_tuned_model_ckpt = torch.load(
    args.downstream_model_checkpoint_fpath,
    map_location=torch.device("cpu"),
)
</code></pre>
<h3>BERT 설정 로드 및 BERT 모델 초기화</h3>
<p>code 2-5는 <code>training_section.ipynb</code>의 파인튜닝 때 사용한 <code>pretrained_model_name</code>에 해당하는 모델의 설정값들을 읽어들인다.</p>
<p>이어서 code 2-6을 실행하면 해당 설정값대로 <strong>BERT</strong> 모델을 초기화 한다.</p>
<h4>code 2-5</h4>
<pre><code class="language-python">from transformers import BertConfig
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=fine_tuned_model_ckpt["state_dict"]["model.classifier.bias"].shape.numel(),
)
</code></pre>
<h4>code 2-6</h4>
<pre><code class="language-python">from transformers import BertForSequenceClassification
model = BertForSequenceClassification(pretrained_model_config)
</code></pre>
<h3>체크포인트 주입하기</h3>
<p>code 2-7은 초기화한 <strong>BERT</strong>모델에 체크포인트(fine_tuned_model_ckpt)를 주입한다.</p>
<h4>code 2-7</h4>
<pre><code class="language-python">model.load_state_dict({k.replace("model.",""): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})
</code></pre>
<pre><code>&#x3C;All keys matched successfully>
</code></pre>
<h3>평가모드로 전환</h3>
<p>이어서 code 2-8을 실행하면 모델이 평가모드로 전환되게 된다. <strong>드롭아웃 등 학습 때만 사용하는 기법들을 무효화하는 역할</strong>을 한다.</p>
<h4>code 2-8</h4>
<pre><code class="language-python">model.eval()
</code></pre>
<pre><code>BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30000, 768, padding_idx=0)
      (position_embeddings): Embedding(300, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
)
</code></pre>
<h2>3. 모델 출력값 만들고 후처리 하기</h2>
<p>code 2-9는 <strong>인퍼런스 과정을 정의한 함수</strong>이다. 문장에 토큰화를 수행한 뒤 <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>를 만든다. 이들 입력값을 파이토치의 텐서 자료형으로 변환한 뒤 모델에 입력한다. 모델 출력값(<code>outputs.logits</code>)은 소프트맥스 함수 적용 이전의 <strong>로짓</strong>(logit)형태인데, 여기에 소프트맥스 함수를 써서 모델 출력을 '[<strong>부정일 확률, 긍정일 확률</strong>]'로 바꾼다.</p>
<p>마지막으로 모델 출력을 약간 후처리 하여 예측 확률의 최댓값이 부정 위치일 때 해당 문장이 '<strong>부정</strong>(negative)', 반대일 때는 '<strong>긍정</strong>(positive)'이 되도록 <code>pred</code>값을 만든다.</p>
<h4>code 2-9</h4>
<pre><code class="language-python">def inference_fn(sentence):
  # 문장을 토큰화한 뒤 input_id, attention_masks, token_type_ids 만들기
  inputs = tokenizer(
      [sentence],
      max_lenght=args.max_seq_length,
      padding="max_length",
      truncation=True,
  )
  with torch.no_grad():
    # 모델 계산하기
    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}안 = inputs를 파이토치 텐서로 바꾸기
    
    # 로짓에 소프트 맥스 취하기
    prob = outputs.logits.softmax(dim=1)

    # 긍정/부정 확률을 소수점 4자리로 반올림
    positive_prob = round(prob[0][1].item(), 4)
    negative_prob = round(prob[0][0].item(), 4)

    # 예측 확률의 최댓값 위치에 따라 pred 만들기
    pred = "긍정 (positive)" if torch.argmax(prob) == 1 else "부정 (negative)"
  return {
      'sentence' : sentence,
      'prediction': pred,
      'positive_data': f"긍정 {positive_prob}",
      'negative_data': f"부정 {negative_prob}",
      'positive_width': f"{positive_prob * 100}%",
      'negative_width': f"{negative_prob * 100}%",
  }
</code></pre>
<p>code 2-9에서 <code>positive_width</code>, <code>negative_width</code>는 웹 페이지에서 긍정/부정 막대의 길이를 조정하려는 것이므로 크게 신경쓰지 않아도 된다.</p>
<h2>4. 웹 서비스 시작하기</h2>
<h3>웹 서비스 만들기 준비</h3>
<p><code>ngrok</code>은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. <code>ngrok</code>을 실행하려면 <a href="https://dashboard.ngrok.com/get-started/setup">회원가입</a> 후 <a href="https://dashboard.ngrok.com/get-started/setup">로그인</a>을 한 뒤 <a href="https://dashboard.ngrok.com/get-started/your-authtoken">이곳</a>에 접속해 인증토큰(authtoken)을 확인해야 한다.</p>
<p>예를 들어 확인된 <code>authtoken</code>이 <code>test123</code>이라면 다음과 같이 실행 된다.</p>
<p>** !mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: test123" > /root/.ngrok2/ngrok.yml**</p>
<h4>code 2-10</h4>
<pre><code class="language-python">!mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: (여기 채우세요))" > /root/.ngrok2/ngrok.yml
</code></pre>
<h3>웹 서비스 시작하기</h3>
<p>code 2-9에서 정의한 인퍼런스 함수 <code>inference_fn</code>을 가지고 code 2-11을 실행하면 <strong>플라스크</strong>(flask)라는 파이썬 라이브러리의 도움을 받아 웹 서비스를 띄울 수 있다.</p>
<h4>code 2-11</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.classification import get_web_service_app
app = get_web_service_app(inference_fn)
app.run()
</code></pre>
<h2>웹 사이트의 형태는 다음과 같다.</h2>
<p><img src="https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png" alt="model_inference"></p>
</div></article></div><!--$--><!--/$--></div></main><script src="/_next/static/chunks/cbd55ab9639e1e66.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"oAIH0-g3w6LOdbw_0qDiA\",\"c\":[\"\",\"posts\",\"2022-03-26-classification_model_apply\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"2022-03-26-classification_model_apply\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen\",\"children\":[\"$L2\",[\"$\",\"main\",null,{\"className\":\"flex-1 min-w-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/a8f82a9835eb887b.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"2:[\"$\",\"aside\",null,{\"className\":\"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-2xl font-bold font-sans tracking-tight\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"Sehoon's Workspace\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-500 mt-2\",\"children\":\"Tech \u0026 Study Blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"space-y-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Menu\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"Recent Posts\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/about\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"About\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Categories\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",\"proteomics\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/proteomics\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"proteomics\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",9,\")\"]}]]}]}],[\"$\",\"li\",\"NLP\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",6,\")\"]}]]}]}],[\"$\",\"li\",\"Blog\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/blog\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Blog\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",5,\")\"]}]]}]}],[\"$\",\"li\",\"Jetson\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jetson\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Jetson\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"PaperReview\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/paperreview\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"PaperReview\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"Neural_Style_Transfer\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/neural_style_transfer\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Neural_Style_Transfer\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",3,\")\"]}]]}]}],[\"$\",\"li\",\"jekyll\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jekyll\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"jekyll\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]]}]}],[\"$\",\"li\",\"ML\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/ml\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[\"$Lf\",\"$L10\"]}]}],\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\"]}]]}]]}],\"$L18\"]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"span\",null,{\"children\":\"ML\"}]\n10:[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]\n11:[\"$\",\"li\",\"algorithms\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/algorithms\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"algorithms\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n12:[\"$\",\"li\",\"Contest\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/contest\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Contest\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n13:[\"$\",\"li\",\"Capstone\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/capstone\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Capstone\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n14:[\"$\",\"li\",\"Linux\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/linux\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Linux\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n15:[\"$\",\"li\",\"ETC\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/etc\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"ETC\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n16:[\"$\",\"li\",\"DataStructure\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/datastructure\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DataStructure\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n17:[\"$\",\"li\",\"DL\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/dl\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DL\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n18:[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex space-x-4\"}]}]\n"])</script><script>self.__next_f.push([1,"19:T7fd3,"])</script><script>self.__next_f.push([1,"\u003cp\u003e자, 그럼 학습을 마친 모델을 어떻게 사용할까?\u003c/p\u003e\n\u003cp\u003e본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)\u003c/p\u003e\n\u003ch1\u003e학습 마친 모델을 실전 투입하기\u003c/h1\u003e\n\u003cp\u003e이번 실습에서는 \u003cstrong\u003e학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e문장을 받아 해당 문장이 긍정인지 부정인지 답변하는 웹 서비스로, 문장을 토큰화한 뒤 모델 입력값으로 만들고 이를 모델에 입력해 [\u003cem\u003e해당 문장이 긍정일 확률, 해당 문장이 부정일 확률\u003c/em\u003e ]을 계산하게 만든다. 이후 약간의 후처리 과정을 거쳐 응답하게 만드는 방식이다.\u003c/p\u003e\n\u003cp\u003e웹 서비스란 네트워크에서 컴퓨터 간에 상호작용을 하기 위해 만들어진 소프트웨어 시스템이다. 본 노트에서는 원격 사용자가 보낸 문장을 수신해 해당 문장이 긍정인지 부정인지 응답을 만들고 이 응답을 원격 사용자에게 전달하는 웹 서비스를 만드는 것이다.\u003c/p\u003e\n\u003ch2\u003e1. 환경 설정하기\u003c/h2\u003e\n\u003ch3\u003e의존성 패키지 설치\u003c/h3\u003e\n\u003cp\u003epip 명령어를 통해 의존성 있는 패키지를 설치한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-0\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!pip install ratsnlp\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eRequirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\nRequirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\nRequirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\nRequirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\nRequirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\nRequirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\nRequirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\nRequirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\nRequirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\nRequirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\nRequirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\nRequirement already satisfied: PyYAML\u0026#x3C;=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\nRequirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\nRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.62.3)\nRequirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\nRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\nRequirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\nRequirement already satisfied: tokenizers\u0026#x3C;0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\nRequirement already satisfied: click\u0026#x3C;8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\nRequirement already satisfied: itsdangerous\u0026#x3C;2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\nRequirement already satisfied: Jinja2\u0026#x3C;3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\nRequirement already satisfied: Werkzeug\u0026#x3C;2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\nRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\nRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\nRequirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u0026#x3C;3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\nRequirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\nRequirement already satisfied: chardet\u0026#x3C;4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\nRequirement already satisfied: idna\u0026#x3C;3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u0026#x3C;1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\nRequirement already satisfied: google-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\nRequirement already satisfied: google-auth\u0026#x3C;3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\nRequirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.43.0)\nRequirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\nRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\nRequirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\nRequirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\nRequirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\nRequirement already satisfied: tensorboard-data-server\u0026#x3C;0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\nRequirement already satisfied: cachetools\u0026#x3C;5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\nRequirement already satisfied: rsa\u0026#x3C;5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\nRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\nRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\nRequirement already satisfied: pyasn1\u0026#x3C;0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\nRequirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\nRequirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\nRequirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\nRequirement already satisfied: yarl\u0026#x3C;2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\nRequirement already satisfied: multidict\u0026#x3C;7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\nRequirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\nRequirement already satisfied: charset-normalizer\u0026#x3C;3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\nRequirement already satisfied: async-timeout\u0026#x3C;5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e구글 드라이브 연동\u003c/h3\u003e\n\u003cp\u003e모델 체크포인트는 구글 드라이브에 저장해 두었다. 코랩 노트북과 자신의 구글 드라이브를 연동한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-1\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom google.colab import drive\ndrive.mount('/gdrive', force_remount=True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eMounted at /gdrive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e인퍼런스 설정\u003c/h3\u003e\n\u003cp\u003e각종 인자( 모델 하이퍼파라미터(hyperparameter)와 저장 위치 등 )를 설정한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-2\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom ratsnlp.nlpbook.classification import ClassificationDeployArguments\nargs = ClassificationDeployArguments(\n    pretrained_model_name=\"beomi/kcbert-base\",\n    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",\n    max_seq_length=128,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003edownstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.28.ckpt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e각 인자의 역할과 내용은 다음과 같다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003epretrained_model_name\u003c/strong\u003e: \u003ccode\u003etraining_section.ipynb\u003c/code\u003e에서 적용한 \u003ccode\u003epretrained_model_name\u003c/code\u003e(단, 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 한다.)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edownstream_model_dir\u003c/strong\u003e:  \u003ccode\u003etraining_section.ipynb\u003c/code\u003e에서 파인튜닝한 모델의 체크포인트 저장 위치(확장자가 \u003ccode\u003eckpt\u003c/code\u003e인 파일이 하나 이상 있어야 한다.)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003emax_seq_length\u003c/strong\u003e: 토큰 기준 입력 문장 최대 길이. 아무것도 입력하지 않으면 128.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e2. 토크나이저 및 모델 불러오기\u003c/h2\u003e\n\u003ch3\u003e토크나이저 로드\u003c/h3\u003e\n\u003cp\u003ecode 2-3을 실행해 토크나이저를 초기화 한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-3\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\n    args.pretrained_model_name,\n    do_lower_case=False,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eDownloading:   0%|          | 0.00/250k [00:00\u0026#x3C;?, ?B/s]\n\n\n\nDownloading:   0%|          | 0.00/49.0 [00:00\u0026#x3C;?, ?B/s]\n\n\n\nDownloading:   0%|          | 0.00/619 [00:00\u0026#x3C;?, ?B/s]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e체크포인트 로드\u003c/h3\u003e\n\u003cp\u003ecode 2-4는 \u003ccode\u003etraining_section.ipynb\u003c/code\u003e에서 파인튜닝한 모델의 체크포인트를 읽어들인다.\u003c/p\u003e\n\u003ch4\u003ecode 2-4\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport torch\nfine_tuned_model_ckpt = torch.load(\n    args.downstream_model_checkpoint_fpath,\n    map_location=torch.device(\"cpu\"),\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eBERT 설정 로드 및 BERT 모델 초기화\u003c/h3\u003e\n\u003cp\u003ecode 2-5는 \u003ccode\u003etraining_section.ipynb\u003c/code\u003e의 파인튜닝 때 사용한 \u003ccode\u003epretrained_model_name\u003c/code\u003e에 해당하는 모델의 설정값들을 읽어들인다.\u003c/p\u003e\n\u003cp\u003e이어서 code 2-6을 실행하면 해당 설정값대로 \u003cstrong\u003eBERT\u003c/strong\u003e 모델을 초기화 한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-5\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertConfig\npretrained_model_config = BertConfig.from_pretrained(\n    args.pretrained_model_name,\n    num_labels=fine_tuned_model_ckpt[\"state_dict\"][\"model.classifier.bias\"].shape.numel(),\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003ecode 2-6\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertForSequenceClassification\nmodel = BertForSequenceClassification(pretrained_model_config)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e체크포인트 주입하기\u003c/h3\u003e\n\u003cp\u003ecode 2-7은 초기화한 \u003cstrong\u003eBERT\u003c/strong\u003e모델에 체크포인트(fine_tuned_model_ckpt)를 주입한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-7\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel.load_state_dict({k.replace(\"model.\",\"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026#x3C;All keys matched successfully\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e평가모드로 전환\u003c/h3\u003e\n\u003cp\u003e이어서 code 2-8을 실행하면 모델이 평가모드로 전환되게 된다. \u003cstrong\u003e드롭아웃 등 학습 때만 사용하는 기법들을 무효화하는 역할\u003c/strong\u003e을 한다.\u003c/p\u003e\n\u003ch4\u003ecode 2-8\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel.eval()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eBertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e3. 모델 출력값 만들고 후처리 하기\u003c/h2\u003e\n\u003cp\u003ecode 2-9는 \u003cstrong\u003e인퍼런스 과정을 정의한 함수\u003c/strong\u003e이다. 문장에 토큰화를 수행한 뒤 \u003ccode\u003einput_ids\u003c/code\u003e, \u003ccode\u003eattention_mask\u003c/code\u003e, \u003ccode\u003etoken_type_ids\u003c/code\u003e를 만든다. 이들 입력값을 파이토치의 텐서 자료형으로 변환한 뒤 모델에 입력한다. 모델 출력값(\u003ccode\u003eoutputs.logits\u003c/code\u003e)은 소프트맥스 함수 적용 이전의 \u003cstrong\u003e로짓\u003c/strong\u003e(logit)형태인데, 여기에 소프트맥스 함수를 써서 모델 출력을 '[\u003cstrong\u003e부정일 확률, 긍정일 확률\u003c/strong\u003e]'로 바꾼다.\u003c/p\u003e\n\u003cp\u003e마지막으로 모델 출력을 약간 후처리 하여 예측 확률의 최댓값이 부정 위치일 때 해당 문장이 '\u003cstrong\u003e부정\u003c/strong\u003e(negative)', 반대일 때는 '\u003cstrong\u003e긍정\u003c/strong\u003e(positive)'이 되도록 \u003ccode\u003epred\u003c/code\u003e값을 만든다.\u003c/p\u003e\n\u003ch4\u003ecode 2-9\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef inference_fn(sentence):\n  # 문장을 토큰화한 뒤 input_id, attention_masks, token_type_ids 만들기\n  inputs = tokenizer(\n      [sentence],\n      max_lenght=args.max_seq_length,\n      padding=\"max_length\",\n      truncation=True,\n  )\n  with torch.no_grad():\n    # 모델 계산하기\n    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}안 = inputs를 파이토치 텐서로 바꾸기\n    \n    # 로짓에 소프트 맥스 취하기\n    prob = outputs.logits.softmax(dim=1)\n\n    # 긍정/부정 확률을 소수점 4자리로 반올림\n    positive_prob = round(prob[0][1].item(), 4)\n    negative_prob = round(prob[0][0].item(), 4)\n\n    # 예측 확률의 최댓값 위치에 따라 pred 만들기\n    pred = \"긍정 (positive)\" if torch.argmax(prob) == 1 else \"부정 (negative)\"\n  return {\n      'sentence' : sentence,\n      'prediction': pred,\n      'positive_data': f\"긍정 {positive_prob}\",\n      'negative_data': f\"부정 {negative_prob}\",\n      'positive_width': f\"{positive_prob * 100}%\",\n      'negative_width': f\"{negative_prob * 100}%\",\n  }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ecode 2-9에서 \u003ccode\u003epositive_width\u003c/code\u003e, \u003ccode\u003enegative_width\u003c/code\u003e는 웹 페이지에서 긍정/부정 막대의 길이를 조정하려는 것이므로 크게 신경쓰지 않아도 된다.\u003c/p\u003e\n\u003ch2\u003e4. 웹 서비스 시작하기\u003c/h2\u003e\n\u003ch3\u003e웹 서비스 만들기 준비\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003engrok\u003c/code\u003e은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. \u003ccode\u003engrok\u003c/code\u003e을 실행하려면 \u003ca href=\"https://dashboard.ngrok.com/get-started/setup\"\u003e회원가입\u003c/a\u003e 후 \u003ca href=\"https://dashboard.ngrok.com/get-started/setup\"\u003e로그인\u003c/a\u003e을 한 뒤 \u003ca href=\"https://dashboard.ngrok.com/get-started/your-authtoken\"\u003e이곳\u003c/a\u003e에 접속해 인증토큰(authtoken)을 확인해야 한다.\u003c/p\u003e\n\u003cp\u003e예를 들어 확인된 \u003ccode\u003eauthtoken\u003c/code\u003e이 \u003ccode\u003etest123\u003c/code\u003e이라면 다음과 같이 실행 된다.\u003c/p\u003e\n\u003cp\u003e** !mkdir /root/.ngrok2 \u0026#x26;\u0026#x26; echo \"authtoken: test123\" \u003e /root/.ngrok2/ngrok.yml**\u003c/p\u003e\n\u003ch4\u003ecode 2-10\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!mkdir /root/.ngrok2 \u0026#x26;\u0026#x26; echo \"authtoken: (여기 채우세요))\" \u003e /root/.ngrok2/ngrok.yml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e웹 서비스 시작하기\u003c/h3\u003e\n\u003cp\u003ecode 2-9에서 정의한 인퍼런스 함수 \u003ccode\u003einference_fn\u003c/code\u003e을 가지고 code 2-11을 실행하면 \u003cstrong\u003e플라스크\u003c/strong\u003e(flask)라는 파이썬 라이브러리의 도움을 받아 웹 서비스를 띄울 수 있다.\u003c/p\u003e\n\u003ch4\u003ecode 2-11\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom ratsnlp.nlpbook.classification import get_web_service_app\napp = get_web_service_app(inference_fn)\napp.run()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e웹 사이트의 형태는 다음과 같다.\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png\" alt=\"model_inference\"\u003e\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"relative\",\"children\":[[\"$\",\"article\",null,{\"className\":\"prose prose-lg dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 text-sm text-gray-500 flex items-center space-x-2\",\"children\":[[[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"font-medium text-blue-600 hover:underline\",\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"children\":\"•\"}]],[\"$\",\"time\",null,{\"children\":\"2022-03-26\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4\",\"children\":\"[NLP] 문서 분류 모델 실전 투입\"}]]}],[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}]]}],\"$L1a\"]}]\n"])</script><script>self.__next_f.push([1,"1b:I[50718,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"default\"]\n1a:[\"$\",\"$L1b\",null,{}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1c:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"[NLP] 문서 분류 모델 실전 투입\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1c\",\"3\",{}]]\n8:null\n"])</script></body></html>
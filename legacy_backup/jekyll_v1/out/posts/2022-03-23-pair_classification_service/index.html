<!DOCTYPE html><!--oAIH0_g3w6LOdbw_0qDiA--><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/8fa8e9b5e3e9b2cd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/cbd55ab9639e1e66.js"/><script src="/_next/static/chunks/1abc3924204d7dd0.js" async=""></script><script src="/_next/static/chunks/9c23f44fff36548a.js" async=""></script><script src="/_next/static/chunks/5944084dd90310d5.js" async=""></script><script src="/_next/static/chunks/turbopack-aeaf7046609aeecd.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/_next/static/chunks/a8f82a9835eb887b.js" async=""></script><title>[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…</title><meta name="description" content="ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…í•˜ê¸°"/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen"><div hidden=""><!--$--><!--/$--></div><aside class="w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block"><div class="mb-8"><h1 class="text-2xl font-bold font-sans tracking-tight"><a href="/">Sehoon&#x27;s Workspace</a></h1><p class="text-sm text-gray-500 mt-2">Tech &amp; Study Blog</p></div><nav class="space-y-8"><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Menu</h3><ul class="space-y-1"><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/">Recent Posts</a></li><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/about/">About</a></li></ul></div><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Categories</h3><ul class="space-y-1"><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/proteomics/"><span>proteomics</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->9<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/nlp/"><span>NLP</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->6<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/blog/"><span>Blog</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->5<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jetson/"><span>Jetson</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/paperreview/"><span>PaperReview</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/neural_style_transfer/"><span>Neural_Style_Transfer</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->3<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jekyll/"><span>jekyll</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/ml/"><span>ML</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/algorithms/"><span>algorithms</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/contest/"><span>Contest</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/capstone/"><span>Capstone</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/linux/"><span>Linux</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/etc/"><span>ETC</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/datastructure/"><span>DataStructure</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/dl/"><span>DL</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li></ul></div></nav><div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800"><div class="flex space-x-4"></div></div></aside><main class="flex-1 min-w-0"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10"><div class="relative"><article class="prose prose-lg dark:prose-invert max-w-none"><header class="mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8"><div class="mb-4 text-sm text-gray-500 flex items-center space-x-2"><a class="font-medium text-blue-600 hover:underline" href="/category/nlp/">NLP</a><span>â€¢</span><time>2022-03-23</time></div><h1 class="text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4">[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…</h1></header><div><p>ì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?</p>
<p>ë³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ 'Do it! ìì—°ì–´ ì²˜ë¦¬'ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)</p>
<h1>í•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°</h1>
<p>í•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg" alt="pair_classification_map">
<strong>ê·¸ë¦¼ 1.</strong> ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤</p>
<p>ì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´</p>
<p><strong>[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]</strong>
ì„ ê³„ì‚°í•œë‹¤.</p>
<p>ì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.</p>
<h1>ì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°</h1>
<h2>1. í™˜ê²½ ì„¤ì •í•˜ê¸°</h2>
<h3>ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜</h3>
<p>pip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.</p>
<h4>code 4-0</h4>
<pre><code class="language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.18.2)
Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)
Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2022.2.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)
Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.7.2)
Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.5)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.3.0)
Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.63.0)
Requirement already satisfied: PyYAML&#x3C;=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (5.4.1)
Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.4.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.6.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.2)
Requirement already satisfied: tokenizers&#x3C;0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.10.3)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2.23.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.0.47)
Requirement already satisfied: Jinja2&#x3C;3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&#x3C;2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)
Requirement already satisfied: itsdangerous&#x3C;2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)
Requirement already satisfied: click&#x3C;8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0->ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&#x3C;3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)
Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.7)
Requirement already satisfied: idna&#x3C;3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&#x3C;1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2021.10.8)
Requirement already satisfied: chardet&#x3C;4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (3.0.4)
Requirement already satisfied: google-auth-oauthlib&#x3C;0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)
Requirement already satisfied: tensorboard-data-server&#x3C;0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)
Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.44.0)
Requirement already satisfied: google-auth&#x3C;3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)
Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)
Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.6)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)
Requirement already satisfied: rsa&#x3C;5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)
Requirement already satisfied: cachetools&#x3C;5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&#x3C;0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.0)
Requirement already satisfied: yarl&#x3C;2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.7.2)
Requirement already satisfied: charset-normalizer&#x3C;3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.2.0)
Requirement already satisfied: async-timeout&#x3C;5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (4.0.2)
Requirement already satisfied: multidict&#x3C;7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (6.0.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (0.13.0)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)
</code></pre>
<h3>êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™</h3>
<p>í•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.</p>
<h4>code 4-1</h4>
<pre><code class="language-python">from google.colab import drive
drive.mount('/gdrive', force_remount=True)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3>ì¸í¼ëŸ°ìŠ¤ ì„¤ì •</h3>
<p>ê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. <code>pretrained_model_name</code>ê³¼ <code>max_seq_length</code>, <code>downstream_model_dir</code> ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.</p>
<h4>code 4-2</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.classification import ClassificationDeployArguments
args = ClassificationDeployArguments(
    pretrained_model_name="beomi/kcbert-base",
    downstream_model_dir="/gdrive/My Drive/nlpbook/checkpoint-paircls",
    max_seq_length=64,
)
</code></pre>
<pre><code>downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt
</code></pre>
<h2>2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°</h2>
<h3>í† í¬ë‚˜ì´ì € ë¡œë“œ</h3>
<p>code 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.</p>
<h4>code 4-3</h4>
<pre><code class="language-python">from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=False,
)
</code></pre>
<h3>ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ</h3>
<p>code 4-4ëŠ” <code>pair_classification_train.ipynb</code>ì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.</p>
<h4>code 4-4</h4>
<pre><code class="language-python">import torch
fine_tuned_model_ckpt = torch.load(
    args.downstream_model_checkpoint_fpath,
    map_location=torch.device("cpu"),
)
</code></pre>
<h3>BERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”</h3>
<p>code 4-5ëŠ” <code>pair_classification_train.ipynb</code>ì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ <code>pretrained_model_name</code>ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.</p>
<h4>code 4-5</h4>
<pre><code class="language-python">from transformers import BertConfig
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),
)
</code></pre>
<h4>code 4-6</h4>
<pre><code class="language-python">from transformers import BertForSequenceClassification
model = BertForSequenceClassification(pretrained_model_config)
</code></pre>
<h3>ì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°</h3>
<p>code 4-7ì€ ì´ˆê¸°í™”í•œ <strong>BERT</strong>ëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤</p>
<h4>code 4-7</h4>
<pre><code class="language-python">model.load_state_dict({k.replace("model.",""): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})
</code></pre>
<pre><code>&#x3C;All keys matched successfully>
</code></pre>
<h3>í‰ê°€ ëª¨ë“œë¡œ ì „í™˜</h3>
<p>ì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. <strong>ë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• </strong>ì„ í•œë‹¤.</p>
<h4>code 4-8</h4>
<pre><code class="language-python">model.eval()
</code></pre>
<pre><code>BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30000, 768, padding_idx=0)
      (position_embeddings): Embedding(300, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
)
</code></pre>
<h2>3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°</h2>
<p>code 4-9ëŠ” <strong>ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜</strong>ì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>ë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.</p>
<h3>ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜</h3>
<h4>code 4-9</h4>
<pre><code class="language-python">def inference_fn(premise, hypothesis):
  # ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°
  inputs = tokenizer(
      [(premise, hypothesis)],
      max_length=args.max_seq_length,
      padding="max_length",
      truncation=True,
  )
  with torch.no_grad():
    # ëª¨ë¸ ê³„ì‚°í•˜ê¸°
    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°

    # ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°
    prob = outputs.logits.softmax(dim=1)

    # í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼
    entailment_prob = round(prob[0][0].item(), 2)
    contradiction_prob = round(prob[0][1].item(), 2)
    neutral_prob = round(prob[0][2].item(), 2)

    # ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°
    if torch.argmax(prob) == 0:
      pred = "ì°¸ (entailment)"
    elif torch.argmax(prob) == 1:
      pred = "ê±°ì§“ (contradiction)"
    else:
      pred = "ì¤‘ë¦½ (neutral)"
  
  return {
      'premise': premise,
      'hypothesis': hypothesis,
      'prediction': pred,
      'entailment_data': f"ì°¸ {entailment_prob}",
      'contradiction_data': f"ê±°ì§“ {contradiction_prob}",
      'neutral_data': f"ì¤‘ë¦½ {neutral_prob}",
      'entailment_width': f"{entailment_prob * 100}%",
      'contradiction_width': f"{contradiction_prob * 100}%",
      'neutral_width': f"{neutral_prob * 100}%"
  }
</code></pre>
<p>**ëª¨ë¸ ì¶œë ¥ê°’(<code>output.logits</code>)**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ '<strong>ì°¸ (entailment)</strong>', ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° '<strong>ê±°ì§“ (contradiction)</strong>', ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° '<strong>ì¤‘ë¦½ (neutral)</strong>'ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.</p>
<p>code 4-9ì—ì„œ <code>entailment_width</code>, <code>contradiction_width</code>, <code>neutral_width</code>ëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.</p>
<h2>4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h2>
<h3>ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„</h3>
<p><code>ngrok</code>ì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. <code>ngrok</code>ì„ ì‹¤í–‰í•˜ë ¤ë©´ <a href="https://dashboard.ngrok.com/get-started/setup">íšŒì›ê°€ì…</a> í›„ <a href="https://dashboard.ngrok.com/get-started/setup">ë¡œê·¸ì¸</a>ì„ í•œ ë’¤ <a href="https://dashboard.ngrok.com/get-started/your-authtoken">ì´ê³³</a>ì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤.</p>
<p>ì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ <code>authtoken</code>ì´ <code>test123</code>ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.</p>
<p>** !mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: test123" > /root/.ngrok2/ngrok.yml**</p>
<h4>code 4-10</h4>
<pre><code class="language-python">!mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)" > /root/.ngrok2/ngrok.yml
</code></pre>
<pre><code>mkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists
</code></pre>
<h3>ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h3>
<p>code 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ <code>inference_fn</code>ì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.</p>
<h4>code 4-11</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.paircls import get_web_service_app
app = get_web_service_app(inference_fn)
app.run()
</code></pre>
<pre><code> * Serving Flask app "ratsnlp.nlpbook.paircls.deploy" (lazy loading)
 * Environment: production
[31m   WARNING: This is a development server. Do not use it in a production deployment.[0m
[2m   Use a production WSGI server instead.[0m
 * Debug mode: off


 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)


 * Running on http://0163-35-238-180-140.ngrok.io
 * Traffic stats available on http://127.0.0.1:4040


127.0.0.1 - - [04/Mar/2022 09:14:48] "[37mGET / HTTP/1.1[0m" 200 -
127.0.0.1 - - [04/Mar/2022 09:14:49] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
127.0.0.1 - - [04/Mar/2022 09:14:49] "[37mGET / HTTP/1.1[0m" 200 -
127.0.0.1 - - [04/Mar/2022 09:15:01] "[37mPOST /api HTTP/1.1[0m" 200 -
</code></pre>
<h1>ì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</h1>
<p><img src="https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png" alt="pair_classification"></p>
</div></article></div><!--$--><!--/$--></div></main><script src="/_next/static/chunks/cbd55ab9639e1e66.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"oAIH0-g3w6LOdbw_0qDiA\",\"c\":[\"\",\"posts\",\"2022-03-23-pair_classification_service\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"2022-03-23-pair_classification_service\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen\",\"children\":[\"$L2\",[\"$\",\"main\",null,{\"className\":\"flex-1 min-w-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/a8f82a9835eb887b.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"2:[\"$\",\"aside\",null,{\"className\":\"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-2xl font-bold font-sans tracking-tight\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"Sehoon's Workspace\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-500 mt-2\",\"children\":\"Tech \u0026 Study Blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"space-y-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Menu\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"Recent Posts\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/about\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"About\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Categories\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",\"proteomics\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/proteomics\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"proteomics\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",9,\")\"]}]]}]}],[\"$\",\"li\",\"NLP\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",6,\")\"]}]]}]}],[\"$\",\"li\",\"Blog\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/blog\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Blog\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",5,\")\"]}]]}]}],[\"$\",\"li\",\"Jetson\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jetson\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Jetson\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"PaperReview\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/paperreview\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"PaperReview\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"Neural_Style_Transfer\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/neural_style_transfer\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Neural_Style_Transfer\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",3,\")\"]}]]}]}],[\"$\",\"li\",\"jekyll\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jekyll\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"jekyll\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]]}]}],[\"$\",\"li\",\"ML\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/ml\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[\"$Lf\",\"$L10\"]}]}],\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\"]}]]}]]}],\"$L18\"]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"span\",null,{\"children\":\"ML\"}]\n10:[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]\n11:[\"$\",\"li\",\"algorithms\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/algorithms\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"algorithms\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n12:[\"$\",\"li\",\"Contest\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/contest\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Contest\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n13:[\"$\",\"li\",\"Capstone\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/capstone\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Capstone\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n14:[\"$\",\"li\",\"Linux\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/linux\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Linux\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n15:[\"$\",\"li\",\"ETC\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/etc\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"ETC\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n16:[\"$\",\"li\",\"DataStructure\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/datastructure\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DataStructure\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n17:[\"$\",\"li\",\"DL\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/dl\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DL\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n18:[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex space-x-4\"}]}]\n"])</script><script>self.__next_f.push([1,"19:T81e2,"])</script><script>self.__next_f.push([1,"\u003cp\u003eì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?\u003c/p\u003e\n\u003cp\u003eë³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ 'Do it! ìì—°ì–´ ì²˜ë¦¬'ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)\u003c/p\u003e\n\u003ch1\u003eí•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°\u003c/h1\u003e\n\u003cp\u003eí•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg\" alt=\"pair_classification_map\"\u003e\n\u003cstrong\u003eê·¸ë¦¼ 1.\u003c/strong\u003e ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤\u003c/p\u003e\n\u003cp\u003eì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]\u003c/strong\u003e\nì„ ê³„ì‚°í•œë‹¤.\u003c/p\u003e\n\u003cp\u003eì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.\u003c/p\u003e\n\u003ch1\u003eì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°\u003c/h1\u003e\n\u003ch2\u003e1. í™˜ê²½ ì„¤ì •í•˜ê¸°\u003c/h2\u003e\n\u003ch3\u003eì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜\u003c/h3\u003e\n\u003cp\u003epip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-0\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!pip install ratsnlp\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eRequirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\nRequirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\nRequirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\nRequirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\nRequirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\nRequirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\nRequirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\nRequirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\nRequirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\nRequirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\nRequirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\nRequirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\nRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\nRequirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\nRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.63.0)\nRequirement already satisfied: PyYAML\u0026#x3C;=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\nRequirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.2)\nRequirement already satisfied: tokenizers\u0026#x3C;0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\nRequirement already satisfied: Jinja2\u0026#x3C;3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\nRequirement already satisfied: Werkzeug\u0026#x3C;2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\nRequirement already satisfied: itsdangerous\u0026#x3C;2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\nRequirement already satisfied: click\u0026#x3C;8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\nRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\nRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\nRequirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u0026#x3C;3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\nRequirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\nRequirement already satisfied: idna\u0026#x3C;3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u0026#x3C;1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\nRequirement already satisfied: chardet\u0026#x3C;4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\nRequirement already satisfied: google-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\nRequirement already satisfied: tensorboard-data-server\u0026#x3C;0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\nRequirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\nRequirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.44.0)\nRequirement already satisfied: google-auth\u0026#x3C;3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\nRequirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\nRequirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\nRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\nRequirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\nRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\nRequirement already satisfied: rsa\u0026#x3C;5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\nRequirement already satisfied: cachetools\u0026#x3C;5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\nRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\nRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\nRequirement already satisfied: pyasn1\u0026#x3C;0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u0026#x3C;3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\nRequirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u0026#x3C;0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\nRequirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\nRequirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\nRequirement already satisfied: yarl\u0026#x3C;2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\nRequirement already satisfied: charset-normalizer\u0026#x3C;3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\nRequirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\nRequirement already satisfied: async-timeout\u0026#x3C;5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\nRequirement already satisfied: multidict\u0026#x3C;7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eêµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™\u003c/h3\u003e\n\u003cp\u003eí•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-1\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom google.colab import drive\ndrive.mount('/gdrive', force_remount=True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eMounted at /gdrive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eì¸í¼ëŸ°ìŠ¤ ì„¤ì •\u003c/h3\u003e\n\u003cp\u003eê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. \u003ccode\u003epretrained_model_name\u003c/code\u003eê³¼ \u003ccode\u003emax_seq_length\u003c/code\u003e, \u003ccode\u003edownstream_model_dir\u003c/code\u003e ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-2\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom ratsnlp.nlpbook.classification import ClassificationDeployArguments\nargs = ClassificationDeployArguments(\n    pretrained_model_name=\"beomi/kcbert-base\",\n    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-paircls\",\n    max_seq_length=64,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003edownstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\u003c/h2\u003e\n\u003ch3\u003eí† í¬ë‚˜ì´ì € ë¡œë“œ\u003c/h3\u003e\n\u003cp\u003ecode 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-3\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\n    args.pretrained_model_name,\n    do_lower_case=False,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\u003c/h3\u003e\n\u003cp\u003ecode 4-4ëŠ” \u003ccode\u003epair_classification_train.ipynb\u003c/code\u003eì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-4\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport torch\nfine_tuned_model_ckpt = torch.load(\n    args.downstream_model_checkpoint_fpath,\n    map_location=torch.device(\"cpu\"),\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eBERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”\u003c/h3\u003e\n\u003cp\u003ecode 4-5ëŠ” \u003ccode\u003epair_classification_train.ipynb\u003c/code\u003eì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ \u003ccode\u003epretrained_model_name\u003c/code\u003eì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-5\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertConfig\npretrained_model_config = BertConfig.from_pretrained(\n    args.pretrained_model_name,\n    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003ecode 4-6\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom transformers import BertForSequenceClassification\nmodel = BertForSequenceClassification(pretrained_model_config)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°\u003c/h3\u003e\n\u003cp\u003ecode 4-7ì€ ì´ˆê¸°í™”í•œ \u003cstrong\u003eBERT\u003c/strong\u003eëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤\u003c/p\u003e\n\u003ch4\u003ecode 4-7\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel.load_state_dict({k.replace(\"model.\",\"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026#x3C;All keys matched successfully\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eí‰ê°€ ëª¨ë“œë¡œ ì „í™˜\u003c/h3\u003e\n\u003cp\u003eì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. \u003cstrong\u003eë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• \u003c/strong\u003eì„ í•œë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-8\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003emodel.eval()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eBertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°\u003c/h2\u003e\n\u003cp\u003ecode 4-9ëŠ” \u003cstrong\u003eì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜\u003c/strong\u003eì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ \u003ccode\u003einput_ids\u003c/code\u003e, \u003ccode\u003eattention_mask\u003c/code\u003e, \u003ccode\u003etoken_type_ids\u003c/code\u003eë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.\u003c/p\u003e\n\u003ch3\u003eì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜\u003c/h3\u003e\n\u003ch4\u003ecode 4-9\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef inference_fn(premise, hypothesis):\n  # ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°\n  inputs = tokenizer(\n      [(premise, hypothesis)],\n      max_length=args.max_seq_length,\n      padding=\"max_length\",\n      truncation=True,\n  )\n  with torch.no_grad():\n    # ëª¨ë¸ ê³„ì‚°í•˜ê¸°\n    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°\n\n    # ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°\n    prob = outputs.logits.softmax(dim=1)\n\n    # í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼\n    entailment_prob = round(prob[0][0].item(), 2)\n    contradiction_prob = round(prob[0][1].item(), 2)\n    neutral_prob = round(prob[0][2].item(), 2)\n\n    # ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°\n    if torch.argmax(prob) == 0:\n      pred = \"ì°¸ (entailment)\"\n    elif torch.argmax(prob) == 1:\n      pred = \"ê±°ì§“ (contradiction)\"\n    else:\n      pred = \"ì¤‘ë¦½ (neutral)\"\n  \n  return {\n      'premise': premise,\n      'hypothesis': hypothesis,\n      'prediction': pred,\n      'entailment_data': f\"ì°¸ {entailment_prob}\",\n      'contradiction_data': f\"ê±°ì§“ {contradiction_prob}\",\n      'neutral_data': f\"ì¤‘ë¦½ {neutral_prob}\",\n      'entailment_width': f\"{entailment_prob * 100}%\",\n      'contradiction_width': f\"{contradiction_prob * 100}%\",\n      'neutral_width': f\"{neutral_prob * 100}%\"\n  }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e**ëª¨ë¸ ì¶œë ¥ê°’(\u003ccode\u003eoutput.logits\u003c/code\u003e)**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ '\u003cstrong\u003eì°¸ (entailment)\u003c/strong\u003e', ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° '\u003cstrong\u003eê±°ì§“ (contradiction)\u003c/strong\u003e', ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° '\u003cstrong\u003eì¤‘ë¦½ (neutral)\u003c/strong\u003e'ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.\u003c/p\u003e\n\u003cp\u003ecode 4-9ì—ì„œ \u003ccode\u003eentailment_width\u003c/code\u003e, \u003ccode\u003econtradiction_width\u003c/code\u003e, \u003ccode\u003eneutral_width\u003c/code\u003eëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.\u003c/p\u003e\n\u003ch2\u003e4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\u003c/h2\u003e\n\u003ch3\u003eì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003engrok\u003c/code\u003eì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. \u003ccode\u003engrok\u003c/code\u003eì„ ì‹¤í–‰í•˜ë ¤ë©´ \u003ca href=\"https://dashboard.ngrok.com/get-started/setup\"\u003eíšŒì›ê°€ì…\u003c/a\u003e í›„ \u003ca href=\"https://dashboard.ngrok.com/get-started/setup\"\u003eë¡œê·¸ì¸\u003c/a\u003eì„ í•œ ë’¤ \u003ca href=\"https://dashboard.ngrok.com/get-started/your-authtoken\"\u003eì´ê³³\u003c/a\u003eì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤.\u003c/p\u003e\n\u003cp\u003eì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ \u003ccode\u003eauthtoken\u003c/code\u003eì´ \u003ccode\u003etest123\u003c/code\u003eì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.\u003c/p\u003e\n\u003cp\u003e** !mkdir /root/.ngrok2 \u0026#x26;\u0026#x26; echo \"authtoken: test123\" \u003e /root/.ngrok2/ngrok.yml**\u003c/p\u003e\n\u003ch4\u003ecode 4-10\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e!mkdir /root/.ngrok2 \u0026#x26;\u0026#x26; echo \"authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)\" \u003e /root/.ngrok2/ngrok.yml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003emkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\u003c/h3\u003e\n\u003cp\u003ecode 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ \u003ccode\u003einference_fn\u003c/code\u003eì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.\u003c/p\u003e\n\u003ch4\u003ecode 4-11\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom ratsnlp.nlpbook.paircls import get_web_service_app\napp = get_web_service_app(inference_fn)\napp.run()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e * Serving Flask app \"ratsnlp.nlpbook.paircls.deploy\" (lazy loading)\n * Environment: production\n\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n\u001b[2m   Use a production WSGI server instead.\u001b[0m\n * Debug mode: off\n\n\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n\n\n * Running on http://0163-35-238-180-140.ngrok.io\n * Traffic stats available on http://127.0.0.1:4040\n\n\n127.0.0.1 - - [04/Mar/2022 09:14:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [04/Mar/2022 09:14:49] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n127.0.0.1 - - [04/Mar/2022 09:14:49] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [04/Mar/2022 09:15:01] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png\" alt=\"pair_classification\"\u003e\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"relative\",\"children\":[[\"$\",\"article\",null,{\"className\":\"prose prose-lg dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 text-sm text-gray-500 flex items-center space-x-2\",\"children\":[[[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"font-medium text-blue-600 hover:underline\",\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"children\":\"â€¢\"}]],[\"$\",\"time\",null,{\"children\":\"2022-03-23\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4\",\"children\":\"[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…\"}]]}],[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}]]}],\"$L1a\"]}]\n"])</script><script>self.__next_f.push([1,"1b:I[50718,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"default\"]\n1a:[\"$\",\"$L1b\",null,{}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1c:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…í•˜ê¸°\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1c\",\"3\",{}]]\n8:null\n"])</script></body></html>
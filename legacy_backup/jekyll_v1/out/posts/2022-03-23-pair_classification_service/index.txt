1:"$Sreact.fragment"
3:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
4:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
d:I[68027,[],"default"]
:HL["/_next/static/chunks/8fa8e9b5e3e9b2cd.css","style"]
0:{"P":null,"b":"oAIH0-g3w6LOdbw_0qDiA","c":["","posts","2022-03-23-pair_classification_service",""],"q":"","i":false,"f":[[["",{"children":["posts",{"children":[["id","2022-03-23-pair_classification_service","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/8fa8e9b5e3e9b2cd.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/796e69ae18b2784c.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":["$","body",null,{"className":"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen","children":["$L2",["$","main",null,{"className":"flex-1 min-w-0","children":["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",[["$","script","script-0",{"src":"/_next/static/chunks/a8f82a9835eb887b.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$@a"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$@c"}]}]}],null]}],false]],"m":"$undefined","G":["$d",[]],"S":true}
e:I[22016,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],""]
2:["$","aside",null,{"className":"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block","children":[["$","div",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-2xl font-bold font-sans tracking-tight","children":["$","$Le",null,{"href":"/","children":"Sehoon's Workspace"}]}],["$","p",null,{"className":"text-sm text-gray-500 mt-2","children":"Tech & Study Blog"}]]}],["$","nav",null,{"className":"space-y-8","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2","children":"Menu"}],["$","ul",null,{"className":"space-y-1","children":[["$","li",null,{"children":["$","$Le",null,{"href":"/","className":"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm","children":"Recent Posts"}]}],["$","li",null,{"children":["$","$Le",null,{"href":"/about","className":"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm","children":"About"}]}]]}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2","children":"Categories"}],["$","ul",null,{"className":"space-y-1","children":[["$","li","proteomics",{"children":["$","$Le",null,{"href":"/category/proteomics","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"proteomics"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",9,")"]}]]}]}],["$","li","NLP",{"children":["$","$Le",null,{"href":"/category/nlp","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"NLP"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",6,")"]}]]}]}],["$","li","Blog",{"children":["$","$Le",null,{"href":"/category/blog","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Blog"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",5,")"]}]]}]}],["$","li","Jetson",{"children":["$","$Le",null,{"href":"/category/jetson","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Jetson"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",4,")"]}]]}]}],["$","li","PaperReview",{"children":["$","$Le",null,{"href":"/category/paperreview","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"PaperReview"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",4,")"]}]]}]}],["$","li","Neural_Style_Transfer",{"children":["$","$Le",null,{"href":"/category/neural_style_transfer","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Neural_Style_Transfer"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",3,")"]}]]}]}],["$","li","jekyll",{"children":["$","$Le",null,{"href":"/category/jekyll","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"jekyll"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",2,")"]}]]}]}],["$","li","ML",{"children":["$","$Le",null,{"href":"/category/ml","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":["$Lf","$L10"]}]}],"$L11","$L12","$L13","$L14","$L15","$L16","$L17"]}]]}]]}],"$L18"]}]
f:["$","span",null,{"children":"ML"}]
10:["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",2,")"]}]
11:["$","li","algorithms",{"children":["$","$Le",null,{"href":"/category/algorithms","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"algorithms"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
12:["$","li","Contest",{"children":["$","$Le",null,{"href":"/category/contest","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Contest"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
13:["$","li","Capstone",{"children":["$","$Le",null,{"href":"/category/capstone","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Capstone"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
14:["$","li","Linux",{"children":["$","$Le",null,{"href":"/category/linux","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Linux"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
15:["$","li","ETC",{"children":["$","$Le",null,{"href":"/category/etc","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"ETC"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
16:["$","li","DataStructure",{"children":["$","$Le",null,{"href":"/category/datastructure","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"DataStructure"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
17:["$","li","DL",{"children":["$","$Le",null,{"href":"/category/dl","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"DL"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
18:["$","div",null,{"className":"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800","children":["$","div",null,{"className":"flex space-x-4"}]}]
19:T81e2,<p>ì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?</p>
<p>ë³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ 'Do it! ìì—°ì–´ ì²˜ë¦¬'ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)</p>
<h1>í•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°</h1>
<p>í•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg" alt="pair_classification_map">
<strong>ê·¸ë¦¼ 1.</strong> ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤</p>
<p>ì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´</p>
<p><strong>[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]</strong>
ì„ ê³„ì‚°í•œë‹¤.</p>
<p>ì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.</p>
<h1>ì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°</h1>
<h2>1. í™˜ê²½ ì„¤ì •í•˜ê¸°</h2>
<h3>ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜</h3>
<p>pip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.</p>
<h4>code 4-0</h4>
<pre><code class="language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: Korpora>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: flask-ngrok>=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.18.2)
Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)
Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2022.2.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)
Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.7.2)
Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.5)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (0.3.0)
Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.63.0)
Requirement already satisfied: PyYAML&#x3C;=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (5.4.1)
Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.4.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.6.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.2)
Requirement already satisfied: tokenizers&#x3C;0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.10.3)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2.23.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (0.0.47)
Requirement already satisfied: Jinja2&#x3C;3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&#x3C;2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)
Requirement already satisfied: itsdangerous&#x3C;2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)
Requirement already satisfied: click&#x3C;8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0->ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&#x3C;3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (0.6)
Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora>=0.2.0->ratsnlp) (2.0.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.7)
Requirement already satisfied: idna&#x3C;3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&#x3C;1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2021.10.8)
Requirement already satisfied: chardet&#x3C;4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (3.0.4)
Requirement already satisfied: google-auth-oauthlib&#x3C;0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)
Requirement already satisfied: tensorboard-data-server&#x3C;0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)
Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)
Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.44.0)
Requirement already satisfied: google-auth&#x3C;3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)
Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)
Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.6)
Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)
Requirement already satisfied: rsa&#x3C;5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)
Requirement already satisfied: cachetools&#x3C;5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)
Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&#x3C;0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth&#x3C;3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib&#x3C;0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.0)
Requirement already satisfied: yarl&#x3C;2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.7.2)
Requirement already satisfied: charset-normalizer&#x3C;3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (1.2.0)
Requirement already satisfied: async-timeout&#x3C;5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (4.0.2)
Requirement already satisfied: multidict&#x3C;7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (6.0.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (0.13.0)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)
</code></pre>
<h3>êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™</h3>
<p>í•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.</p>
<h4>code 4-1</h4>
<pre><code class="language-python">from google.colab import drive
drive.mount('/gdrive', force_remount=True)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3>ì¸í¼ëŸ°ìŠ¤ ì„¤ì •</h3>
<p>ê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. <code>pretrained_model_name</code>ê³¼ <code>max_seq_length</code>, <code>downstream_model_dir</code> ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.</p>
<h4>code 4-2</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.classification import ClassificationDeployArguments
args = ClassificationDeployArguments(
    pretrained_model_name="beomi/kcbert-base",
    downstream_model_dir="/gdrive/My Drive/nlpbook/checkpoint-paircls",
    max_seq_length=64,
)
</code></pre>
<pre><code>downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt
</code></pre>
<h2>2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°</h2>
<h3>í† í¬ë‚˜ì´ì € ë¡œë“œ</h3>
<p>code 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.</p>
<h4>code 4-3</h4>
<pre><code class="language-python">from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=False,
)
</code></pre>
<h3>ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ</h3>
<p>code 4-4ëŠ” <code>pair_classification_train.ipynb</code>ì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.</p>
<h4>code 4-4</h4>
<pre><code class="language-python">import torch
fine_tuned_model_ckpt = torch.load(
    args.downstream_model_checkpoint_fpath,
    map_location=torch.device("cpu"),
)
</code></pre>
<h3>BERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”</h3>
<p>code 4-5ëŠ” <code>pair_classification_train.ipynb</code>ì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ <code>pretrained_model_name</code>ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.</p>
<h4>code 4-5</h4>
<pre><code class="language-python">from transformers import BertConfig
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),
)
</code></pre>
<h4>code 4-6</h4>
<pre><code class="language-python">from transformers import BertForSequenceClassification
model = BertForSequenceClassification(pretrained_model_config)
</code></pre>
<h3>ì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°</h3>
<p>code 4-7ì€ ì´ˆê¸°í™”í•œ <strong>BERT</strong>ëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤</p>
<h4>code 4-7</h4>
<pre><code class="language-python">model.load_state_dict({k.replace("model.",""): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})
</code></pre>
<pre><code>&#x3C;All keys matched successfully>
</code></pre>
<h3>í‰ê°€ ëª¨ë“œë¡œ ì „í™˜</h3>
<p>ì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. <strong>ë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• </strong>ì„ í•œë‹¤.</p>
<h4>code 4-8</h4>
<pre><code class="language-python">model.eval()
</code></pre>
<pre><code>BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30000, 768, padding_idx=0)
      (position_embeddings): Embedding(300, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
)
</code></pre>
<h2>3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°</h2>
<p>code 4-9ëŠ” <strong>ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜</strong>ì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>ë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.</p>
<h3>ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜</h3>
<h4>code 4-9</h4>
<pre><code class="language-python">def inference_fn(premise, hypothesis):
  # ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°
  inputs = tokenizer(
      [(premise, hypothesis)],
      max_length=args.max_seq_length,
      padding="max_length",
      truncation=True,
  )
  with torch.no_grad():
    # ëª¨ë¸ ê³„ì‚°í•˜ê¸°
    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°

    # ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°
    prob = outputs.logits.softmax(dim=1)

    # í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼
    entailment_prob = round(prob[0][0].item(), 2)
    contradiction_prob = round(prob[0][1].item(), 2)
    neutral_prob = round(prob[0][2].item(), 2)

    # ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°
    if torch.argmax(prob) == 0:
      pred = "ì°¸ (entailment)"
    elif torch.argmax(prob) == 1:
      pred = "ê±°ì§“ (contradiction)"
    else:
      pred = "ì¤‘ë¦½ (neutral)"
  
  return {
      'premise': premise,
      'hypothesis': hypothesis,
      'prediction': pred,
      'entailment_data': f"ì°¸ {entailment_prob}",
      'contradiction_data': f"ê±°ì§“ {contradiction_prob}",
      'neutral_data': f"ì¤‘ë¦½ {neutral_prob}",
      'entailment_width': f"{entailment_prob * 100}%",
      'contradiction_width': f"{contradiction_prob * 100}%",
      'neutral_width': f"{neutral_prob * 100}%"
  }
</code></pre>
<p>**ëª¨ë¸ ì¶œë ¥ê°’(<code>output.logits</code>)**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ '<strong>ì°¸ (entailment)</strong>', ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° '<strong>ê±°ì§“ (contradiction)</strong>', ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° '<strong>ì¤‘ë¦½ (neutral)</strong>'ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.</p>
<p>code 4-9ì—ì„œ <code>entailment_width</code>, <code>contradiction_width</code>, <code>neutral_width</code>ëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.</p>
<h2>4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h2>
<h3>ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„</h3>
<p><code>ngrok</code>ì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. <code>ngrok</code>ì„ ì‹¤í–‰í•˜ë ¤ë©´ <a href="https://dashboard.ngrok.com/get-started/setup">íšŒì›ê°€ì…</a> í›„ <a href="https://dashboard.ngrok.com/get-started/setup">ë¡œê·¸ì¸</a>ì„ í•œ ë’¤ <a href="https://dashboard.ngrok.com/get-started/your-authtoken">ì´ê³³</a>ì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤.</p>
<p>ì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ <code>authtoken</code>ì´ <code>test123</code>ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.</p>
<p>** !mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: test123" > /root/.ngrok2/ngrok.yml**</p>
<h4>code 4-10</h4>
<pre><code class="language-python">!mkdir /root/.ngrok2 &#x26;&#x26; echo "authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)" > /root/.ngrok2/ngrok.yml
</code></pre>
<pre><code>mkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists
</code></pre>
<h3>ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h3>
<p>code 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ <code>inference_fn</code>ì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.</p>
<h4>code 4-11</h4>
<pre><code class="language-python">from ratsnlp.nlpbook.paircls import get_web_service_app
app = get_web_service_app(inference_fn)
app.run()
</code></pre>
<pre><code> * Serving Flask app "ratsnlp.nlpbook.paircls.deploy" (lazy loading)
 * Environment: production
[31m   WARNING: This is a development server. Do not use it in a production deployment.[0m
[2m   Use a production WSGI server instead.[0m
 * Debug mode: off


 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)


 * Running on http://0163-35-238-180-140.ngrok.io
 * Traffic stats available on http://127.0.0.1:4040


127.0.0.1 - - [04/Mar/2022 09:14:48] "[37mGET / HTTP/1.1[0m" 200 -
127.0.0.1 - - [04/Mar/2022 09:14:49] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
127.0.0.1 - - [04/Mar/2022 09:14:49] "[37mGET / HTTP/1.1[0m" 200 -
127.0.0.1 - - [04/Mar/2022 09:15:01] "[37mPOST /api HTTP/1.1[0m" 200 -
</code></pre>
<h1>ì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</h1>
<p><img src="https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png" alt="pair_classification"></p>
5:["$","div",null,{"className":"relative","children":[["$","article",null,{"className":"prose prose-lg dark:prose-invert max-w-none","children":[["$","header",null,{"className":"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8","children":[["$","div",null,{"className":"mb-4 text-sm text-gray-500 flex items-center space-x-2","children":[[["$","$Le",null,{"href":"/category/nlp","className":"font-medium text-blue-600 hover:underline","children":"NLP"}],["$","span",null,{"children":"â€¢"}]],["$","time",null,{"children":"2022-03-23"}]]}],["$","h1",null,{"className":"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4","children":"[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…"}]]}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$19"}}]]}],"$L1a"]}]
1b:I[50718,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],"default"]
1a:["$","$L1b",null,{}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
1c:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
c:[["$","title","0",{"children":"[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…"}],["$","meta","1",{"name":"description","content":"ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…í•˜ê¸°"}],["$","link","2",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L1c","3",{}]]
8:null

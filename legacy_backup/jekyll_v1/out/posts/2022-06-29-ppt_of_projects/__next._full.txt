1:"$Sreact.fragment"
3:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
4:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
d:I[68027,[],"default"]
:HL["/_next/static/chunks/8fa8e9b5e3e9b2cd.css","style"]
0:{"P":null,"b":"oAIH0-g3w6LOdbw_0qDiA","c":["","posts","2022-06-29-ppt_of_projects",""],"q":"","i":false,"f":[[["",{"children":["posts",{"children":[["id","2022-06-29-ppt_of_projects","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/8fa8e9b5e3e9b2cd.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/796e69ae18b2784c.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":["$","body",null,{"className":"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen","children":["$L2",["$","main",null,{"className":"flex-1 min-w-0","children":["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",[["$","script","script-0",{"src":"/_next/static/chunks/a8f82a9835eb887b.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$@a"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$@c"}]}]}],null]}],false]],"m":"$undefined","G":["$d",[]],"S":true}
e:I[22016,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],""]
2:["$","aside",null,{"className":"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block","children":[["$","div",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-2xl font-bold font-sans tracking-tight","children":["$","$Le",null,{"href":"/","children":"Sehoon's Workspace"}]}],["$","p",null,{"className":"text-sm text-gray-500 mt-2","children":"Tech & Study Blog"}]]}],["$","nav",null,{"className":"space-y-8","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2","children":"Menu"}],["$","ul",null,{"className":"space-y-1","children":[["$","li",null,{"children":["$","$Le",null,{"href":"/","className":"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm","children":"Recent Posts"}]}],["$","li",null,{"children":["$","$Le",null,{"href":"/about","className":"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm","children":"About"}]}]]}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2","children":"Categories"}],["$","ul",null,{"className":"space-y-1","children":[["$","li","proteomics",{"children":["$","$Le",null,{"href":"/category/proteomics","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"proteomics"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",9,")"]}]]}]}],["$","li","NLP",{"children":["$","$Le",null,{"href":"/category/nlp","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"NLP"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",6,")"]}]]}]}],["$","li","Blog",{"children":["$","$Le",null,{"href":"/category/blog","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Blog"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",5,")"]}]]}]}],["$","li","Jetson",{"children":["$","$Le",null,{"href":"/category/jetson","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Jetson"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",4,")"]}]]}]}],["$","li","PaperReview",{"children":["$","$Le",null,{"href":"/category/paperreview","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"PaperReview"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",4,")"]}]]}]}],["$","li","Neural_Style_Transfer",{"children":["$","$Le",null,{"href":"/category/neural_style_transfer","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Neural_Style_Transfer"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",3,")"]}]]}]}],["$","li","jekyll",{"children":["$","$Le",null,{"href":"/category/jekyll","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"jekyll"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",2,")"]}]]}]}],["$","li","ML",{"children":["$","$Le",null,{"href":"/category/ml","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":["$Lf","$L10"]}]}],"$L11","$L12","$L13","$L14","$L15","$L16","$L17"]}]]}]]}],"$L18"]}]
f:["$","span",null,{"children":"ML"}]
10:["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",2,")"]}]
11:["$","li","algorithms",{"children":["$","$Le",null,{"href":"/category/algorithms","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"algorithms"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
12:["$","li","Contest",{"children":["$","$Le",null,{"href":"/category/contest","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Contest"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
13:["$","li","Capstone",{"children":["$","$Le",null,{"href":"/category/capstone","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Capstone"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
14:["$","li","Linux",{"children":["$","$Le",null,{"href":"/category/linux","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"Linux"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
15:["$","li","ETC",{"children":["$","$Le",null,{"href":"/category/etc","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"ETC"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
16:["$","li","DataStructure",{"children":["$","$Le",null,{"href":"/category/datastructure","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"DataStructure"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
17:["$","li","DL",{"children":["$","$Le",null,{"href":"/category/dl","className":"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm","children":[["$","span",null,{"children":"DL"}],["$","span",null,{"className":"text-xs text-gray-400 group-hover:text-blue-500 font-mono","children":["(",1,")"]}]]}]}]
18:["$","div",null,{"className":"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800","children":["$","div",null,{"className":"flex space-x-4"}]}]
19:T1f89,<p>학기가 모두 끝이 났습니다!! 그동안 프로젝트를 진행하고 시험,과제 처리하느라 업로드를 못했지만....
이제 시간적 여유가 생겼으니, 다시 정리해보도록 할게요.</p>
<p>본 포스팅에서는 최종 결과 및 발표 ppt와 관련한 내용을 정리할 예정입니다.
자세한 내용은 <a href="https://github.com/sehooni/Neural-Style-Transfer_tf">본인의 깃허브 repository</a>
에 업로드 해 두었습니다.</p>
<h1>Neural Style Transfer-tf</h1>
<p>opencv 및 tf.keras를 활용한 Neural Style Transfer 프로젝트.</p>
<h2>Processing in Project</h2>
<ul>
<li>프로젝트의 코드를 기존 코드와 비교.</li>
<li>최종 결과물 확인.</li>
</ul>
<h3>Code 비교 (<code>Neural_Style_Transfer.py</code>)</h3>
<p>기존의 <code>.ipymd</code>파일을 <code>.py</code>로 바꾸는 과정을 통해 변화를 준 부분이 존재 합니다.
우선 환경의 특성에 따라 main함수를 지정하여 주고 필요한 내용들은 미리 위에서 사전 정의해주게 됩니다.
타인이 본 코드를 사용할 때, 이미지들을 INPUT해주는 경로는 모두 상이할 수 있습니다.
따라서 정의해놓은 함수에 원하는 경로를 삽입하여주면 바로 작동하도록 새롭게 정의해놓았습니다.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131250-99e46527-ee45-433d-a4e7-7f4a4cf0a3da.png" alt="소스코드와 비교1"></p>
<p><img src="https://user-images.githubusercontent.com/84653623/176365710-8e31e48c-a3e7-427f-a5b1-ca8fe1112ddc.png" alt="소스코드와 비교2"></p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131466-e203a847-708e-4c1b-b027-3ec6f0371cb0.png" alt="소스코드와 비교3"></p>
<h3>동영상 파일에 적용하기 (<code>Neural_Style_Video.py</code>)</h3>
<p>더 나아가 동영상 파일을 대상으로 하는 코드 또한 작성하였습니다.
이전 이미지처리 코드와의 큰 차이점은 역시 동영상을 대상으로 진행된다는 점입니다.
이때 OPENCV의 코드를 사용하게 됩니다.</p>
<p>동영상은 결국 이미지 사진의 연속으로 만들어지게 됩니다.
본 코드의 실행과정 중 나오는 이미지 사진들을 살펴보면 frame별로 사진이 저장되어 있음을 확인할 수 있습니다.</p>
<p>기존 이미지 처리 코드와 동일하게 <code>if __name__ == __main__:</code>을 통해 정의해놓은 함수를 불러오고, 사전 정의해놓은 함수들의 input에 맞게 경로를 입력하여 주시면 되겠습니다.
<img src="https://user-images.githubusercontent.com/84653623/176131541-797e4638-e06b-436a-97df-ef6c1ba35aed.png" alt="동영상 파일에 적용"></p>
<p>본 프로젝트를 진행하면서 직면한 대표적인 문제는 다음과 같습니다.
예를 들자면, 198, 199 다음 2, 200, 201과 같이 프레임의 순서가 순차적으로 들어가지 않아 동영상을 생성했을 때 매끄럽지 못하고 튀는 듯한 양상을 보인 것입니다.
원인을 살펴보자면, 프레임은 제대로 추출하였으나, 이를 인간이 아는 숫자 순번이 아닌, 컴퓨터의 순차적인 순번으로(위에서 든 예시와 같이) 불러왔기 때문이었습니다.</p>
<p>이러한 문제는 아래 사진의 네모 코드와 같이 순서를 재 정렬하므로서 해결할 수 있었습니다.
프레임을 추출한 뒤 이 코드를 한번 실행하여 줌으로서, 스타일 변환된 사진들을 일차적으로 재정렬시킵니다.
이후 이 프레임들을 합쳐 영상을 제작하는 과정에서도 한번 더 삽입하여 줌으로서 영상이 튀지 않고 순차적으로 재생하도록 재정렬하였습니다.
<img src="https://user-images.githubusercontent.com/84653623/176131642-01022619-70c4-4107-a74d-5f2a614a5397.png" alt="동영상 파일에 적용2"></p>
<h3>Results</h3>
<p>마지막 결과물을 확인하여 보면 다음과 같습니다.
이미지 처리의 경우, 총 두 번, 다른 사진을 이용하여  진행하였습니다. 저작권을 지키며 공개된 사진 및 본인이 직접 촬영한 이미지와 영상을 사용하였음을 알려드립니다! :)</p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131743-829acc9d-b096-4b68-ae53-22d5ad56676a.png" alt="Results1">
왼쪽이 원본사진으로 여러분들께서 흔히 아시는 에펠탑 사진이며, 오른쪽이 이미지 스타일 사진으로 창조의 기둥으로 명명된 성운 사진입니다.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131840-18433d00-6d2a-438f-b2a2-0b68700df164.png" alt="Results2">
두 번째로 사용한 사진으로 왼쪽이 원본인 남산타워 사진이고, 오른쪽이 이미지 스타일 사진으로 반고흐 작가의 '별이 빛나는 밤에' 입니다.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131892-cf631a81-eb9e-4fe6-ad51-8771e94812d2.png" alt="Results3">
본 프로젝트를 통해 위와 같은 결과들을 얻을 수 있었습니다.
어쩌면 화가의 역할을 이제는 컴퓨터가, 인공지능 모델이 대체할 수도 있겠다는 생각이 들었습니다.
원하는 원본 사진과 함께 원하는 그림 스타일만 넣으면 이와 같이 출력되기 때문입니다.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/176131944-0b3efa54-32cc-4799-86b0-9b6f1f27bbff.png" alt="Results4">
동영상의 경우, 왼쪽이 원본(제가 직접 촬영한), 오른쪽이 변환된 영상입니다.
블로그 특성상 repo에 업로드된 ppt를 통해 확인할 수 있을 것으로 예상됩니다.</p>
<p>이와 비슷하게 DALL-E라는 인공지능 모델은 아예 획기적으로 문장, 즉 글을 제시하면 새로운 이미지를 생성한다고 합니다.
논문 리뷰를 통해 본인 또한 공부해볼 예정입니다.</p>
<p>이처럼 영상처리, 이미지 처리 분야는 인공지능의 발전과 더불어 대표적인 기법으로서 수많은 연구와 적용이 진행되고 있습니다.
본 프로젝트는 그러한 발전의 기반이 되는 논문을 바탕으로 진행되었고, 코드를 구현하고 재구성하는 과정을 통해서 저 또한 많은 것을 배운 것 같습니다.</p>
<h2>Reference</h2>
<p>본 repository는 Opencv 기법 및 tf.keras가 적용된 'Neural-Style-Transfer' project입니다.
원본 코드 또한 본 repo에 같이 업로드 해 놓았음을 알려드립니다.</p>
<h3>In this file, I use these photos.</h3>
<ul>
<li>Effel Tower smogy january evening-By Siren.Com [CC BY-SA 3.0(<a href="https://creativecommons.org/licenses/by-sa/3.0/">https://creativecommons.org/licenses/by-sa/3.0/</a>)], from <a href="https://commons.wikimedia.org/wiki/File:Effel_Tower_smogy_january_evening.jpg">Wikimedia Commons</a></li>
<li>Image of Pillars of Creation by NASA, ESA, and the Hubble Heritage Team, <a href="https://en.wikipedia.org/wiki/File:Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg">Public Domain</a></li>
<li>Arbre en fleur, Gustave Caillebotte,1882-By lbex73 [CC BY-SA 4.0(<a href="https://creativecommons.org/licenses/by-sa/4.0/">https://creativecommons.org/licenses/by-sa/4.0/</a>)], from <a href="https://commons.wikimedia.org/wiki/File:Arbre_en_fleur,_Gustave_Caillebotte,_1882.jpg">Wikimedia Commons</a></li>
<li>Image of Starry Night by Vincent van Gogh <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg">Public domain</a></li>
<li>The Tower of Namsan (photo by myself)</li>
</ul>
<h3>PAPER</h3>
<ul>
<li><a href="https://arxiv.org/abs/1508.06576">A Neural Algorithm of Artistic Style.2015</a> 에서 제시된 Mechanism을 이용하여 본 프로젝트를 진행한다.</li>
</ul>
<h1>글을 마무리하며</h1>
<p>PS. 추가 문의사항 및 질문은 환영합니다. 그를 통해 저도 더 성장할 수 있을테니까요. 긴 글 읽어주셔서 감사합니다.</p>
5:["$","div",null,{"className":"relative","children":[["$","article",null,{"className":"prose prose-lg dark:prose-invert max-w-none","children":[["$","header",null,{"className":"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8","children":[["$","div",null,{"className":"mb-4 text-sm text-gray-500 flex items-center space-x-2","children":[[["$","$Le",null,{"href":"/category/neural_style_transfer","className":"font-medium text-blue-600 hover:underline","children":"Neural_Style_Transfer"}],["$","span",null,{"children":"•"}]],["$","time",null,{"children":"2022-06-29"}]]}],["$","h1",null,{"className":"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4","children":"[Neural Style Transfer] Neural Style Transfer 프로젝트 Results"}]]}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$19"}}]]}],"$L1a"]}]
1b:I[50718,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],"default"]
1a:["$","$L1b",null,{}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
1c:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
c:[["$","title","0",{"children":"[Neural Style Transfer] Neural Style Transfer 프로젝트 Results"}],["$","meta","1",{"name":"description","content":"tf를 활용한 Neural Style Transfer 구현 및 응용"}],["$","link","2",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L1c","3",{}]]
8:null

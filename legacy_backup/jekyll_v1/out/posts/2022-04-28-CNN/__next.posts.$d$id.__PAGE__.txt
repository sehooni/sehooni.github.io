1:"$Sreact.fragment"
2:I[22016,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],""]
7:I[50718,["/_next/static/chunks/796e69ae18b2784c.js","/_next/static/chunks/a8f82a9835eb887b.js"],"default"]
8:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
9:"$Sreact.suspense"
3:Tf9d,<p>봄이 어느덧 지나가고, 중간고사 기간이 빠르게 찾아왔다.
linear regression 이후 CNN에 대해 살펴보자.
본 포스팅에서는 <strong>Pytorch</strong> 를 이용하여 실행하게 된다.</p>
<h1>CNN Implementation</h1>
<p>다음 그림과 같은 모양으로 CNN 학습을 진행한다.</p>
<p>##그림 1. CNN Implementation
<img src="https://user-images.githubusercontent.com/84653623/163127806-018be86d-286a-4fdf-b773-4d85b1b75214.png" alt="cnn implementation"></p>
<p>이때의 코드는 다음과 같다.
import torch
import torch.nn as nn</p>
<pre><code>input = torch.Tensor(1, 1, 28, 28)
conv1 = nn.Conv2d(1, 5, 5)
pool - nn.MaxPool2d(2)

out = conv1(input)
out2 = pool(out)

out.size()
out2.size()
</code></pre>
<p>이와 관련된 코드는 <a href="https://github.com/sehooni/ML-Pytorch/blob/master/CNN/CNN%20Implementation/example.py">example.py</a>에서 확인할 수 있다.</p>
<p>그렇다면 위에 명시된 코드 <code>nn.Conv2d</code>와 <code>nn.MaxPool2d</code>는 무엇이며 어떠한 방식으로 진행이 될까?</p>
<h1>CNN pytorch 관련 내용</h1>
<h2>Pytorch nn.Conv2d</h2>
<pre><code>conv = torch.nn.Conv2d(in_channels=, out_channels=, kernel_size=,
             stride = 1, padding=0, dilation=1, groups=1,bias=True)
</code></pre>
<p>이때 <code>stride, padding, dilation, groups</code> 는 default value이다.</p>
<p>ex) 입력채널 1 / 출력채널 1 / 커널크기 3*3
conv = nn.Conv2d(1, 1, 3)</p>
<p>input type : torch.Tensor
input shape : (N * C * H * W)
(batch_size, channel, height, width)</p>
<h3>Output Volume Caculations</h3>
<pre><code>Output size = (input size - filter size + (2 * padding))/stride + 1
</code></pre>
<p>다음 예제들을 수기로 풀면 다음과 같다.</p>
<h4>예제 1)</h4>
<pre><code>input image size : 227 * 227
filter size : 11 * 11
stride = 4
padding = 0
output image size = ?
공식에 따라 계산하면 (227-11+2*0)/4 + 1 = 55
                    55 * 55
</code></pre>
<h4>예제 2)</h4>
<pre><code>input image size : 64 * 64
filter size : 7 * 7
stride = 2
padding = 0
output image size = ?
공식에 따라 계산하면 (64-7+2*0)/2 + 1 = 29.5 = 29
                    29 * 29
</code></pre>
<h4>예제 3)</h4>
<pre><code>input image size : 32 * 32
filter size : 5 * 5
stride = 1
padding = 2
output image size = ?
공식에 따라 계산하면 (32-5+2*2)/1 + 1 = 32
                    32 * 32
</code></pre>
<h4>예제 4)</h4>
<pre><code>input image size : 32 * 64
filter size : 5 * 5
stride = 1
padding = 0
output image size = ?
공식에 따라 계산하면 (32-5+2*0)/1 + 1 = 28, (64-5+2*0)/1 + 1 = 60
                    28 * 60
</code></pre>
<h4>예제 5)</h4>
<pre><code>input image size : 64 * 32
filter size : 3 * 3
stride = 1
padding = 1
output image size = ?
공식에 따라 계산하면 (64-3+2*1)/1 + 1 = 64, (32-3+2*1)/1 + 1 = 32
                    64 * 32
</code></pre>
<p>위 예제들을 pytorch를 이용하여 계산할 수 있다.
<a href="https://github.com/sehooni/ML-Pytorch/blob/master/CNN/Conv/Pytorch_nn_Conv2d.py">Pytorch_nn_Conv2d.py</a>에서 확인 가능하다.</p>
<h2>Pytorch nn.Conv2d</h2>
<pre><code>max_pool = torch.nn.MaxPool2d(kernel_size=,
             stride = None, padding=0, dilation=1, return_indices = False,ceil_mode=False)
</code></pre>
<p>이때 <code>stride, padding, dilation, return_indices, ceil_mode</code> 는 default value이다.</p>
<hr>
<h1>글을 요약하자면..</h1>
<h2>결국 CNN에서는 기존 Perceptron과 Multi-layer-Perceptron과 달리 Convolution layer와 Pooling layer가 추가되었다는 점에서 차이를 보인다.
이를 통해 계산 시간은 단축이 되었으며, 매개변수를 구하는 과정이 단축됨에 따라 용량도 줄었다는 장점을 가진다.</h2>
<p>이번 기회를 통해 수업내용도 정리하고 코드 적용도 학습해보았다.
이후 관련 논문과 코드구현 내용도 업로드 예정이니 많은 관심 부탁드리며.. 글을 마무리해본다.</p>
0:{"buildId":"oAIH0-g3w6LOdbw_0qDiA","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"relative","children":[["$","article",null,{"className":"prose prose-lg dark:prose-invert max-w-none","children":[["$","header",null,{"className":"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8","children":[["$","div",null,{"className":"mb-4 text-sm text-gray-500 flex items-center space-x-2","children":[[["$","$L2",null,{"href":"/category/ml","className":"font-medium text-blue-600 hover:underline","children":"ML"}],["$","span",null,{"children":"•"}]],["$","time",null,{}]]}],["$","h1",null,{"className":"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4","children":"[ML] CNN 정리(Conv2d, MaxPool2d)"}]]}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$3"}}]]}],"$L4"]}],["$L5"],"$L6"]}],"loading":null,"isPartial":false}
4:["$","$L7",null,{}]
5:["$","script","script-0",{"src":"/_next/static/chunks/a8f82a9835eb887b.js","async":true}]
6:["$","$L8",null,{"children":["$","$9",null,{"name":"Next.MetadataOutlet","children":"$@a"}]}]
a:null

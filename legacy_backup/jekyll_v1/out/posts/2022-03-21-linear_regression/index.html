<!DOCTYPE html><!--oAIH0_g3w6LOdbw_0qDiA--><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/8fa8e9b5e3e9b2cd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/cbd55ab9639e1e66.js"/><script src="/_next/static/chunks/1abc3924204d7dd0.js" async=""></script><script src="/_next/static/chunks/9c23f44fff36548a.js" async=""></script><script src="/_next/static/chunks/5944084dd90310d5.js" async=""></script><script src="/_next/static/chunks/turbopack-aeaf7046609aeecd.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/_next/static/chunks/a8f82a9835eb887b.js" async=""></script><title>[ML] Linear Regression 정리</title><meta name="description" content="Linear Regression"/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen"><div hidden=""><!--$--><!--/$--></div><aside class="w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block"><div class="mb-8"><h1 class="text-2xl font-bold font-sans tracking-tight"><a href="/">Sehoon&#x27;s Workspace</a></h1><p class="text-sm text-gray-500 mt-2">Tech &amp; Study Blog</p></div><nav class="space-y-8"><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Menu</h3><ul class="space-y-1"><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/">Recent Posts</a></li><li><a class="block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm" href="/about/">About</a></li></ul></div><div><h3 class="text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2">Categories</h3><ul class="space-y-1"><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/proteomics/"><span>proteomics</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->9<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/nlp/"><span>NLP</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->6<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/blog/"><span>Blog</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->5<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jetson/"><span>Jetson</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/paperreview/"><span>PaperReview</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->4<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/neural_style_transfer/"><span>Neural_Style_Transfer</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->3<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/jekyll/"><span>jekyll</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/ml/"><span>ML</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->2<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/algorithms/"><span>algorithms</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/contest/"><span>Contest</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/capstone/"><span>Capstone</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/linux/"><span>Linux</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/etc/"><span>ETC</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/datastructure/"><span>DataStructure</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li><li><a class="flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm" href="/category/dl/"><span>DL</span><span class="text-xs text-gray-400 group-hover:text-blue-500 font-mono">(<!-- -->1<!-- -->)</span></a></li></ul></div></nav><div class="mt-8 pt-8 border-t border-gray-200 dark:border-gray-800"><div class="flex space-x-4"></div></div></aside><main class="flex-1 min-w-0"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10"><div class="relative"><article class="prose prose-lg dark:prose-invert max-w-none"><header class="mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8"><div class="mb-4 text-sm text-gray-500 flex items-center space-x-2"><a class="font-medium text-blue-600 hover:underline" href="/category/ml/">ML</a><span>•</span><time></time></div><h1 class="text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4">[ML] Linear Regression 정리</h1></header><div><p>학교 수업으로 타학과 전공인 '인공지능과 딥러닝'을 수강하게 되었다.
오일석 교수님의 [Machine Learning 기계학습] 을 기반으로 진행되는 강의이다.</p>
<p>Perceptron을 설명하면서 Linear regression을 직접 코딩을 통해 실습하는 시간을 가졌는데, 아래의 내용은 그 실습 내용을 정리한 것이다.</p>
<h1>Linear regression</h1>
<p>Author: Seungjae Lee(이승재)</p>
<p>모두를 위한 딥러닝을 참고하였습니다.</p>
<h2>Theoretical Overview</h2>
<p>$ H(x) = Wx + b $</p>
<p>$ cost(W, b) = \frac{1}{m} \sum^m_{i=1} \left( H(x^{(i)}) - y^{(i)} \right)^2 $</p>
<ul>
<li>$H(x)$: 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가</li>
<li>$cost(W, b)$: $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가</li>
</ul>
<h2>Import</h2>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
</code></pre>
<h2>For reproducibility</h2>
<pre><code>torch.manual_seed(1)
</code></pre>
<h2>Data</h2>
<p>다음 예제를 위해 예시 데이터를 사용하여보자.
(We will use fake data for this example.)</p>
<pre><code>x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[1], [2], [3]])
print(x_train)
print(x_train.shape)
print(y_train)
print(y_train.shape)
</code></pre>
<p>기본적으로 Pytorch는 NCHW 형태이다.</p>
<h2>Weight Initialization</h2>
<pre><code>W = torch.zeros(1, requires_grad=True)
print(W)
b = torch.zeros(1, requires_grad=True)
print(b)
</code></pre>
<h2>Hypothesis</h2>
<p>$ H(x) = Wx + b $</p>
<pre><code>hypothesis = x_train * W + b
print(hypothesis)
</code></pre>
<h2>Cost</h2>
<p>$ cost(W, b) = \frac{1}{m} \sum^m_{i=1} \left( H(x^{(i)}) - y^{(i)} \right)^2 $</p>
<pre><code>print(hypothesis)
print(y_train)
print(hypothesis - y_train)
print((hypothesis - y_train) ** 2)
cost = torch.mean((hypothesis - y_train) ** 2)
print(cost)
</code></pre>
<h2>Gradient Descent</h2>
<pre><code>optimizer = optim.SGD([W, b], lr = 0.01)
optimizer.zero_grad()
cost.backward()
optimizer.step()
print(W)
print(b)
</code></pre>
<p>가설이 잘 작동하는지 확인하여 보자.
(Let's check if the hypothesis is now better.)</p>
<pre><code>hypothesis = x_train * W + b
print(hypothesis)
cost = torch.mean((hypothesis - y_train) ** 2)
print(cost)
</code></pre>
<h2>Training with Full Code</h2>
<p>In reality, we will be training on the dataset for multiple epochs. This can be done simply with loops.</p>
<pre><code># 데이터
x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[1], [2], [3]])

# 모델 초기화
W = torch.zeros(1, requires_grad=True)
b = torch.zeros(1, requires_grad=True)

# optimizer 설정
optimizer = optim.SGD([W, b], lr = 0.01)

nb_epochs = 1000
for epoch in range(nb_epochs + 1):
        
    # H(x) 계산
    hypothesis = x_train * W + b
        
    # cost 계산
    cost = torch.mean((hypothesis - y_train) ** 2)
        
    # cost로 H(x) 개선
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()
        
    # 100번마다 로그 출력
    if epoch % 100 == 0:
        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(
                epoch, nb_epochs, W.item(), b.item(), cost.item()
        ))
</code></pre>
<h2>High-level implementaion with <code>nn.Module</code></h2>
<p>Remember that we had this fake data.</p>
<pre><code>x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[1], [2], [3]])
</code></pre>
<h3>이제 linear regression 모델을 만들면 되는데, 기본적으로 Pytorch의 모든 모델은 제공되는 <code>nn.Module</code>을 inherit 해서 만들게 된다.</h3>
<pre><code>class LinearRegressionModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(1, 1)
        
    def forward(self, x):
        return self.linear(x)
</code></pre>
<h3>모델의 <code>__init__</code>에서는 사용할 레이어들을 정의하게 된다. 여기서 우리는 linear regression 모델을 만들기 때문에, <code>nn.Linear</code>를 이용할 것이다. 그리고 <code>forward</code>에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려준다.</h3>
<pre><code>model = LinearRegressionModel()
</code></pre>
<h2>Hypothesis</h2>
<p>이제 모델을 생성해서 예측값 <em>H(x)</em> 를 구해보자</p>
<pre><code>hypothesis = model(x_train)
print(hypothesis)
</code></pre>
<h2>Cost</h2>
<p>이제 mean squared error (MSE)로 cost를 구해보자. MSE 역시 PyTorch에서 기본적으로 제공한다.</p>
<pre><code>print(hypothesis)
print(y_train)
cost = F.mse_loss(hypothesis, y_train)
print(cost)
</code></pre>
<h2>Gradient Descent</h2>
<p>마지막 주어진 cost를 이용해 <em>H(x)</em> 의 <em>W</em> , <em>b</em> 를 바꾸어서 cost를 줄여봅시다. 이때 PyTorch의 <code>torch.optim</code>에 있는 <code>optimizer</code>들 중 하나를 사용할 수 있다.</p>
<pre><code>optimizer = optim.SGD(model.parameters(), lr=0.01)
optimizer.zero_grad()
cost.backward()
optimizer.step()
</code></pre>
<h2>Training with Full Code</h2>
<p>이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 피팅하여보자.</p>
<pre><code># 데이터
x_train = torch.FloatTensor([[1], [2], [3]])
y_train = torch.FloatTensor([[1], [2], [3]])

# 모델 초기화
model = LinearRegressionModel()

# optimizer 설정
optimizer = optim.SGD(model.parameters(), lr=0.01)

nb_epochs = 1000
for epoch in range(nb_epochs + 1):
    
    # H(x) 계산
    prediction = model(x_train)
        
    # cost 계산
    cost = F.mse_loss(prediction, y_train)
        
    # cost로 H(x) 개선
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()
        
    # 100번 마다 로그 출력
    if epoch % 100 == 0:
        params = list(model.parameters())
        W = params[0].item()
        b = params[1].item()
        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(
            epoch, nb_epochs, W, b, cost.item()
        ))
    
</code></pre>
<p>점점 <em>H(x)</em> 의 <em>W</em> 와 <em>b</em> 를 조정해서 cost가 줄어드는 것을 볼 수 있다.</p>
</div></article></div><!--$--><!--/$--></div></main><script src="/_next/static/chunks/cbd55ab9639e1e66.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"oAIH0-g3w6LOdbw_0qDiA\",\"c\":[\"\",\"posts\",\"2022-03-21-linear_regression\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"id\",\"2022-03-21-linear_regression\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/8fa8e9b5e3e9b2cd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased bg-white dark:bg-black text-gray-900 dark:text-white flex min-h-screen\",\"children\":[\"$L2\",[\"$\",\"main\",null,{\"className\":\"flex-1 min-w-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-10\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/a8f82a9835eb887b.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"2:[\"$\",\"aside\",null,{\"className\":\"w-64 h-screen sticky top-0 bg-gray-50 dark:bg-gray-900 border-r border-gray-200 dark:border-gray-800 p-6 overflow-y-auto hidden lg:block\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-2xl font-bold font-sans tracking-tight\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"Sehoon's Workspace\"}]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-500 mt-2\",\"children\":\"Tech \u0026 Study Blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"space-y-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Menu\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"Recent Posts\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/about\",\"className\":\"block py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors text-sm\",\"children\":\"About\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-xs font-semibold text-gray-400 uppercase tracking-wider mb-2\",\"children\":\"Categories\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-1\",\"children\":[[\"$\",\"li\",\"proteomics\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/proteomics\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"proteomics\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",9,\")\"]}]]}]}],[\"$\",\"li\",\"NLP\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/nlp\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"NLP\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",6,\")\"]}]]}]}],[\"$\",\"li\",\"Blog\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/blog\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Blog\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",5,\")\"]}]]}]}],[\"$\",\"li\",\"Jetson\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jetson\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Jetson\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"PaperReview\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/paperreview\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"PaperReview\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",4,\")\"]}]]}]}],[\"$\",\"li\",\"Neural_Style_Transfer\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/neural_style_transfer\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Neural_Style_Transfer\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",3,\")\"]}]]}]}],[\"$\",\"li\",\"jekyll\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/jekyll\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"jekyll\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]]}]}],[\"$\",\"li\",\"ML\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/ml\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[\"$Lf\",\"$L10\"]}]}],\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\"]}]]}]]}],\"$L18\"]}]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"span\",null,{\"children\":\"ML\"}]\n10:[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",2,\")\"]}]\n11:[\"$\",\"li\",\"algorithms\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/algorithms\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"algorithms\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n12:[\"$\",\"li\",\"Contest\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/contest\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Contest\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n13:[\"$\",\"li\",\"Capstone\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/capstone\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Capstone\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n14:[\"$\",\"li\",\"Linux\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/linux\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"Linux\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n15:[\"$\",\"li\",\"ETC\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/etc\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"ETC\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n16:[\"$\",\"li\",\"DataStructure\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/datastructure\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DataStructure\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n17:[\"$\",\"li\",\"DL\",{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/category/dl\",\"className\":\"flex items-center justify-between py-1.5 text-gray-700 dark:text-gray-300 hover:text-blue-600 transition-colors group text-sm\",\"children\":[[\"$\",\"span\",null,{\"children\":\"DL\"}],[\"$\",\"span\",null,{\"className\":\"text-xs text-gray-400 group-hover:text-blue-500 font-mono\",\"children\":[\"(\",1,\")\"]}]]}]}]\n18:[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-200 dark:border-gray-800\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex space-x-4\"}]}]\n"])</script><script>self.__next_f.push([1,"19:T1838,"])</script><script>self.__next_f.push([1,"\u003cp\u003e학교 수업으로 타학과 전공인 '인공지능과 딥러닝'을 수강하게 되었다.\n오일석 교수님의 [Machine Learning 기계학습] 을 기반으로 진행되는 강의이다.\u003c/p\u003e\n\u003cp\u003ePerceptron을 설명하면서 Linear regression을 직접 코딩을 통해 실습하는 시간을 가졌는데, 아래의 내용은 그 실습 내용을 정리한 것이다.\u003c/p\u003e\n\u003ch1\u003eLinear regression\u003c/h1\u003e\n\u003cp\u003eAuthor: Seungjae Lee(이승재)\u003c/p\u003e\n\u003cp\u003e모두를 위한 딥러닝을 참고하였습니다.\u003c/p\u003e\n\u003ch2\u003eTheoretical Overview\u003c/h2\u003e\n\u003cp\u003e$ H(x) = Wx + b $\u003c/p\u003e\n\u003cp\u003e$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$H(x)$: 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가\u003c/li\u003e\n\u003cli\u003e$cost(W, b)$: $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eImport\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eFor reproducibility\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003etorch.manual_seed(1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eData\u003c/h2\u003e\n\u003cp\u003e다음 예제를 위해 예시 데이터를 사용하여보자.\n(We will use fake data for this example.)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ex_train = torch.FloatTensor([[1], [2], [3]])\ny_train = torch.FloatTensor([[1], [2], [3]])\nprint(x_train)\nprint(x_train.shape)\nprint(y_train)\nprint(y_train.shape)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e기본적으로 Pytorch는 NCHW 형태이다.\u003c/p\u003e\n\u003ch2\u003eWeight Initialization\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eW = torch.zeros(1, requires_grad=True)\nprint(W)\nb = torch.zeros(1, requires_grad=True)\nprint(b)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eHypothesis\u003c/h2\u003e\n\u003cp\u003e$ H(x) = Wx + b $\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehypothesis = x_train * W + b\nprint(hypothesis)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCost\u003c/h2\u003e\n\u003cp\u003e$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eprint(hypothesis)\nprint(y_train)\nprint(hypothesis - y_train)\nprint((hypothesis - y_train) ** 2)\ncost = torch.mean((hypothesis - y_train) ** 2)\nprint(cost)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eGradient Descent\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eoptimizer = optim.SGD([W, b], lr = 0.01)\noptimizer.zero_grad()\ncost.backward()\noptimizer.step()\nprint(W)\nprint(b)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e가설이 잘 작동하는지 확인하여 보자.\n(Let's check if the hypothesis is now better.)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehypothesis = x_train * W + b\nprint(hypothesis)\ncost = torch.mean((hypothesis - y_train) ** 2)\nprint(cost)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eTraining with Full Code\u003c/h2\u003e\n\u003cp\u003eIn reality, we will be training on the dataset for multiple epochs. This can be done simply with loops.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# 데이터\nx_train = torch.FloatTensor([[1], [2], [3]])\ny_train = torch.FloatTensor([[1], [2], [3]])\n\n# 모델 초기화\nW = torch.zeros(1, requires_grad=True)\nb = torch.zeros(1, requires_grad=True)\n\n# optimizer 설정\noptimizer = optim.SGD([W, b], lr = 0.01)\n\nnb_epochs = 1000\nfor epoch in range(nb_epochs + 1):\n        \n    # H(x) 계산\n    hypothesis = x_train * W + b\n        \n    # cost 계산\n    cost = torch.mean((hypothesis - y_train) ** 2)\n        \n    # cost로 H(x) 개선\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n        \n    # 100번마다 로그 출력\n    if epoch % 100 == 0:\n        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n                epoch, nb_epochs, W.item(), b.item(), cost.item()\n        ))\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eHigh-level implementaion with \u003ccode\u003enn.Module\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eRemember that we had this fake data.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ex_train = torch.FloatTensor([[1], [2], [3]])\ny_train = torch.FloatTensor([[1], [2], [3]])\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e이제 linear regression 모델을 만들면 되는데, 기본적으로 Pytorch의 모든 모델은 제공되는 \u003ccode\u003enn.Module\u003c/code\u003e을 inherit 해서 만들게 된다.\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eclass LinearRegressionModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(1, 1)\n        \n    def forward(self, x):\n        return self.linear(x)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e모델의 \u003ccode\u003e__init__\u003c/code\u003e에서는 사용할 레이어들을 정의하게 된다. 여기서 우리는 linear regression 모델을 만들기 때문에, \u003ccode\u003enn.Linear\u003c/code\u003e를 이용할 것이다. 그리고 \u003ccode\u003eforward\u003c/code\u003e에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려준다.\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003emodel = LinearRegressionModel()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eHypothesis\u003c/h2\u003e\n\u003cp\u003e이제 모델을 생성해서 예측값 \u003cem\u003eH(x)\u003c/em\u003e 를 구해보자\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehypothesis = model(x_train)\nprint(hypothesis)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eCost\u003c/h2\u003e\n\u003cp\u003e이제 mean squared error (MSE)로 cost를 구해보자. MSE 역시 PyTorch에서 기본적으로 제공한다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eprint(hypothesis)\nprint(y_train)\ncost = F.mse_loss(hypothesis, y_train)\nprint(cost)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eGradient Descent\u003c/h2\u003e\n\u003cp\u003e마지막 주어진 cost를 이용해 \u003cem\u003eH(x)\u003c/em\u003e 의 \u003cem\u003eW\u003c/em\u003e , \u003cem\u003eb\u003c/em\u003e 를 바꾸어서 cost를 줄여봅시다. 이때 PyTorch의 \u003ccode\u003etorch.optim\u003c/code\u003e에 있는 \u003ccode\u003eoptimizer\u003c/code\u003e들 중 하나를 사용할 수 있다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eoptimizer = optim.SGD(model.parameters(), lr=0.01)\noptimizer.zero_grad()\ncost.backward()\noptimizer.step()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eTraining with Full Code\u003c/h2\u003e\n\u003cp\u003e이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 피팅하여보자.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# 데이터\nx_train = torch.FloatTensor([[1], [2], [3]])\ny_train = torch.FloatTensor([[1], [2], [3]])\n\n# 모델 초기화\nmodel = LinearRegressionModel()\n\n# optimizer 설정\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nnb_epochs = 1000\nfor epoch in range(nb_epochs + 1):\n    \n    # H(x) 계산\n    prediction = model(x_train)\n        \n    # cost 계산\n    cost = F.mse_loss(prediction, y_train)\n        \n    # cost로 H(x) 개선\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n        \n    # 100번 마다 로그 출력\n    if epoch % 100 == 0:\n        params = list(model.parameters())\n        W = params[0].item()\n        b = params[1].item()\n        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n            epoch, nb_epochs, W, b, cost.item()\n        ))\n    \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e점점 \u003cem\u003eH(x)\u003c/em\u003e 의 \u003cem\u003eW\u003c/em\u003e 와 \u003cem\u003eb\u003c/em\u003e 를 조정해서 cost가 줄어드는 것을 볼 수 있다.\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"relative\",\"children\":[[\"$\",\"article\",null,{\"className\":\"prose prose-lg dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-10 not-prose border-b border-gray-100 dark:border-gray-800 pb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 text-sm text-gray-500 flex items-center space-x-2\",\"children\":[[[\"$\",\"$Le\",null,{\"href\":\"/category/ml\",\"className\":\"font-medium text-blue-600 hover:underline\",\"children\":\"ML\"}],[\"$\",\"span\",null,{\"children\":\"•\"}]],[\"$\",\"time\",null,{\"children\":\"$undefined\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-extrabold tracking-tight text-gray-900 dark:text-white mb-4\",\"children\":\"[ML] Linear Regression 정리\"}]]}],[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}]]}],\"$L1a\"]}]\n"])</script><script>self.__next_f.push([1,"1b:I[50718,[\"/_next/static/chunks/796e69ae18b2784c.js\",\"/_next/static/chunks/a8f82a9835eb887b.js\"],\"default\"]\n1a:[\"$\",\"$L1b\",null,{}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1c:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"[ML] Linear Regression 정리\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Linear Regression\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1c\",\"3\",{}]]\n8:null\n"])</script></body></html>
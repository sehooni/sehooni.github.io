<!DOCTYPE html><!--8lJiHtAmlyU3nNFMbG8_k--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png" as="image"/><link rel="stylesheet" href="/_next/static/chunks/2f40a2027cd59172.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/b9ef641e76e3a351.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/475fa0f5a019bf38.js"/><script src="/_next/static/chunks/aa5e9022907a8769.js" async=""></script><script src="/_next/static/chunks/42fbd80a90fec4a2.js" async=""></script><script src="/_next/static/chunks/5cdb1f5564fc8217.js" async=""></script><script src="/_next/static/chunks/turbopack-f5bb12e1c2d48879.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/865c404e1d9a0c65.js" async=""></script><script src="/_next/static/chunks/6b8d09032578b975.js" async=""></script><title>Sehoon&#x27;s Workspace</title><meta name="description" content="Welcome to my page!"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="min-h-screen flex flex-col font-sans"><div hidden=""><!--$--><!--/$--></div><div class="flex gap-10"><article class="flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none"><header class="mb-8 not-prose border-b pb-8"><h1 class="text-4xl font-bold mb-4">[NLP] 문서 분류 모델 실전 투입</h1><div class="flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400"><time dateTime="Sat Mar 26 2022 09:00:00 GMT+0900 (대한민국 표준시)">March 26, 2022</time></div></header><p>자, 그럼 학습을 마친 모델을 어떻게 사용할까?</p>
<p>본 파일은 이기창님의 &#x27;Do it! 자연어 처리&#x27;에 기초하여 작성되었다! :)</p>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">학습 마친 모델을 실전 투입하기</h1>
<p>이번 실습에서는 <strong>학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다</strong>.</p>
<p>문장을 받아 해당 문장이 긍정인지 부정인지 답변하는 웹 서비스로, 문장을 토큰화한 뒤 모델 입력값으로 만들고 이를 모델에 입력해 [<em>해당 문장이 긍정일 확률, 해당 문장이 부정일 확률</em> ]을 계산하게 만든다. 이후 약간의 후처리 과정을 거쳐 응답하게 만드는 방식이다.</p>
<p>웹 서비스란 네트워크에서 컴퓨터 간에 상호작용을 하기 위해 만들어진 소프트웨어 시스템이다. 본 노트에서는 원격 사용자가 보낸 문장을 수신해 해당 문장이 긍정인지 부정인지 응답을 만들고 이 응답을 원격 사용자에게 전달하는 웹 서비스를 만드는 것이다.</p>
<h2 id="1" class="text-2xl font-bold mt-8 mb-4">1. 환경 설정하기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">의존성 패키지 설치</h3>
<p>pip 명령어를 통해 의존성 있는 패키지를 설치한다.</p>
<h4>code 2-0</h4>
<pre><code class="hljs language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: Korpora&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: flask-ngrok&gt;=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: torch&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: flask&gt;=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: flask-cors&gt;=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: fsspec[http]&gt;=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2022.2.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (21.3)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.3.0)
Requirement already satisfied: tensorboard!=2.5.0,&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2.8.0)
Requirement already satisfied: PyYAML&lt;=5.4.1,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (5.4.1)
Requirement already satisfied: torchmetrics&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.7.2)
Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (4.62.3)
Requirement already satisfied: future&gt;=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.18.2)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (1.21.5)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2.23.0)
Requirement already satisfied: huggingface-hub&gt;=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.4.0)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.0.47)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (4.11.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2019.12.20)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (3.6.0)
Requirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.10.3)
Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (7.1.2)
Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.1.0)
Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.0.1)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors&gt;=3.0.10-&gt;ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&gt;=0.0.12-&gt;transformers==4.10.0-&gt;ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;flask&gt;=1.1.4-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses&gt;=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (0.6)
Requirement already satisfied: xlrd&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (1.24.3)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.6)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.35.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.43.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.17.3)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.37.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (57.4.0)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.3.6)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.6.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.8.1)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.2.4)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.8)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers==4.10.0-&gt;ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.2.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (21.4.0)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.2.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.7.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.13.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (6.0.2)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.0)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (2.0.12)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.0.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==4.10.0-&gt;ratsnlp) (1.1.0)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">구글 드라이브 연동</h3>
<p>모델 체크포인트는 구글 드라이브에 저장해 두었다. 코랩 노트북과 자신의 구글 드라이브를 연동한다.</p>
<h4>code 2-1</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">&#x27;/gdrive&#x27;</span>, force_remount=<span class="hljs-literal">True</span>)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">인퍼런스 설정</h3>
<p>각종 인자( 모델 하이퍼파라미터(hyperparameter)와 저장 위치 등 )를 설정한다.</p>
<h4>code 2-2</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> ClassificationDeployArguments
args = ClassificationDeployArguments(
    pretrained_model_name=<span class="hljs-string">&quot;beomi/kcbert-base&quot;</span>,
    downstream_model_dir=<span class="hljs-string">&quot;/gdrive/My Drive/nlpbook/checkpoint-doccls&quot;</span>,
    max_seq_length=<span class="hljs-number">128</span>,
)
</code></pre>
<pre><code>downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.28.ckpt
</code></pre>
<p>각 인자의 역할과 내용은 다음과 같다.</p>
<ul>
<li><strong>pretrained_model_name</strong>: <code>training_section.ipynb</code>에서 적용한 <code>pretrained_model_name</code>(단, 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 한다.)</li>
<li><strong>downstream_model_dir</strong>:  <code>training_section.ipynb</code>에서 파인튜닝한 모델의 체크포인트 저장 위치(확장자가 <code>ckpt</code>인 파일이 하나 이상 있어야 한다.)</li>
<li><strong>max_seq_length</strong>: 토큰 기준 입력 문장 최대 길이. 아무것도 입력하지 않으면 128.</li>
</ul>
<h2 id="2" class="text-2xl font-bold mt-8 mb-4">2. 토크나이저 및 모델 불러오기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">토크나이저 로드</h3>
<p>code 2-3을 실행해 토크나이저를 초기화 한다.</p>
<h4>code 2-3</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=<span class="hljs-literal">False</span>,
)
</code></pre>
<pre><code>Downloading:   0%|          | 0.00/250k [00:00&lt;?, ?B/s]



Downloading:   0%|          | 0.00/49.0 [00:00&lt;?, ?B/s]



Downloading:   0%|          | 0.00/619 [00:00&lt;?, ?B/s]
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">체크포인트 로드</h3>
<p>code 2-4는 <code>training_section.ipynb</code>에서 파인튜닝한 모델의 체크포인트를 읽어들인다.</p>
<h4>code 2-4</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> torch
fine_tuned_model_ckpt = torch.load(
    args.downstream_model_checkpoint_fpath,
    map_location=torch.device(<span class="hljs-string">&quot;cpu&quot;</span>),
)
</code></pre>
<h3 id="b" class="text-xl font-bold mt-6 mb-3">BERT 설정 로드 및 BERT 모델 초기화</h3>
<p>code 2-5는 <code>training_section.ipynb</code>의 파인튜닝 때 사용한 <code>pretrained_model_name</code>에 해당하는 모델의 설정값들을 읽어들인다.</p>
<p>이어서 code 2-6을 실행하면 해당 설정값대로 <strong>BERT</strong> 모델을 초기화 한다.</p>
<h4>code 2-5</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=fine_tuned_model_ckpt[<span class="hljs-string">&quot;state_dict&quot;</span>][<span class="hljs-string">&quot;model.classifier.bias&quot;</span>].shape.numel(),
)
</code></pre>
<h4>code 2-6</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertForSequenceClassification
model = BertForSequenceClassification(pretrained_model_config)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">체크포인트 주입하기</h3>
<p>code 2-7은 초기화한 <strong>BERT</strong>모델에 체크포인트(fine_tuned_model_ckpt)를 주입한다.</p>
<h4>code 2-7</h4>
<pre><code class="hljs language-python">model.load_state_dict({k.replace(<span class="hljs-string">&quot;model.&quot;</span>,<span class="hljs-string">&quot;&quot;</span>): v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> fine_tuned_model_ckpt[<span class="hljs-string">&#x27;state_dict&#x27;</span>].items()})
</code></pre>
<pre><code>&lt;All keys matched successfully&gt;
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">평가모드로 전환</h3>
<p>이어서 code 2-8을 실행하면 모델이 평가모드로 전환되게 된다. <strong>드롭아웃 등 학습 때만 사용하는 기법들을 무효화하는 역할</strong>을 한다.</p>
<h4>code 2-8</h4>
<pre><code class="hljs language-python">model.<span class="hljs-built_in">eval</span>()
</code></pre>
<pre><code>BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30000, 768, padding_idx=0)
      (position_embeddings): Embedding(300, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
)
</code></pre>
<h2 id="3" class="text-2xl font-bold mt-8 mb-4">3. 모델 출력값 만들고 후처리 하기</h2>
<p>code 2-9는 <strong>인퍼런스 과정을 정의한 함수</strong>이다. 문장에 토큰화를 수행한 뒤 <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>를 만든다. 이들 입력값을 파이토치의 텐서 자료형으로 변환한 뒤 모델에 입력한다. 모델 출력값(<code>outputs.logits</code>)은 소프트맥스 함수 적용 이전의 <strong>로짓</strong>(logit)형태인데, 여기에 소프트맥스 함수를 써서 모델 출력을 &#x27;[<strong>부정일 확률, 긍정일 확률</strong>]&#x27;로 바꾼다.</p>
<p>마지막으로 모델 출력을 약간 후처리 하여 예측 확률의 최댓값이 부정 위치일 때 해당 문장이 &#x27;<strong>부정</strong>(negative)&#x27;, 반대일 때는 &#x27;<strong>긍정</strong>(positive)&#x27;이 되도록 <code>pred</code>값을 만든다.</p>
<h4>code 2-9</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">inference_fn</span>(<span class="hljs-params">sentence</span>):
  <span class="hljs-comment"># 문장을 토큰화한 뒤 input_id, attention_masks, token_type_ids 만들기</span>
  inputs = tokenizer(
      [sentence],
      max_lenght=args.max_seq_length,
      padding=<span class="hljs-string">&quot;max_length&quot;</span>,
      truncation=<span class="hljs-literal">True</span>,
  )
  <span class="hljs-keyword">with</span> torch.no_grad():
    <span class="hljs-comment"># 모델 계산하기</span>
    outputs = model(**{k: torch.tensor(v) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()})  <span class="hljs-comment"># {}안 = inputs를 파이토치 텐서로 바꾸기</span>
    
    <span class="hljs-comment"># 로짓에 소프트 맥스 취하기</span>
    prob = outputs.logits.softmax(dim=<span class="hljs-number">1</span>)

    <span class="hljs-comment"># 긍정/부정 확률을 소수점 4자리로 반올림</span>
    positive_prob = <span class="hljs-built_in">round</span>(prob[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].item(), <span class="hljs-number">4</span>)
    negative_prob = <span class="hljs-built_in">round</span>(prob[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].item(), <span class="hljs-number">4</span>)

    <span class="hljs-comment"># 예측 확률의 최댓값 위치에 따라 pred 만들기</span>
    pred = <span class="hljs-string">&quot;긍정 (positive)&quot;</span> <span class="hljs-keyword">if</span> torch.argmax(prob) == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;부정 (negative)&quot;</span>
  <span class="hljs-keyword">return</span> {
      <span class="hljs-string">&#x27;sentence&#x27;</span> : sentence,
      <span class="hljs-string">&#x27;prediction&#x27;</span>: pred,
      <span class="hljs-string">&#x27;positive_data&#x27;</span>: <span class="hljs-string">f&quot;긍정 <span class="hljs-subst">{positive_prob}</span>&quot;</span>,
      <span class="hljs-string">&#x27;negative_data&#x27;</span>: <span class="hljs-string">f&quot;부정 <span class="hljs-subst">{negative_prob}</span>&quot;</span>,
      <span class="hljs-string">&#x27;positive_width&#x27;</span>: <span class="hljs-string">f&quot;<span class="hljs-subst">{positive_prob * <span class="hljs-number">100</span>}</span>%&quot;</span>,
      <span class="hljs-string">&#x27;negative_width&#x27;</span>: <span class="hljs-string">f&quot;<span class="hljs-subst">{negative_prob * <span class="hljs-number">100</span>}</span>%&quot;</span>,
  }
</code></pre>
<p>code 2-9에서 <code>positive_width</code>, <code>negative_width</code>는 웹 페이지에서 긍정/부정 막대의 길이를 조정하려는 것이므로 크게 신경쓰지 않아도 된다.</p>
<h2 id="4" class="text-2xl font-bold mt-8 mb-4">4. 웹 서비스 시작하기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">웹 서비스 만들기 준비</h3>
<p><code>ngrok</code>은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. <code>ngrok</code>을 실행하려면 <a href="https://dashboard.ngrok.com/get-started/setup">회원가입</a> 후 <a href="https://dashboard.ngrok.com/get-started/setup">로그인</a>을 한 뒤 <a href="https://dashboard.ngrok.com/get-started/your-authtoken">이곳</a>에 접속해 인증토큰(authtoken)을 확인해야 한다.</p>
<p>예를 들어 확인된 <code>authtoken</code>이 <code>test123</code>이라면 다음과 같이 실행 된다.</p>
<p>** !mkdir /root/.ngrok2 &amp;&amp; echo &quot;authtoken: test123&quot; &gt; /root/.ngrok2/ngrok.yml**</p>
<h4>code 2-10</h4>
<pre><code class="hljs language-python">!mkdir /root/.ngrok2 &amp;&amp; echo <span class="hljs-string">&quot;authtoken: (여기 채우세요))&quot;</span> &gt; /root/.ngrok2/ngrok.yml
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">웹 서비스 시작하기</h3>
<p>code 2-9에서 정의한 인퍼런스 함수 <code>inference_fn</code>을 가지고 code 2-11을 실행하면 <strong>플라스크</strong>(flask)라는 파이썬 라이브러리의 도움을 받아 웹 서비스를 띄울 수 있다.</p>
<h4>code 2-11</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> get_web_service_app
app = get_web_service_app(inference_fn)
app.run()
</code></pre>
<h2 id="" class="text-2xl font-bold mt-8 mb-4">웹 사이트의 형태는 다음과 같다.</h2>
<p><img src="https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png" alt="model_inference"/></p><div class="mt-10 border-t pt-10"></div></article></div><!--$--><!--/$--><script src="/_next/static/chunks/475fa0f5a019bf38.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n3:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n5:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"OutletBoundary\"]\n6:\"$Sreact.suspense\"\n8:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"ViewportBoundary\"]\na:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"MetadataBoundary\"]\nc:I[68027,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n:HL[\"/_next/static/chunks/2f40a2027cd59172.css\",\"style\"]\n:HL[\"/_next/static/chunks/b9ef641e76e3a351.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"8lJiHtAmlyU3nNFMbG8_k\",\"c\":[\"\",\"2022-03-26-classification_model_apply\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"2022-03-26-classification_model_apply\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/2f40a2027cd59172.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"min-h-screen flex flex-col font-sans\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/b9ef641e76e3a351.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/6b8d09032578b975.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@7\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L8\",null,{\"children\":\"$@9\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@b\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:T2695,"])</script><script>self.__next_f.push([1,"Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\nRequirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\nRequirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\nRequirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\nRequirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\nRequirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\nRequirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\nRequirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\nRequirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\nRequirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\nRequirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\nRequirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\nRequirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\nRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.62.3)\nRequirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\nRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\nRequirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\nRequirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\nRequirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\nRequirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\nRequirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\nRequirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\nRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\nRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\nRequirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\nRequirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\nRequirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\nRequirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\nRequirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\nRequirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\nRequirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.43.0)\nRequirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\nRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\nRequirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\nRequirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\nRequirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\nRequirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\nRequirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\nRequirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\nRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\nRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\nRequirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\nRequirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\nRequirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\nRequirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\nRequirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\nRequirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\nRequirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\nRequirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\nRequirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"flex gap-10\",\"children\":[[\"$\",\"article\",null,{\"className\":\"flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8 not-prose border-b pb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold mb-4\",\"children\":\"[NLP] 문서 분류 모델 실전 투입\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"$D2022-03-26T00:00:00.000Z\",\"children\":\"March 26, 2022\"}],\"$undefined\"]}]]}],[[\"$\",\"p\",\"p-0\",{\"children\":\"자, 그럼 학습을 마친 모델을 어떻게 사용할까?\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)\"}],\"\\n\",[\"$\",\"h1\",\"h1-0\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"학습 마친 모델을 실전 투입하기\"}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":[\"이번 실습에서는 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다\"}],\".\"]}],\"\\n\",[\"$\",\"p\",\"p-3\",{\"children\":[\"문장을 받아 해당 문장이 긍정인지 부정인지 답변하는 웹 서비스로, 문장을 토큰화한 뒤 모델 입력값으로 만들고 이를 모델에 입력해 [\",[\"$\",\"em\",\"em-0\",{\"children\":\"해당 문장이 긍정일 확률, 해당 문장이 부정일 확률\"}],\" ]을 계산하게 만든다. 이후 약간의 후처리 과정을 거쳐 응답하게 만드는 방식이다.\"]}],\"\\n\",[\"$\",\"p\",\"p-4\",{\"children\":\"웹 서비스란 네트워크에서 컴퓨터 간에 상호작용을 하기 위해 만들어진 소프트웨어 시스템이다. 본 노트에서는 원격 사용자가 보낸 문장을 수신해 해당 문장이 긍정인지 부정인지 응답을 만들고 이 응답을 원격 사용자에게 전달하는 웹 서비스를 만드는 것이다.\"}],\"\\n\",[\"$\",\"h2\",\"h2-0\",{\"id\":\"1\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"1. 환경 설정하기\"}],\"\\n\",[\"$\",\"h3\",\"h3-0\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"의존성 패키지 설치\"}],\"\\n\",[\"$\",\"p\",\"p-5\",{\"children\":\"pip 명령어를 통해 의존성 있는 패키지를 설치한다.\"}],\"\\n\",[\"$\",\"h4\",\"h4-0\",{\"children\":\"code 2-0\"}],\"\\n\",[\"$\",\"pre\",\"pre-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"!pip install ratsnlp\\n\"}]}],\"\\n\",[\"$\",\"pre\",\"pre-1\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$d\"}]}],\"\\n\",\"$Le\",\"\\n\",\"$Lf\",\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\"],\"$L48\"]}],\"$L49\"]}]\n"])</script><script>self.__next_f.push([1,"4b:I[24170,[\"/_next/static/chunks/6b8d09032578b975.js\"],\"default\"]\n4c:I[55132,[\"/_next/static/chunks/6b8d09032578b975.js\"],\"default\"]\n:HL[\"https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png\",\"image\"]\ne:[\"$\",\"h3\",\"h3-1\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"구글 드라이브 연동\"}]\nf:[\"$\",\"p\",\"p-6\",{\"children\":\"모델 체크포인트는 구글 드라이브에 저장해 두었다. 코랩 노트북과 자신의 구글 드라이브를 연동한다.\"}]\n10:[\"$\",\"h4\",\"h4-1\",{\"children\":\"code 2-1\"}]\n11:[\"$\",\"pre\",\"pre-2\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" google.colab \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" drive\\ndrive.mount(\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"'/gdrive'\"}],\", force_remount=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\")\\n\"]}]}]\n12:[\"$\",\"pre\",\"pre-3\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"Mounted at /gdrive\\n\"}]}]\n13:[\"$\",\"h3\",\"h3-2\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"인퍼런스 설정\"}]\n14:[\"$\",\"p\",\"p-7\",{\"children\":\"각종 인자( 모델 하이퍼파라미터(hyperparameter)와 저장 위치 등 )를 설정한다.\"}]\n15:[\"$\",\"h4\",\"h4-2\",{\"children\":\"code 2-2\"}]\n16:[\"$\",\"pre\",\"pre-4\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" ClassificationDeployArguments\\nargs = ClassificationDeployArguments(\\n    pretrained_model_name=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"\\\"beomi/kcbert-base\\\"\"}],\",\\n    downstream_model_dir=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-string\",\"children\":\"\\\"/gdrive/My Drive/nlpbook/checkpoint-doccls\\\"\"}],\",\\n    max_seq_length=\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-number\",\"children\":\"128\"}],\",\\n)\\n\"]}]}]\n17:[\"$\",\"pre\",\"pre-5\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.28.ckpt\\n\"}]}]\n18:[\"$\",\"p\",\"p-8\",{\"children\":\"각 인자의 역할과 내용은 다음과 같다.\"}]\n19:[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"pretrained_model_name\"}],\": \",[\"$\",\"code\",\"code-0\",{\"children\":\"training_section.ipynb\"}],\"에서 적용한 \",[\"$\",\"code\",\"code-1\",{\"children\":\"pretrained_model_name\"}],\"(단, 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 한다.)\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"downstream_model_dir\"}],\":  \",[\"$\",\"code\",\"code-0\",{\"children\":\"training_section.ipynb\"}],\"에서 파인튜닝한 모델의 체크포인트 저장 위치(확장자가 \",[\"$\",\"code\",\"code-1\",{\"children\":\"ckpt\"}],\"인 파일이 하나 이상 있어야 한다.)\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"max_seq_length\"}],\": 토큰 기준 입력 문장 최대 길이. 아무것도 입력하지 않으면 128.\"]}],\"\\n\"]}]\n1a:[\"$\",\"h2\",\"h2-1\",{\"id\":\"2\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"2. 토크나이저 및 모델 불러오기\"}]\n1b:[\"$\",\"h3\",\"h3-3\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"토크나이저 로드\"}]\n1c:[\"$\",\"p\",\"p-9\",{\"children\":\"code 2-3을 실행해 토크나이저를 초기화 한다.\"}]\n1d:[\"$\",\"h4\",\"h4-3\",{\"children\":\"code 2-3\"}]\n1e:[\"$\",\"pre\",\"pre-6\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertTokenizer\\ntokenizer = BertTokenizer.from_pretrained(\\n    args.pretrained_model_name,\\n    do_lower_case=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-literal\",\"children\":"])</script><script>self.__next_f.push([1,"\"False\"}],\",\\n)\\n\"]}]}]\n1f:[\"$\",\"pre\",\"pre-7\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"Downloading:   0%|          | 0.00/250k [00:00\u003c?, ?B/s]\\n\\n\\n\\nDownloading:   0%|          | 0.00/49.0 [00:00\u003c?, ?B/s]\\n\\n\\n\\nDownloading:   0%|          | 0.00/619 [00:00\u003c?, ?B/s]\\n\"}]}]\n20:[\"$\",\"h3\",\"h3-4\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"체크포인트 로드\"}]\n21:[\"$\",\"p\",\"p-10\",{\"children\":[\"code 2-4는 \",[\"$\",\"code\",\"code-0\",{\"children\":\"training_section.ipynb\"}],\"에서 파인튜닝한 모델의 체크포인트를 읽어들인다.\"]}]\n22:[\"$\",\"h4\",\"h4-4\",{\"children\":\"code 2-4\"}]\n23:[\"$\",\"pre\",\"pre-8\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch\\nfine_tuned_model_ckpt = torch.load(\\n    args.downstream_model_checkpoint_fpath,\\n    map_location=torch.device(\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-string\",\"children\":\"\\\"cpu\\\"\"}],\"),\\n)\\n\"]}]}]\n24:[\"$\",\"h3\",\"h3-5\",{\"id\":\"b\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"BERT 설정 로드 및 BERT 모델 초기화\"}]\n25:[\"$\",\"p\",\"p-11\",{\"children\":[\"code 2-5는 \",[\"$\",\"code\",\"code-0\",{\"children\":\"training_section.ipynb\"}],\"의 파인튜닝 때 사용한 \",[\"$\",\"code\",\"code-1\",{\"children\":\"pretrained_model_name\"}],\"에 해당하는 모델의 설정값들을 읽어들인다.\"]}]\n26:[\"$\",\"p\",\"p-12\",{\"children\":[\"이어서 code 2-6을 실행하면 해당 설정값대로 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"BERT\"}],\" 모델을 초기화 한다.\"]}]\n27:[\"$\",\"h4\",\"h4-5\",{\"children\":\"code 2-5\"}]\n28:[\"$\",\"pre\",\"pre-9\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertConfig\\npretrained_model_config = BertConfig.from_pretrained(\\n    args.pretrained_model_name,\\n    num_labels=fine_tuned_model_ckpt[\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"\\\"state_dict\\\"\"}],\"][\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-string\",\"children\":\"\\\"model.classifier.bias\\\"\"}],\"].shape.numel(),\\n)\\n\"]}]}]\n29:[\"$\",\"h4\",\"h4-6\",{\"children\":\"code 2-6\"}]\n2a:[\"$\",\"pre\",\"pre-10\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertForSequenceClassification\\nmodel = BertForSequenceClassification(pretrained_model_config)\\n\"]}]}]\n2b:[\"$\",\"h3\",\"h3-6\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"체크포인트 주입하기\"}]\n2c:[\"$\",\"p\",\"p-13\",{\"children\":[\"code 2-7은 초기화한 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"BERT\"}],\"모델에 체크포인트(fine_tuned_model_ckpt)를 주입한다.\"]}]\n2d:[\"$\",\"h4\",\"h4-7\",{\"children\":\"code 2-7\"}]\n2e:[\"$\",\"pre\",\"pre-11\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"model.load_state_dict({k.replace(\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-string\",\"children\":\"\\\"model.\\\"\"}],\",\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-string\",\"children\":\"\\\"\\\"\"}],\"): v \",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-keyword\",\"children\":\"for\"}],\" k, v \",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-keyword\",\"children\":\"in\"}],\" fine_tuned_model_ckpt[\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-string\",\"children\":\"'state_dict'\"}],\"].items()})\\n\"]}]}]\n2f:[\"$\",\"pre\",\"pre-12\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"\u003cAll keys matched successfully\u003e\\n\"}]}]\n30:[\"$\",\"h3\",\"h3-7\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"평가모드로 전환\"}]\n31:[\"$\",\"p\",\"p-14\",{\"children\":[\"이어서 code 2-8을 실행하면 모델이 평가모드로 전환되게 된다. \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"드롭아웃 등 학습 때만 사용하는 기법들을 무효화하는 역할\"}],\"을 한다.\"]}]\n32:[\"$\",\"h4\",\"h4-8\",{\"children\":\"code 2-8\"}]\n33:[\"$\",\"pre\",\"pre-13\",{\"children\":[\"$\",\"code\",\"code-0\","])</script><script>self.__next_f.push([1,"{\"className\":\"hljs language-python\",\"children\":[\"model.\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-built_in\",\"children\":\"eval\"}],\"()\\n\"]}]}]\n4a:T348e,"])</script><script>self.__next_f.push([1,"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)\n"])</script><script>self.__next_f.push([1,"34:[\"$\",\"pre\",\"pre-14\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$4a\"}]}]\n35:[\"$\",\"h2\",\"h2-2\",{\"id\":\"3\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"3. 모델 출력값 만들고 후처리 하기\"}]\n36:[\"$\",\"p\",\"p-15\",{\"children\":[\"code 2-9는 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"인퍼런스 과정을 정의한 함수\"}],\"이다. 문장에 토큰화를 수행한 뒤 \",[\"$\",\"code\",\"code-0\",{\"children\":\"input_ids\"}],\", \",[\"$\",\"code\",\"code-1\",{\"children\":\"attention_mask\"}],\", \",[\"$\",\"code\",\"code-2\",{\"children\":\"token_type_ids\"}],\"를 만든다. 이들 입력값을 파이토치의 텐서 자료형으로 변환한 뒤 모델에 입력한다. 모델 출력값(\",[\"$\",\"code\",\"code-3\",{\"children\":\"outputs.logits\"}],\")은 소프트맥스 함수 적용 이전의 \",[\"$\",\"strong\",\"strong-1\",{\"children\":\"로짓\"}],\"(logit)형태인데, 여기에 소프트맥스 함수를 써서 모델 출력을 '[\",[\"$\",\"strong\",\"strong-2\",{\"children\":\"부정일 확률, 긍정일 확률\"}],\"]'로 바꾼다.\"]}]\n37:[\"$\",\"p\",\"p-16\",{\"children\":[\"마지막으로 모델 출력을 약간 후처리 하여 예측 확률의 최댓값이 부정 위치일 때 해당 문장이 '\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"부정\"}],\"(negative)', 반대일 때는 '\",[\"$\",\"strong\",\"strong-1\",{\"children\":\"긍정\"}],\"(positive)'이 되도록 \",[\"$\",\"code\",\"code-0\",{\"children\":\"pred\"}],\"값을 만든다.\"]}]\n38:[\"$\",\"h4\",\"h4-9\",{\"children\":\"code 2-9\"}]\n"])</script><script>self.__next_f.push([1,"39:[\"$\",\"pre\",\"pre-15\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-title function_\",\"children\":\"inference_fn\"}],\"(\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-params\",\"children\":\"sentence\"}],\"):\\n  \",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-comment\",\"children\":\"# 문장을 토큰화한 뒤 input_id, attention_masks, token_type_ids 만들기\"}],\"\\n  inputs = tokenizer(\\n      [sentence],\\n      max_lenght=args.max_seq_length,\\n      padding=\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-string\",\"children\":\"\\\"max_length\\\"\"}],\",\\n      truncation=\",[\"$\",\"span\",\"span-5\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\",\\n  )\\n  \",[\"$\",\"span\",\"span-6\",{\"className\":\"hljs-keyword\",\"children\":\"with\"}],\" torch.no_grad():\\n    \",[\"$\",\"span\",\"span-7\",{\"className\":\"hljs-comment\",\"children\":\"# 모델 계산하기\"}],\"\\n    outputs = model(**{k: torch.tensor(v) \",[\"$\",\"span\",\"span-8\",{\"className\":\"hljs-keyword\",\"children\":\"for\"}],\" k, v \",[\"$\",\"span\",\"span-9\",{\"className\":\"hljs-keyword\",\"children\":\"in\"}],\" inputs.items()})  \",[\"$\",\"span\",\"span-10\",{\"className\":\"hljs-comment\",\"children\":\"# {}안 = inputs를 파이토치 텐서로 바꾸기\"}],\"\\n    \\n    \",[\"$\",\"span\",\"span-11\",{\"className\":\"hljs-comment\",\"children\":\"# 로짓에 소프트 맥스 취하기\"}],\"\\n    prob = outputs.logits.softmax(dim=\",[\"$\",\"span\",\"span-12\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\")\\n\\n    \",[\"$\",\"span\",\"span-13\",{\"className\":\"hljs-comment\",\"children\":\"# 긍정/부정 확률을 소수점 4자리로 반올림\"}],\"\\n    positive_prob = \",[\"$\",\"span\",\"span-14\",{\"className\":\"hljs-built_in\",\"children\":\"round\"}],\"(prob[\",[\"$\",\"span\",\"span-15\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"][\",[\"$\",\"span\",\"span-16\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\"].item(), \",[\"$\",\"span\",\"span-17\",{\"className\":\"hljs-number\",\"children\":\"4\"}],\")\\n    negative_prob = \",[\"$\",\"span\",\"span-18\",{\"className\":\"hljs-built_in\",\"children\":\"round\"}],\"(prob[\",[\"$\",\"span\",\"span-19\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"][\",[\"$\",\"span\",\"span-20\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"].item(), \",[\"$\",\"span\",\"span-21\",{\"className\":\"hljs-number\",\"children\":\"4\"}],\")\\n\\n    \",[\"$\",\"span\",\"span-22\",{\"className\":\"hljs-comment\",\"children\":\"# 예측 확률의 최댓값 위치에 따라 pred 만들기\"}],\"\\n    pred = \",[\"$\",\"span\",\"span-23\",{\"className\":\"hljs-string\",\"children\":\"\\\"긍정 (positive)\\\"\"}],\" \",[\"$\",\"span\",\"span-24\",{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" torch.argmax(prob) == \",[\"$\",\"span\",\"span-25\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\" \",[\"$\",\"span\",\"span-26\",{\"className\":\"hljs-keyword\",\"children\":\"else\"}],\" \",[\"$\",\"span\",\"span-27\",{\"className\":\"hljs-string\",\"children\":\"\\\"부정 (negative)\\\"\"}],\"\\n  \",[\"$\",\"span\",\"span-28\",{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" {\\n      \",[\"$\",\"span\",\"span-29\",{\"className\":\"hljs-string\",\"children\":\"'sentence'\"}],\" : sentence,\\n      \",[\"$\",\"span\",\"span-30\",{\"className\":\"hljs-string\",\"children\":\"'prediction'\"}],\": pred,\\n      \",[\"$\",\"span\",\"span-31\",{\"className\":\"hljs-string\",\"children\":\"'positive_data'\"}],\": \",[\"$\",\"span\",\"span-32\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"긍정 \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":\"{positive_prob}\"}],\"\\\"\"]}],\",\\n      \",[\"$\",\"span\",\"span-33\",{\"className\":\"hljs-string\",\"children\":\"'negative_data'\"}],\": \",[\"$\",\"span\",\"span-34\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"부정 \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":\"{negative_prob}\"}],\"\\\"\"]}],\",\\n      \",[\"$\",\"span\",\"span-35\",{\"className\":\"hljs-string\",\"children\":\"'positive_width'\"}],\": \",[\"$\",\"span\",\"span-36\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":[\"{positive_prob * \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"100\"}],\"}\"]}],\"%\\\"\"]}],\",\\n      \",[\"$\",\"span\",\"span-37\",{\"className\":\"hljs-string\",\"children\":\"'negative_width'\"}],\": \",[\"$\",\"span\",\"span-38\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":[\"{negative_prob * \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"100\"}],\"}\"]}],\"%\\\"\"]}],\",\\n  }\\n\"]}]}]\n"])</script><script>self.__next_f.push([1,"3a:[\"$\",\"p\",\"p-17\",{\"children\":[\"code 2-9에서 \",[\"$\",\"code\",\"code-0\",{\"children\":\"positive_width\"}],\", \",[\"$\",\"code\",\"code-1\",{\"children\":\"negative_width\"}],\"는 웹 페이지에서 긍정/부정 막대의 길이를 조정하려는 것이므로 크게 신경쓰지 않아도 된다.\"]}]\n3b:[\"$\",\"h2\",\"h2-3\",{\"id\":\"4\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"4. 웹 서비스 시작하기\"}]\n3c:[\"$\",\"h3\",\"h3-8\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"웹 서비스 만들기 준비\"}]\n3d:[\"$\",\"p\",\"p-18\",{\"children\":[[\"$\",\"code\",\"code-0\",{\"children\":\"ngrok\"}],\"은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. \",[\"$\",\"code\",\"code-1\",{\"children\":\"ngrok\"}],\"을 실행하려면 \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://dashboard.ngrok.com/get-started/setup\",\"children\":\"회원가입\"}],\" 후 \",[\"$\",\"a\",\"a-1\",{\"href\":\"https://dashboard.ngrok.com/get-started/setup\",\"children\":\"로그인\"}],\"을 한 뒤 \",[\"$\",\"a\",\"a-2\",{\"href\":\"https://dashboard.ngrok.com/get-started/your-authtoken\",\"children\":\"이곳\"}],\"에 접속해 인증토큰(authtoken)을 확인해야 한다.\"]}]\n3e:[\"$\",\"p\",\"p-19\",{\"children\":[\"예를 들어 확인된 \",[\"$\",\"code\",\"code-0\",{\"children\":\"authtoken\"}],\"이 \",[\"$\",\"code\",\"code-1\",{\"children\":\"test123\"}],\"이라면 다음과 같이 실행 된다.\"]}]\n3f:[\"$\",\"p\",\"p-20\",{\"children\":\"** !mkdir /root/.ngrok2 \u0026\u0026 echo \\\"authtoken: test123\\\" \u003e /root/.ngrok2/ngrok.yml**\"}]\n40:[\"$\",\"h4\",\"h4-10\",{\"children\":\"code 2-10\"}]\n41:[\"$\",\"pre\",\"pre-16\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"!mkdir /root/.ngrok2 \u0026\u0026 echo \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-string\",\"children\":\"\\\"authtoken: (여기 채우세요))\\\"\"}],\" \u003e /root/.ngrok2/ngrok.yml\\n\"]}]}]\n42:[\"$\",\"h3\",\"h3-9\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"웹 서비스 시작하기\"}]\n43:[\"$\",\"p\",\"p-21\",{\"children\":[\"code 2-9에서 정의한 인퍼런스 함수 \",[\"$\",\"code\",\"code-0\",{\"children\":\"inference_fn\"}],\"을 가지고 code 2-11을 실행하면 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"플라스크\"}],\"(flask)라는 파이썬 라이브러리의 도움을 받아 웹 서비스를 띄울 수 있다.\"]}]\n44:[\"$\",\"h4\",\"h4-11\",{\"children\":\"code 2-11\"}]\n45:[\"$\",\"pre\",\"pre-17\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" get_web_service_app\\napp = get_web_service_app(inference_fn)\\napp.run()\\n\"]}]}]\n46:[\"$\",\"h2\",\"h2-4\",{\"id\":\"\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"웹 사이트의 형태는 다음과 같다.\"}]\n47:[\"$\",\"p\",\"p-22\",{\"children\":[\"$\",\"img\",\"img-0\",{\"src\":\"https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png\",\"alt\":\"model_inference\"}]}]\n48:[\"$\",\"$L4b\",null,{}]\n4d:T802e,"])</script><script>self.__next_f.push([1,"\n자, 그럼 학습을 마친 모델을 어떻게 사용할까?\n\n본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)\n\n# 학습 마친 모델을 실전 투입하기\n\n이번 실습에서는 **학습을 마친 문서 분류 모델을 가지고 웹 서비스를 만든다**.\n\n문장을 받아 해당 문장이 긍정인지 부정인지 답변하는 웹 서비스로, 문장을 토큰화한 뒤 모델 입력값으로 만들고 이를 모델에 입력해 [*해당 문장이 긍정일 확률, 해당 문장이 부정일 확률* ]을 계산하게 만든다. 이후 약간의 후처리 과정을 거쳐 응답하게 만드는 방식이다.\n\n웹 서비스란 네트워크에서 컴퓨터 간에 상호작용을 하기 위해 만들어진 소프트웨어 시스템이다. 본 노트에서는 원격 사용자가 보낸 문장을 수신해 해당 문장이 긍정인지 부정인지 응답을 만들고 이 응답을 원격 사용자에게 전달하는 웹 서비스를 만드는 것이다.\n\n## 1. 환경 설정하기\n\n### 의존성 패키지 설치\n\npip 명령어를 통해 의존성 있는 패키지를 설치한다.\n\n#### code 2-0\n\n\n```python\n!pip install ratsnlp\n```\n\n    Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\n    Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\n    Requirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\n    Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\n    Requirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\n    Requirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\n    Requirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n    Requirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\n    Requirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\n    Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\n    Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\n    Requirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\n    Requirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\n    Requirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\n    Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.62.3)\n    Requirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\n    Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\n    Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\n    Requirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\n    Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\n    Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.1)\n    Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\n    Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\n    Requirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\n    Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\n    Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\n    Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\n    Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\n    Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\n    Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\n    Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\n    Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\n    Requirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\n    Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\n    Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\n    Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\n    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\n    Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\n    Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\n    Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.43.0)\n    Requirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\n    Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\n    Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\n    Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\n    Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\n    Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\n    Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\n    Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\n    Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\n    Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\n    Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\n    Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\n    Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\n    Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\n    Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\n    Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\n    Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\n    Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\n    Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\n    Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\n    Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\n    Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\n    Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n    \n\n### 구글 드라이브 연동\n\n모델 체크포인트는 구글 드라이브에 저장해 두었다. 코랩 노트북과 자신의 구글 드라이브를 연동한다.\n\n#### code 2-1\n\n\n```python\nfrom google.colab import drive\ndrive.mount('/gdrive', force_remount=True)\n```\n\n    Mounted at /gdrive\n    \n\n### 인퍼런스 설정\n\n각종 인자( 모델 하이퍼파라미터(hyperparameter)와 저장 위치 등 )를 설정한다.\n\n#### code 2-2\n\n\n```python\nfrom ratsnlp.nlpbook.classification import ClassificationDeployArguments\nargs = ClassificationDeployArguments(\n    pretrained_model_name=\"beomi/kcbert-base\",\n    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",\n    max_seq_length=128,\n)\n```\n\n    downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-doccls/epoch=1-val_loss=0.28.ckpt\n    \n\n각 인자의 역할과 내용은 다음과 같다.\n  \n  * **pretrained_model_name**: `training_section.ipynb`에서 적용한 `pretrained_model_name`(단, 해당 모델은 허깅페이스 라이브러리에 등록되어 있어야 한다.)\n  * **downstream_model_dir**:  `training_section.ipynb`에서 파인튜닝한 모델의 체크포인트 저장 위치(확장자가 `ckpt`인 파일이 하나 이상 있어야 한다.)\n  * **max_seq_length**: 토큰 기준 입력 문장 최대 길이. 아무것도 입력하지 않으면 128.\n\n## 2. 토크나이저 및 모델 불러오기\n\n### 토크나이저 로드\n\ncode 2-3을 실행해 토크나이저를 초기화 한다.\n\n#### code 2-3\n\n\n```python\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\n    args.pretrained_model_name,\n    do_lower_case=False,\n)\n```\n\n\n    Downloading:   0%|          | 0.00/250k [00:00\u003c?, ?B/s]\n\n\n\n    Downloading:   0%|          | 0.00/49.0 [00:00\u003c?, ?B/s]\n\n\n\n    Downloading:   0%|          | 0.00/619 [00:00\u003c?, ?B/s]\n\n\n### 체크포인트 로드\n\ncode 2-4는 `training_section.ipynb`에서 파인튜닝한 모델의 체크포인트를 읽어들인다.\n\n#### code 2-4\n\n\n```python\nimport torch\nfine_tuned_model_ckpt = torch.load(\n    args.downstream_model_checkpoint_fpath,\n    map_location=torch.device(\"cpu\"),\n)\n```\n\n### BERT 설정 로드 및 BERT 모델 초기화\n\ncode 2-5는 `training_section.ipynb`의 파인튜닝 때 사용한 `pretrained_model_name`에 해당하는 모델의 설정값들을 읽어들인다. \n\n이어서 code 2-6을 실행하면 해당 설정값대로 **BERT** 모델을 초기화 한다.\n\n#### code 2-5\n\n\n```python\nfrom transformers import BertConfig\npretrained_model_config = BertConfig.from_pretrained(\n    args.pretrained_model_name,\n    num_labels=fine_tuned_model_ckpt[\"state_dict\"][\"model.classifier.bias\"].shape.numel(),\n)\n```\n\n#### code 2-6\n\n\n```python\nfrom transformers import BertForSequenceClassification\nmodel = BertForSequenceClassification(pretrained_model_config)\n```\n\n###  체크포인트 주입하기\n\ncode 2-7은 초기화한 **BERT**모델에 체크포인트(fine_tuned_model_ckpt)를 주입한다.\n\n#### code 2-7\n\n\n```python\nmodel.load_state_dict({k.replace(\"model.\",\"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n```\n\n\n\n\n    \u003cAll keys matched successfully\u003e\n\n\n\n### 평가모드로 전환\n\n이어서 code 2-8을 실행하면 모델이 평가모드로 전환되게 된다. **드롭아웃 등 학습 때만 사용하는 기법들을 무효화하는 역할**을 한다.\n\n#### code 2-8\n\n\n```python\nmodel.eval()\n```\n\n\n\n\n    BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30000, 768, padding_idx=0)\n          (position_embeddings): Embedding(300, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (1): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (2): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (3): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (4): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (5): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (6): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (7): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (8): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (9): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (10): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (11): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): Linear(in_features=768, out_features=2, bias=True)\n    )\n\n\n\n## 3. 모델 출력값 만들고 후처리 하기\n\ncode 2-9는 **인퍼런스 과정을 정의한 함수**이다. 문장에 토큰화를 수행한 뒤 `input_ids`, `attention_mask`, `token_type_ids`를 만든다. 이들 입력값을 파이토치의 텐서 자료형으로 변환한 뒤 모델에 입력한다. 모델 출력값(`outputs.logits`)은 소프트맥스 함수 적용 이전의 **로짓**(logit)형태인데, 여기에 소프트맥스 함수를 써서 모델 출력을 '[**부정일 확률, 긍정일 확률**]'로 바꾼다.\n\n마지막으로 모델 출력을 약간 후처리 하여 예측 확률의 최댓값이 부정 위치일 때 해당 문장이 '**부정**(negative)', 반대일 때는 '**긍정**(positive)'이 되도록 `pred`값을 만든다.\n\n#### code 2-9\n\n\n```python\ndef inference_fn(sentence):\n  # 문장을 토큰화한 뒤 input_id, attention_masks, token_type_ids 만들기\n  inputs = tokenizer(\n      [sentence],\n      max_lenght=args.max_seq_length,\n      padding=\"max_length\",\n      truncation=True,\n  )\n  with torch.no_grad():\n    # 모델 계산하기\n    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}안 = inputs를 파이토치 텐서로 바꾸기\n    \n    # 로짓에 소프트 맥스 취하기\n    prob = outputs.logits.softmax(dim=1)\n\n    # 긍정/부정 확률을 소수점 4자리로 반올림\n    positive_prob = round(prob[0][1].item(), 4)\n    negative_prob = round(prob[0][0].item(), 4)\n\n    # 예측 확률의 최댓값 위치에 따라 pred 만들기\n    pred = \"긍정 (positive)\" if torch.argmax(prob) == 1 else \"부정 (negative)\"\n  return {\n      'sentence' : sentence,\n      'prediction': pred,\n      'positive_data': f\"긍정 {positive_prob}\",\n      'negative_data': f\"부정 {negative_prob}\",\n      'positive_width': f\"{positive_prob * 100}%\",\n      'negative_width': f\"{negative_prob * 100}%\",\n  }\n```\n\ncode 2-9에서 `positive_width`, `negative_width`는 웹 페이지에서 긍정/부정 막대의 길이를 조정하려는 것이므로 크게 신경쓰지 않아도 된다.\n\n## 4. 웹 서비스 시작하기\n\n### 웹 서비스 만들기 준비\n\n`ngrok`은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구이다. `ngrok`을 실행하려면 [회원가입](https://dashboard.ngrok.com/get-started/setup) 후 [로그인](https://dashboard.ngrok.com/get-started/setup)을 한 뒤 [이곳](https://dashboard.ngrok.com/get-started/your-authtoken)에 접속해 인증토큰(authtoken)을 확인해야 한다. \n\n예를 들어 확인된 `authtoken`이 `test123`이라면 다음과 같이 실행 된다.\n\n** !mkdir /root/.ngrok2 \u0026\u0026 echo \"authtoken: test123\" \u003e /root/.ngrok2/ngrok.yml**\n\n#### code 2-10\n\n\n```python\n!mkdir /root/.ngrok2 \u0026\u0026 echo \"authtoken: (여기 채우세요))\" \u003e /root/.ngrok2/ngrok.yml\n```\n\n### 웹 서비스 시작하기\n\ncode 2-9에서 정의한 인퍼런스 함수 `inference_fn`을 가지고 code 2-11을 실행하면 **플라스크**(flask)라는 파이썬 라이브러리의 도움을 받아 웹 서비스를 띄울 수 있다.\n\n#### code 2-11\n\n\n```python\nfrom ratsnlp.nlpbook.classification import get_web_service_app\napp = get_web_service_app(inference_fn)\napp.run()\n```\n\n## 웹 사이트의 형태는 다음과 같다.\n\n![model_inference](https://user-images.githubusercontent.com/84653623/160078717-08773d8a-9907-448c-b490-7c68f2a84147.png)"])</script><script>self.__next_f.push([1,"49:[\"$\",\"$L4c\",null,{\"content\":\"$4d\"}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"title\",\"0\",{\"children\":\"Sehoon's Workspace\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Welcome to my page!\"}]]\n7:null\n"])</script></body></html>
<!DOCTYPE html><!--xTAnN8PQ3b6_LdzNENhZ7--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/51e5ba5c7de07f80.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/5eacd01f773eed7f.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-1c8036505c2e140d.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-c0bfd06c366bd1e0.js" async=""></script><script src="/_next/static/chunks/main-app-dcd8b77c1bc52c83.js" async=""></script><script src="/_next/static/chunks/app/%5Bslug%5D/page-ad31c54747687caf.js" async=""></script><title>Sehoon&#x27;s Workspace</title><meta name="description" content="Welcome to my page!"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="min-h-screen flex flex-col font-sans"><div hidden=""><!--$--><!--/$--></div><div class="flex gap-10"><article class="flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none"><header class="mb-8 not-prose border-b pb-8"><h1 class="text-4xl font-bold mb-4">[NLP] 문서 분류 모델 training</h1><div class="flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400"><time dateTime="Fri Mar 25 2022 09:00:00 GMT+0900 (Korean Standard Time)">March 25, 2022</time></div></header><p>자연어처리의 예제를 학습하여 보자.
다음은 이전 글에서 설명하였던 문서 분류 모델을 구현한 것이다.</p>
<p>본 파일은 이기창님의 &#x27;Do it! 자연어 처리&#x27;에 기초하여 작성되었다! :)</p>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">문서분류 모델 학습하기</h1>
<h2 id="1" class="text-2xl font-bold mt-8 mb-4">1. 각종 설정하기</h2>
<h3 id="t" class="text-xl font-bold mt-6 mb-3">TPU 관련 패키지 설치</h3>
<p>코랩 노트북 초기화 과정에서 하드웨어 가속기로 TPU를 선택했다면 다음 코드를 실행하면 된다.
그러면 TPU 관련 라이브러리 들을 설치한다.</p>
<p>(참고로 TPU 학습은 라이브러리 지원 등이 GPU보다 불안정한 편이므로 될 수 있으면 GPU를 사용하기를 권함)</p>
<h4>code 1-0</h4>
<pre><code class="hljs language-python">!pip install cloud-tpu-client==<span class="hljs-number">0.10</span> https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-<span class="hljs-number">1.9</span>-cp37-cp37m-linux_x86_64.whl
</code></pre>
<pre><code>Collecting torch-xla==1.9
  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)
Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)
Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)
Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)
Requirement already satisfied: google-api-core&lt;2dev,&gt;=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (1.26.3)
Requirement already satisfied: google-auth&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (1.35.0)
Requirement already satisfied: uritemplate&lt;4dev,&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (3.0.1)
Requirement already satisfied: six&lt;2dev,&gt;=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (1.15.0)
Requirement already satisfied: google-auth-httplib2&gt;=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (0.0.4)
Requirement already satisfied: httplib2&lt;1dev,&gt;=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (0.17.4)
Requirement already satisfied: googleapis-common-protos&lt;2.0dev,&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (1.55.0)
Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (2018.9)
Requirement already satisfied: setuptools&gt;=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (57.4.0)
Requirement already satisfied: protobuf&gt;=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (3.17.3)
Requirement already satisfied: packaging&gt;=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (21.3)
Requirement already satisfied: requests&lt;3.0.0dev,&gt;=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (2.23.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&gt;=1.4.1-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&gt;=1.4.1-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (4.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&gt;=1.4.1-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (4.2.4)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=14.3-&gt;google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (3.0.7)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&gt;=1.4.1-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (0.4.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.13.0-&gt;google-api-python-client==1.8.0-&gt;cloud-tpu-client==0.10) (2.10)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">의존성 패키지 설치</h3>
<p>다음 코드는 TPU이외에 의존성 있는 패키지를 설치한다.</p>
<p>명령어 맨 앞에 붙은 느낌표(!)는 코랩 환경에서 파이썬이 아닌, 셸(shell)명령을 수행한다는 의미이다.</p>
<h4>code 1-1</h4>
<pre><code class="hljs language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: torch&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: flask-ngrok&gt;=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: Korpora&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: flask-cors&gt;=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: flask&gt;=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: fsspec[http]&gt;=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2022.2.0)
Requirement already satisfied: torchmetrics&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.7.2)
Requirement already satisfied: PyYAML&lt;=5.4.1,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (5.4.1)
Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (4.62.3)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (21.3)
Requirement already satisfied: future&gt;=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.18.2)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (1.21.5)
Requirement already satisfied: tensorboard!=2.5.0,&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2.8.0)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.0.47)
Requirement already satisfied: huggingface-hub&gt;=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.4.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2019.12.20)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (4.11.1)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (3.6.0)
Requirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.10.3)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2.23.0)
Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.0.1)
Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (7.1.2)
Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.1.0)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors&gt;=3.0.10-&gt;ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&gt;=0.0.12-&gt;transformers==4.10.0-&gt;ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;flask&gt;=1.1.4-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: xlrd&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses&gt;=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (0.6)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (1.24.3)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.6)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.0.0)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (57.4.0)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.37.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.3.6)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.8.1)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.6.1)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.17.3)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.35.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.44.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.2.4)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers==4.10.0-&gt;ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.0)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.2.0)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.13.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (6.0.2)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.0.2)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.7.2)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (21.4.0)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (2.0.12)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==4.10.0-&gt;ratsnlp) (1.1.0)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">구글 드라이브와 연결</h3>
<p>코랩 노트북은 일정시간 사용하지 않으면 당시까지의 모든 결과물이 날아갈 수 있다. 모델 체크포인트 등을 저장해 두기 위해 자신의 구글 드라이브를 코랩 노트북과 연결한다.</p>
<h4>code 1-2</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">&#x27;/gdrive&#x27;</span>, force_remount=<span class="hljs-literal">True</span>)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">모델 환경 설정</h3>
<p>kcbert-base 모델을 NSMC데이터로 파인튜닝</p>
<h4>code 1-3</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> ClassificationTrainArguments
args = ClassificationTrainArguments(
    pretrained_model_name=<span class="hljs-string">&quot;beomi/kcbert-base&quot;</span>,
    downstream_corpus_name=<span class="hljs-string">&quot;nsmc&quot;</span>,
    downstream_model_dir=<span class="hljs-string">&quot;/gdrive/My Drive/nlpbook/checkpoint-doccls&quot;</span>,
    batch_size=<span class="hljs-number">32</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-number">4</span>,
    learning_rate=<span class="hljs-number">5e-5</span>,
    max_seq_length=<span class="hljs-number">128</span>,
    epochs=<span class="hljs-number">3</span>,
    tpu_cores=<span class="hljs-number">0</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-number">8</span>,
    seed=<span class="hljs-number">7</span>,
)
</code></pre>
<p>참고로 TrainArguments의 각 인자가 하는 역할과 의미는 다음과 같다.</p>
<ul>
<li><strong><code>pretrained_model_name</code></strong></li>
</ul>
<blockquote>
<p>프리트레인 마친 언어 모델의 이름 (단, 해당 모델은 허깅페이스 모델 허브에 등록되어 있어야 한다.)</p>
</blockquote>
<ul>
<li><strong><code>downstream_corpus_name</code></strong></li>
</ul>
<blockquote>
<p>다운스트림 데이터의 이름</p>
</blockquote>
<ul>
<li><strong><code>downstream_corpus_root_dir</code></strong></li>
</ul>
<blockquote>
<p>다운스트림 데이터를 내려받을 위치. 입력하지 않으면 /root/Korpora에 저장된다.</p>
</blockquote>
<ul>
<li><strong><code>downstream_model_dir</code></strong></li>
</ul>
<blockquote>
<p>파인튜닝된 모델의 체크포인트가 저장될 위치. gdrive/My Drive/nlpbook/checkpoint-doccs로 지정하면 자신의 구글 드라이브 [내 폴더] 아래 npbook/checkpoint-doccls디렉터리에 저장된다.</p>
</blockquote>
<ul>
<li><strong><code>batch_size</code></strong></li>
</ul>
<blockquote>
<p>배치 크기. 하드웨어 가속기로 GPU를 선택(<code>torch.cuda.is_available() == True</code>)했다면 32, TPU라면(<code>torch.cuda.is_available() == False</code>) 4. 코랩 환경에서 TPU는 보통 8개의 코어가 할당되는데 batch_size는 코어별로 적용되는 배치 크기이므로 이렇게 설정해 둔다.</p>
</blockquote>
<ul>
<li><strong><code>learning_rate</code></strong></li>
</ul>
<blockquote>
<p>러닝 레이트(보폭). 1회 스텝에서 모델을 얼마나 업데이트할지에 관한 크기를 가리킨다.</p>
</blockquote>
<ul>
<li><strong><code>max_seq_length</code></strong></li>
</ul>
<blockquote>
<p>토큰 기준 입력 문장 최대 길이. 이보다 긴 문장은 <code>max_seq_length</code>로 자르고, 짧은 문장은 <code>max_seq_length</code>가 되도록 스페셜 토큰([PAD])를 붙여준다.</p>
</blockquote>
<ul>
<li><strong><code>epochs</code></strong></li>
</ul>
<blockquote>
<p>학습 에포크 수. 3이라면 학습 데이터 전체를 3회 반복 학습합니다.</p>
</blockquote>
<ul>
<li><strong><code>tpu_cores</code></strong></li>
</ul>
<blockquote>
<p>TPU 코어 수. 하드웨어 가속기로 GPU를 선택했다면 0, TPU라면 8.</p>
</blockquote>
<ul>
<li><strong><code>seed</code></strong></li>
</ul>
<blockquote>
<p>랜덤 시드(정수). <code>None</code>을 입력하면 랜덤 시드를 고정하지 않는다.</p>
</blockquote>
<h3 id="" class="text-xl font-bold mt-6 mb-3">랜덤 시드 고정</h3>
<p>랜덤 시드를 설정.</p>
<p>code 1-4는 <code>args</code>에 지정된 시드로 고정하는 역할을 한다.</p>
<h4>code 1-4</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp <span class="hljs-keyword">import</span> nlpbook
nlpbook.set_seed(args)
</code></pre>
<pre><code>set seed: 7
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">로거 설정</h3>
<p>각종 로그를 출력하는 로거를 설정.</p>
<h4>code 1-5</h4>
<pre><code class="hljs language-python">nlpbook.set_logger(args)
</code></pre>
<pre><code>INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name=&#x27;beomi/kcbert-base&#x27;, downstream_task_name=&#x27;document-classification&#x27;, downstream_corpus_name=&#x27;nsmc&#x27;, downstream_corpus_root_dir=&#x27;/content/Korpora&#x27;, downstream_model_dir=&#x27;/gdrive/My Drive/nlpbook/checkpoint-doccls&#x27;, max_seq_length=128, save_top_k=1, monitor=&#x27;min val_loss&#x27;, seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)
</code></pre>
<h2 id="2" class="text-2xl font-bold mt-8 mb-4">2. 말뭉치 내려받기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">말뭉치 내려 받기</h3>
<p>NSMC 데이터를 내려받는다. 데이터를 내려받는 도구로 <strong>코포라</strong>(Korpora*)라는 파이썬 오픈소스 패키지를 사용해, corpus_name(nsmc)에 해당하는 말뭉치를 root_dir(/root/Korpora) 아래에 저장해 둔다.</p>
<ul>
<li>Korpora*: github.com/ko-nlp/korpora</li>
</ul>
<h4>code 1-6</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> Korpora <span class="hljs-keyword">import</span> Korpora
Korpora.fetch(
    corpus_name=args.downstream_corpus_name,
    root_dir=args.downstream_corpus_root_dir,
    force_download=<span class="hljs-literal">True</span>,
) 
</code></pre>
<pre><code>[nsmc] download ratings_train.txt: 14.6MB [00:00, 75.6MB/s]                           
[nsmc] download ratings_test.txt: 4.90MB [00:00, 33.9MB/s]                           
</code></pre>
<h2 id="3" class="text-2xl font-bold mt-8 mb-4">3. 토크나이저 준비하기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">토크나이저 준비</h3>
<p>본 프로젝트에서 다루는 데이터의 기본 단위는 텍스트 형태의 문장이다. 토큰화란 문장을 토큰 시퀀스로 분절하는 과정을 가리킨다. 본 실습에서 사용하는 모델은 자연어 문장을 분절한 토큰 시퀀스를 입력 받는다.</p>
<p>code 1-7를 실행해 kcbert-base 모델이 사용하는 토크나이저를 선언한다.</p>
<p>토크나이저는 토큰화를 수행하는 프로그램이라는 뜻이다.</p>
<h4>code 1-7</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=<span class="hljs-literal">False</span>,
)
</code></pre>
<pre><code>Downloading:   0%|          | 0.00/250k [00:00&lt;?, ?B/s]



Downloading:   0%|          | 0.00/49.0 [00:00&lt;?, ?B/s]



Downloading:   0%|          | 0.00/619 [00:00&lt;?, ?B/s]
</code></pre>
<h2 id="4" class="text-2xl font-bold mt-8 mb-4">4. 데이터 전처리하기</h2>
<p>딥러닝 모델을 학습하려면 학습 데이터를 배치 단위로 계속 모델에 공급해 주어야 한다. 파이토치에서는 이 역할을 <strong>데이터 로더</strong>(dataloader)가 수행한다.</p>
<p>데이터 로더는 <strong>데이터셋</strong>(dataset)이 보유하고 있는 인스턴스를 배치 크기만큼 뽑아서 자료형, 데이터 길이 등 정해진 형식에 맞춰 배치를 만들어 준다.</p>
<h3 id="" class="text-xl font-bold mt-6 mb-3">학습 데이터셋 구축</h3>
<p>code 1-8을 통해 <strong>ClassificationDataset</strong>을 만들 수 있다.
<strong>ClassificationDataset</strong>의 가장 큰 역할은 모든 인스턴스를 가지고 있다가 데이터 로더가 배치를 만들 때 인스턴스를 제공하는 일이다.</p>
<h4>code 1-8</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> NsmcCorpus, ClassificationDataset
corpus = NsmcCorpus()
train_dataset = ClassificationDataset(
    args=args,
    corpus=corpus,
    tokenizer=tokenizer,
    mode=<span class="hljs-string">&quot;train&quot;</span>,
)
</code></pre>
<pre><code>INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc
INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt
INFO:ratsnlp:tokenize sentences, it could take a lot of time...
INFO:ratsnlp:tokenize sentences [took 42.255 s]
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 아 더빙.. 진짜 짜증나네요 목소리
INFO:ratsnlp:tokens: [CLS] 아 더 ##빙 . . 진짜 짜증나네 ##요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2170, 832, 5045, 17, 17, 7992, 29734, 4040, 10720, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나
INFO:ratsnlp:tokens: [CLS] 흠 . . . 포 ##스터 ##보고 초딩 ##영화 ##줄 . . . . 오버 ##연기 ##조차 가볍 ##지 않 ##구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 1
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 3521, 17, 17, 17, 3294, 13069, 8190, 10635, 13796, 4006, 17, 17, 17, 17, 17613, 19625, 9790, 17775, 4102, 2175, 8030, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 너무재밓었다그래서보는것을추천한다
INFO:ratsnlp:tokens: [CLS] 너무 ##재 ##밓 ##었다 ##그래 ##서 ##보는 ##것을 ##추 ##천 ##한다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8069, 4089, 7847, 8217, 9791, 4072, 9136, 8750, 4142, 4244, 8008, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정
INFO:ratsnlp:tokens: [CLS] 교도소 이야기 ##구먼 . . 솔직히 재미 ##는 없다 . . 평 ##점 조정 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 12164, 9089, 9828, 17, 17, 8876, 10827, 4008, 8131, 17, 17, 3288, 4213, 16612, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다
INFO:ratsnlp:tokens: [CLS] 사이 ##몬 ##페 ##그 ##의 익 ##살 ##스런 연기 ##가 돋 ##보 ##였던 영화 ! 스파이 ##더 ##맨 ##에서 늙어 ##보이 ##기만 했던 커 ##스 ##틴 던 ##스트 ##가 너무나도 이뻐 ##보 ##였다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 1
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8538, 4880, 4335, 4313, 4042, 2452, 4471, 10670, 11219, 4009, 870, 4010, 13043, 9376, 5, 24034, 4356, 4617, 7971, 22878, 11980, 9235, 10129, 3010, 4103, 4713, 834, 8795, 4009, 22110, 23997, 4010, 9827, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
INFO:ratsnlp:Saving features into cached file, it could take a lot of time...
INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 23.322 s]
</code></pre>
<h3 id="object-object" class="text-xl font-bold mt-6 mb-3"><strong>ClassificationDataset</strong> 클래스가 하는 역할</h3>
<p>이 클래스는 <strong>NsmcCorpus</strong>와 위에서 선언해 둔 **토크나이저(tokenizer)**를 품고 있다.</p>
<p><strong>NsmcCorpus</strong>는 CSV 파일 형식의 NSMC 데이터를 문장과 레이블*(예를 들면 영화 리뷰와 긍정 및 부정)*으로 읽는다.</p>
<p><strong>NsmcCorpus</strong>는 <strong>ClassificationDataset</strong>이 요구하면 이 문장과 레이블을 <strong>ClassificationDataset</strong>에 제공한다.</p>
<p><strong>ClassificationDataset</strong>은 제공받은 문장과 레이블 각각을 tokenizer를 활용해 모델이 학습할 수 있는 형태(<strong>ClassificationFeature</strong>)로 가공한다.</p>
<p><strong>ClassificationFeature</strong>라는 자료형에는 총 4가지의 정보가 있다.</p>
<ul>
<li>
<p>첫번째는 **<code>input_id</code>**이다. 인덱스로 변환된 토큰 시퀀스이다.</p>
</li>
<li>
<p>두번째는 **<code>attention_mask</code>**로 해당 토큰이 패딩 토큰인지(0) 아닌지(1)를 나타낸다.</p>
</li>
<li>
<p><strong><code>token_type_ids</code></strong> 세그먼트 정보, **<code>label</code>**은 정수로 바뀐 레이블 정보 이다.</p>
</li>
</ul>
<p><strong><code>ClassificationFeatures</code></strong> 각 구성 요소의 자료형은 다음과 같다.</p>
<ul>
<li><strong><code>input_ids</code></strong> : <code>List[int]</code></li>
<li><strong><code>attention_mask</code></strong> : <code>List[int]</code></li>
<li><strong><code>token_type_ids</code></strong> : <code>Listh[int]</code></li>
<li><strong><code>label</code></strong> : <code>int</code></li>
</ul>
<h3 id="" class="text-xl font-bold mt-6 mb-3">학습 데이터 로더 구축</h3>
<p>code 1-9를 통해 학습할 때 쓰이는 데이터 로더를 만들 수 있다. 데이터 로더는 ClassificationDataset클래스가 들고 있는 전체 인스턴스 가운데 배치 크기(<em>code 1-3에서 정의한</em> <code>args</code><em>의</em> <code>batch_size</code>)만큼을 뽑아 배치 형태로 가공(<code>nlpbook.data_collator</code>)하는 역할을 수행한다.</p>
<h4>code 1-9</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, RandomSampler
train_dataloader = DataLoader(
    train_dataset,
    batch_size=args.batch_size,
    sampler=RandomSampler(train_dataset, replacement=<span class="hljs-literal">False</span>),
    collate_fn=nlpbook.data_collator,
    drop_last=<span class="hljs-literal">False</span>,
    num_workers=args.cpu_workers,
)
</code></pre>
<p>코드를 자세히 보면 <code>sampler</code>와 <code>collate_fn</code>이 눈에 띈다.
전자는 샘플링 방식을 정의한다.</p>
<p>여기서 만든 데이터 로더는 배치를 만들 때 <code>ClassificationDataset</code>이 들고 있는 전체 인스턴스 가운데 <code>batch_size</code> 개수만큼 비복원(<strong><code>replacement=False</code></strong>) 랜덤 추출(RandomSampler)한다.</p>
<p><code>collate_fn</code>은 이렇게 뽑은 인스턴스들을 배치로 만드는 역할을 하는 함수이다. <code>nlpbook.data_collator</code>는 같은 배치에서 인스턴스가 여럿일 때 이를 <code>input_ids</code>, <code>attention_mask</code> 등 종류별로 모으고 파이토치가 요구하는 자료형인 텐서(<code>tensor</code>)형태로 바꾸는 역할을 수행한다.</p>
<h3 id="" class="text-xl font-bold mt-6 mb-3">평가용 데이터 로더 구축</h3>
<p>평가용 데이터 로더는 학습용 데이터 로더와 달리 **<code>SequentialSampler</code>**를 사용한다. <code>SequentialSampler</code>는 인스턴스를 <code>batch_size</code>만큼 순서대로 추출하는 역할을 한다. 학습 때 배치 구성은 랜덤으로 하는 것이 좋은데, 평가할 때는 평가용 데이터 전체를 사용하므로 굳이 랜덤으로 구성할 이유가 없어 <code>SequentialSampler</code>를 사용한다.</p>
<p>code 1-10을 통해 평가용 데이터 로더를 구축한다.</p>
<h4>code 1-10</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> SequentialSampler
val_dataset = ClassificationDataset(
    args=args,
    corpus=corpus,
    tokenizer=tokenizer,
    mode=<span class="hljs-string">&quot;test&quot;</span>,
)
val_dataloader= DataLoader(
    val_dataset,
    batch_size=args.batch_size,
    sampler=SequentialSampler(val_dataset),
    collate_fn=nlpbook.data_collator,
    drop_last=<span class="hljs-literal">False</span>,
    num_workers=args.cpu_workers,
)
</code></pre>
<pre><code>INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc
INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt
INFO:ratsnlp:tokenize sentences, it could take a lot of time...
INFO:ratsnlp:tokenize sentences [took 14.198 s]
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 굳 ㅋ
INFO:ratsnlp:tokens: [CLS] 굳 ㅋ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 1
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 352, 192, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: GDNTOPCLASSINTHECLUB
INFO:ratsnlp:tokens: [CLS] G ##D ##N ##TO ##P ##C ##L ##A ##S ##S ##I ##N ##T ##H ##E ##C ##L ##U ##B [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 40, 4452, 4581, 25144, 4579, 4881, 4450, 4580, 4985, 4985, 4506, 4581, 4850, 5121, 4451, 4881, 4450, 5167, 4756, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아
INFO:ratsnlp:tokens: [CLS] 뭐야 이 평 ##점 ##들은 . . . . 나쁘 ##진 않지만 10 ##점 짜리 ##는 더더욱 아니잖아 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 10691, 2451, 3288, 4213, 7977, 17, 17, 17, 17, 10476, 4153, 15426, 8240, 4213, 21394, 4008, 15616, 13439, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 지루하지는 않은데 완전 막장임... 돈주고 보기에는....
INFO:ratsnlp:tokens: [CLS] 지 ##루 ##하지는 않은데 완전 막장 ##임 . . . 돈주고 보기에 ##는 . . . . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2688, 4532, 16036, 20879, 8357, 15971, 4252, 17, 17, 17, 13900, 25253, 4008, 17, 17, 17, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:*** Example ***
INFO:ratsnlp:sentence: 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??
INFO:ratsnlp:tokens: [CLS] 3 ##D ##만 아니었 ##어도 별 다섯 개 줬 ##을텐데 . . 왜 3 ##D ##로 나와서 제 심 ##기를 불편 ##하게 하죠 ? ? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
INFO:ratsnlp:label: 0
INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 22, 4452, 4049, 18851, 8194, 1558, 23887, 220, 2648, 9243, 17, 17, 2332, 22, 4452, 4091, 10045, 2545, 2015, 8313, 10588, 8007, 18566, 32, 32, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
INFO:ratsnlp:Saving features into cached file, it could take a lot of time...
INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 7.800 s]
</code></pre>
<h2 id="5" class="text-2xl font-bold mt-8 mb-4">5. 모델 불러오기</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">모델 초기화</h3>
<p>code 1-3**(1. 각종 설정하기-모델 환경 설정)**에서 <code>pretrained_model_name</code>을 <code>beomi/kebert-base</code>로 지정했으므로 프리트레인을 마친 BERT로 <code>kcbert-base</code>를 사용한다.</p>
<p>모델을 초기화하는 코드에서 <code>BertForSequenceClassification</code>은 프리트레인을 마친 BERT 모델 위에 문서 분류용 태스크 모듈이 덧붙여진 형태의 모델 클래스이다. 이 클래스는 허깅페이스에서 제공하는 <code>transformers</code> 라이브러리에 포함되어 있다.</p>
<h4>code 1-11</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertForSequenceClassification
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=corpus.num_labels,
)
model = BertForSequenceClassification.from_pretrained(
    args.pretrained_model_name,
    config=pretrained_model_config,
)
</code></pre>
<pre><code>Downloading:   0%|          | 0.00/438M [00:00&lt;?, ?B/s]


Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: [&#x27;cls.seq_relationship.bias&#x27;, &#x27;cls.predictions.transform.dense.bias&#x27;, &#x27;cls.predictions.decoder.bias&#x27;, &#x27;cls.predictions.transform.LayerNorm.weight&#x27;, &#x27;cls.seq_relationship.weight&#x27;, &#x27;cls.predictions.transform.dense.weight&#x27;, &#x27;cls.predictions.bias&#x27;, &#x27;cls.predictions.transform.LayerNorm.bias&#x27;, &#x27;cls.predictions.decoder.weight&#x27;]
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: [&#x27;classifier.weight&#x27;, &#x27;classifier.bias&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
<h2 id="6" class="text-2xl font-bold mt-8 mb-4">6. 모델 학습시키기</h2>
<p>파이토치 라이트닝(pytorch lightning*)이 제공하는 <code>LightningModule</code> 클래스를 상속받아 태스크(task)를 정의한다. 태스크에는 모델과 옵티마이저, 학습 과정 등이 정의되어 있다.</p>
<ul>
<li>pytorch lightning*: github.com/PyTorchLightning/pytorch-lightning</li>
</ul>
<h3 id="t" class="text-xl font-bold mt-6 mb-3">Task 정의</h3>
<p>code 1-3**(1. 각종 설정하기-모델 환경 설정)<strong>에서 만든 학습 설정(<code>args</code>)과 code 1-11</strong>(5. 모델 불러오기-모델초기화)**에서 준비한 모델(<code>model</code>)을 <code>ClassificationTask</code>에 주입한다. <code>ClassificationTask</code>에는 <strong>옵티마이저</strong>(optimizer), <strong>러닝 레이트 스케줄러</strong>(learnig rate scheduler)가 정의되어 있다. 옵티마이저로는 <strong>아담</strong>(Adam), 러닝 레이트 스케줄러로는 <code>ExponentialLR</code>을 사용한다.</p>
<p>code1-12를 통해 문서 분류용 태스크를 정의할 수 있다.</p>
<h4>code 1-12</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> ClassificationTask
task = ClassificationTask(model, args)
</code></pre>
<p>&#x27;Do it! 자연어 처리&#x27;의 저자 이기창 님의 비유를 인용하자면,</p>
<hr/>
<p><em>모델 학습 과정은 눈을 가린 상태에서 산등성이를 한 걸음씩 내려가는 과정과 같다. 러닝 레이트는 한 번 내려갈 때 얼마나 이동할지 보폭에 해당한다.</em></p>
<hr/>
<p>학습이 진행되는 동안 점차 러닝 레이트를 줄여 세밀하게 탐색하면 좀 더 좋은 모델을 만들 수 있다. 이 역할을 하는 게 바로 러닝 레이트 스케줄러이다. <code>ExponentialLR</code>은 현재 에포크(epoch*)의 러닝 메이트를 &#x27;이전 에포크의 러닝 레이트 x gamma&#x27;로 스케줄링 한다. 본 예제에서는 gamma를 0.9로 설정하였다.</p>
<ul>
<li>에포크: 데이터 전체를 학습하는 횟수. 만일 에포크가 3이라면 데이터를 3번 반복 학습한다는 뜻이다.</li>
</ul>
<h3 id="" class="text-xl font-bold mt-6 mb-3">트레이너 정의</h3>
<p>code 1-13을 통해 트레이너를 정의할 수 있다. 이 트레이너는 파이토치 라이트닝 라이브러리의 도움을 받아 GPU/TPU 설정, 로그 및 체크포인트 등 귀찮은 설정을 알아서 해 준다.</p>
<h4>code 1-13</h4>
<pre><code class="hljs language-python">trainer = nlpbook.get_trainer(args)
</code></pre>
<pre><code>/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /gdrive/My Drive/nlpbook/checkpoint-doccls exists and is not empty.
  warnings.warn(*args, **kwargs)
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">학습 개시</h3>
<p>code 1-14처럼 트레이너의 <code>fit()</code>함수를 호출하면 학습을 시작한다. 학습 시간은 자신의 코랩 환경에 따라 다를 수 있으나 꽤 오래 걸릴 수 있다. 학습이 진행되는 도중 브라우저를 끄면 모델 학습을 비롯한 코랩 실행이 중단되니 주의해야한다.</p>
<h4>code 1-14</h4>
<pre><code class="hljs language-python">trainer.fit(
    task,
    train_dataloader=train_dataloader,
    val_dataloaders=val_dataloader,
)
</code></pre>
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type                          | Params
--------------------------------------------------------
0 | model | BertForSequenceClassification | 108 M 
--------------------------------------------------------
108 M     Trainable params
0         Non-trainable params
108 M     Total params
435.680   Total estimated model params size (MB)



Training: 114it [00:00, ?it/s]



Validating: 0it [00:00, ?it/s]



Validating: 0it [00:00, ?it/s]
</code></pre>
<hr/>
<h1 id="object-object" class="text-3xl font-bold mt-8 mb-4"><strong>문서 분류 모델 학습</strong>을 요약하자면</h1>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">각종 설정을 마친 뒤 말뭉치를 내려받아 전처리한다. 프리트레인을 마친 모델을 이 데이터에 맞게 파인 튜닝한다.</h1><div class="mt-10 border-t pt-10"></div></article></div><!--$--><!--/$--><script src="/_next/static/chunks/webpack-1c8036505c2e140d.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9766,[],\"\"]\n3:I[8924,[],\"\"]\n5:I[4431,[],\"OutletBoundary\"]\n7:I[5278,[],\"AsyncMetadataOutlet\"]\n9:I[4431,[],\"ViewportBoundary\"]\nb:I[4431,[],\"MetadataBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[7150,[],\"\"]\n:HL[\"/_next/static/css/51e5ba5c7de07f80.css\",\"style\"]\n:HL[\"/_next/static/css/5eacd01f773eed7f.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"xTAnN8PQ3b6-LdzNENhZ7\",\"p\":\"\",\"c\":[\"\",\"2022-03-25-classification_model_train\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"2022-03-25-classification_model_train\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/51e5ba5c7de07f80.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"min-h-screen flex flex-col font-sans\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"slug\",\"2022-03-25-classification_model_train\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5eacd01f773eed7f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$L6\",[\"$\",\"$L7\",null,{\"promise\":\"$@8\"}]]}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],null],[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$c\",null,{\"fallback\":null,\"children\":\"$Ld\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:T11e5,"])</script><script>self.__next_f.push([1,"Collecting torch-xla==1.9\n  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)\nRequirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\nRequirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\nRequirement already satisfied: google-api-core\u003c2dev,\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.26.3)\nRequirement already satisfied: google-auth\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.35.0)\nRequirement already satisfied: uritemplate\u003c4dev,\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.1)\nRequirement already satisfied: six\u003c2dev,\u003e=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.15.0)\nRequirement already satisfied: google-auth-httplib2\u003e=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.0.4)\nRequirement already satisfied: httplib2\u003c1dev,\u003e=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.17.4)\nRequirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.55.0)\nRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2018.9)\nRequirement already satisfied: setuptools\u003e=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (57.4.0)\nRequirement already satisfied: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.17.3)\nRequirement already satisfied: packaging\u003e=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (21.3)\nRequirement already satisfied: requests\u003c3.0.0dev,\u003e=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2.23.0)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.2.8)\nRequirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (4.8)\nRequirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (4.2.4)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=14.3-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.7)\nRequirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.4.8)\nRequirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.24.3)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2021.10.8)\nRequirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2.10)\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"flex gap-10\",\"children\":[[\"$\",\"article\",null,{\"className\":\"flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8 not-prose border-b pb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold mb-4\",\"children\":\"[NLP] 문서 분류 모델 training\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"$D2022-03-25T00:00:00.000Z\",\"children\":\"March 25, 2022\"}],\"$undefined\"]}]]}],[[\"$\",\"p\",\"p-0\",{\"children\":\"자연어처리의 예제를 학습하여 보자.\\n다음은 이전 글에서 설명하였던 문서 분류 모델을 구현한 것이다.\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)\"}],\"\\n\",[\"$\",\"h1\",\"h1-0\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"문서분류 모델 학습하기\"}],\"\\n\",[\"$\",\"h2\",\"h2-0\",{\"id\":\"1\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"1. 각종 설정하기\"}],\"\\n\",[\"$\",\"h3\",\"h3-0\",{\"id\":\"t\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"TPU 관련 패키지 설치\"}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":\"코랩 노트북 초기화 과정에서 하드웨어 가속기로 TPU를 선택했다면 다음 코드를 실행하면 된다.\\n그러면 TPU 관련 라이브러리 들을 설치한다.\"}],\"\\n\",[\"$\",\"p\",\"p-3\",{\"children\":\"(참고로 TPU 학습은 라이브러리 지원 등이 GPU보다 불안정한 편이므로 될 수 있으면 GPU를 사용하기를 권함)\"}],\"\\n\",[\"$\",\"h4\",\"h4-0\",{\"children\":\"code 1-0\"}],\"\\n\",[\"$\",\"pre\",\"pre-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"!pip install cloud-tpu-client==\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"0.10\"}],\" https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-number\",\"children\":\"1.9\"}],\"-cp37-cp37m-linux_x86_64.whl\\n\"]}]}],\"\\n\",[\"$\",\"pre\",\"pre-1\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$f\"}]}],\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\",\"\\n\",\"$L48\",\"\\n\",\"$L49\",\"\\n\",\"$L4a\",\"\\n\",\"$L4b\",\"\\n\",\"$L4c\",\"\\n\",\"$L4d\",\"\\n\",\"$L4e\",\"\\n\",\"$L4f\",\"\\n\",\"$L50\",\"\\n\",\"$L51\",\"\\n\",\"$L52\",\"\\n\",\"$L53\",\"\\n\",\"$L54\",\"\\n\",\"$L55\",\"\\n\",\"$L56\",\"\\n\",\"$L57\",\"\\n\",\"$L58\",\"\\n\",\"$L59\",\"\\n\",\"$L5a\",\"\\n\",\"$L5b\",\"\\n\",\"$L5c\",\"\\n\",\"$L5d\",\"\\n\",\"$L5e\",\"\\n\",\"$L5f\",\"\\n\",\"$L60\",\"\\n\",\"$L61\",\"\\n\",\"$L62\",\"\\n\",\"$L63\",\"\\n\",\"$L64\",\"\\n\",\"$L65\",\"\\n\",\"$L66\",\"\\n\",\"$L67\",\"\\n\",\"$L68\",\"\\n\",\"$L69\",\"\\n\",\"$L6a\",\"\\n\",\"$L6b\",\"\\n\",\"$L6c\",\"\\n\",\"$L6d\",\"\\n\",\"$L6e\",\"\\n\",\"$L6f\",\"\\n\",\"$L70\",\"\\n\",\"$L71\",\"\\n\",\"$L72\",\"\\n\",\"$L73\",\"\\n\",\"$L74\",\"\\n\",\"$L75\",\"\\n\",\"$L76\",\"\\n\",\"$L77\",\"\\n\",\"$L78\",\"\\n\",\"$L79\",\"\\n\",\"$L7a\",\"\\n\",\"$L7b\",\"\\n\",\"$L7c\",\"\\n\",\"$L7d\",\"\\n\",\"$L7e\",\"\\n\",\"$L7f\",\"\\n\",\"$L80\",\"\\n\",\"$L81\",\"\\n\",\"$L82\",\"\\n\",\"$L83\",\"\\n\",\"$L84\",\"\\n\",\"$L85\",\"\\n\",\"$L86\",\"\\n\",\"$L87\",\"\\n\",\"$L88\",\"\\n\",\"$L89\",\"\\n\",\"$L8a\",\"\\n\",\"$L8b\",\"\\n\",\"$L8c\",\"\\n\",\"$L8d\"],\"$L8e\"]}],\"$L8f\"]}]\n"])</script><script>self.__next_f.push([1,"94:I[3089,[\"182\",\"static/chunks/app/%5Bslug%5D/page-ad31c54747687caf.js\"],\"default\"]\n95:I[4010,[\"182\",\"static/chunks/app/%5Bslug%5D/page-ad31c54747687caf.js\"],\"default\"]\n10:[\"$\",\"h3\",\"h3-1\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"의존성 패키지 설치\"}]\n11:[\"$\",\"p\",\"p-4\",{\"children\":\"다음 코드는 TPU이외에 의존성 있는 패키지를 설치한다.\"}]\n12:[\"$\",\"p\",\"p-5\",{\"children\":\"명령어 맨 앞에 붙은 느낌표(!)는 코랩 환경에서 파이썬이 아닌, 셸(shell)명령을 수행한다는 의미이다.\"}]\n13:[\"$\",\"h4\",\"h4-1\",{\"children\":\"code 1-1\"}]\n14:[\"$\",\"pre\",\"pre-2\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"!pip install ratsnlp\\n\"}]}]\n90:T2695,"])</script><script>self.__next_f.push([1,"Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\nRequirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\nRequirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\nRequirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\nRequirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\nRequirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\nRequirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\nRequirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\nRequirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\nRequirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\nRequirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\nRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.62.3)\nRequirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\nRequirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\nRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\nRequirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\nRequirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\nRequirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\nRequirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\nRequirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\nRequirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\nRequirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\nRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\nRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\nRequirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\nRequirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\nRequirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\nRequirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\nRequirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\nRequirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\nRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\nRequirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\nRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\nRequirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\nRequirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\nRequirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\nRequirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.44.0)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\nRequirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\nRequirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\nRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\nRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\nRequirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\nRequirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\nRequirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\nRequirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\nRequirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\nRequirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\nRequirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\nRequirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\nRequirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n"])</script><script>self.__next_f.push([1,"15:[\"$\",\"pre\",\"pre-3\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$90\"}]}]\n16:[\"$\",\"h3\",\"h3-2\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"구글 드라이브와 연결\"}]\n17:[\"$\",\"p\",\"p-6\",{\"children\":\"코랩 노트북은 일정시간 사용하지 않으면 당시까지의 모든 결과물이 날아갈 수 있다. 모델 체크포인트 등을 저장해 두기 위해 자신의 구글 드라이브를 코랩 노트북과 연결한다.\"}]\n18:[\"$\",\"h4\",\"h4-2\",{\"children\":\"code 1-2\"}]\n19:[\"$\",\"pre\",\"pre-4\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" google.colab \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" drive\\ndrive.mount(\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"'/gdrive'\"}],\", force_remount=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\")\\n\"]}]}]\n1a:[\"$\",\"pre\",\"pre-5\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"Mounted at /gdrive\\n\"}]}]\n1b:[\"$\",\"h3\",\"h3-3\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"모델 환경 설정\"}]\n1c:[\"$\",\"p\",\"p-7\",{\"children\":\"kcbert-base 모델을 NSMC데이터로 파인튜닝\"}]\n1d:[\"$\",\"h4\",\"h4-3\",{\"children\":\"code 1-3\"}]\n"])</script><script>self.__next_f.push([1,"1e:[\"$\",\"pre\",\"pre-6\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch\\n\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" ClassificationTrainArguments\\nargs = ClassificationTrainArguments(\\n    pretrained_model_name=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-string\",\"children\":\"\\\"beomi/kcbert-base\\\"\"}],\",\\n    downstream_corpus_name=\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-string\",\"children\":\"\\\"nsmc\\\"\"}],\",\\n    downstream_model_dir=\",[\"$\",\"span\",\"span-5\",{\"className\":\"hljs-string\",\"children\":\"\\\"/gdrive/My Drive/nlpbook/checkpoint-doccls\\\"\"}],\",\\n    batch_size=\",[\"$\",\"span\",\"span-6\",{\"className\":\"hljs-number\",\"children\":\"32\"}],\" \",[\"$\",\"span\",\"span-7\",{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" torch.cuda.is_available() \",[\"$\",\"span\",\"span-8\",{\"className\":\"hljs-keyword\",\"children\":\"else\"}],\" \",[\"$\",\"span\",\"span-9\",{\"className\":\"hljs-number\",\"children\":\"4\"}],\",\\n    learning_rate=\",[\"$\",\"span\",\"span-10\",{\"className\":\"hljs-number\",\"children\":\"5e-5\"}],\",\\n    max_seq_length=\",[\"$\",\"span\",\"span-11\",{\"className\":\"hljs-number\",\"children\":\"128\"}],\",\\n    epochs=\",[\"$\",\"span\",\"span-12\",{\"className\":\"hljs-number\",\"children\":\"3\"}],\",\\n    tpu_cores=\",[\"$\",\"span\",\"span-13\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\" \",[\"$\",\"span\",\"span-14\",{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" torch.cuda.is_available() \",[\"$\",\"span\",\"span-15\",{\"className\":\"hljs-keyword\",\"children\":\"else\"}],\" \",[\"$\",\"span\",\"span-16\",{\"className\":\"hljs-number\",\"children\":\"8\"}],\",\\n    seed=\",[\"$\",\"span\",\"span-17\",{\"className\":\"hljs-number\",\"children\":\"7\"}],\",\\n)\\n\"]}]}]\n"])</script><script>self.__next_f.push([1,"1f:[\"$\",\"p\",\"p-8\",{\"children\":\"참고로 TrainArguments의 각 인자가 하는 역할과 의미는 다음과 같다.\"}]\n20:[\"$\",\"ul\",\"ul-0\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"pretrained_model_name\"}]}]}],\"\\n\"]}]\n21:[\"$\",\"blockquote\",\"blockquote-0\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"프리트레인 마친 언어 모델의 이름 (단, 해당 모델은 허깅페이스 모델 허브에 등록되어 있어야 한다.)\"}],\"\\n\"]}]\n22:[\"$\",\"ul\",\"ul-1\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"downstream_corpus_name\"}]}]}],\"\\n\"]}]\n23:[\"$\",\"blockquote\",\"blockquote-1\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"다운스트림 데이터의 이름\"}],\"\\n\"]}]\n24:[\"$\",\"ul\",\"ul-2\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"downstream_corpus_root_dir\"}]}]}],\"\\n\"]}]\n25:[\"$\",\"blockquote\",\"blockquote-2\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"다운스트림 데이터를 내려받을 위치. 입력하지 않으면 /root/Korpora에 저장된다.\"}],\"\\n\"]}]\n26:[\"$\",\"ul\",\"ul-3\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"downstream_model_dir\"}]}]}],\"\\n\"]}]\n27:[\"$\",\"blockquote\",\"blockquote-3\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"파인튜닝된 모델의 체크포인트가 저장될 위치. gdrive/My Drive/nlpbook/checkpoint-doccs로 지정하면 자신의 구글 드라이브 [내 폴더] 아래 npbook/checkpoint-doccls디렉터리에 저장된다.\"}],\"\\n\"]}]\n28:[\"$\",\"ul\",\"ul-4\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"batch_size\"}]}]}],\"\\n\"]}]\n29:[\"$\",\"blockquote\",\"blockquote-4\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"배치 크기. 하드웨어 가속기로 GPU를 선택(\",[\"$\",\"code\",\"code-0\",{\"children\":\"torch.cuda.is"])</script><script>self.__next_f.push([1,"_available() == True\"}],\")했다면 32, TPU라면(\",[\"$\",\"code\",\"code-1\",{\"children\":\"torch.cuda.is_available() == False\"}],\") 4. 코랩 환경에서 TPU는 보통 8개의 코어가 할당되는데 batch_size는 코어별로 적용되는 배치 크기이므로 이렇게 설정해 둔다.\"]}],\"\\n\"]}]\n2a:[\"$\",\"ul\",\"ul-5\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"learning_rate\"}]}]}],\"\\n\"]}]\n2b:[\"$\",\"blockquote\",\"blockquote-5\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"러닝 레이트(보폭). 1회 스텝에서 모델을 얼마나 업데이트할지에 관한 크기를 가리킨다.\"}],\"\\n\"]}]\n2c:[\"$\",\"ul\",\"ul-6\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"max_seq_length\"}]}]}],\"\\n\"]}]\n2d:[\"$\",\"blockquote\",\"blockquote-6\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"토큰 기준 입력 문장 최대 길이. 이보다 긴 문장은 \",[\"$\",\"code\",\"code-0\",{\"children\":\"max_seq_length\"}],\"로 자르고, 짧은 문장은 \",[\"$\",\"code\",\"code-1\",{\"children\":\"max_seq_length\"}],\"가 되도록 스페셜 토큰([PAD])를 붙여준다.\"]}],\"\\n\"]}]\n2e:[\"$\",\"ul\",\"ul-7\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"epochs\"}]}]}],\"\\n\"]}]\n2f:[\"$\",\"blockquote\",\"blockquote-7\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"학습 에포크 수. 3이라면 학습 데이터 전체를 3회 반복 학습합니다.\"}],\"\\n\"]}]\n30:[\"$\",\"ul\",\"ul-8\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"tpu_cores\"}]}]}],\"\\n\"]}]\n31:[\"$\",\"blockquote\",\"blockquote-8\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":\"TPU 코어 수. 하드웨어 가속기로 GPU를 선택했다면 0, TPU라면 8.\"}],\"\\n\"]}]\n32:[\"$\",\"ul\",\"ul-9\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"seed\"}]}]}],\"\\n\"]}]\n33:[\"$"])</script><script>self.__next_f.push([1,"\",\"blockquote\",\"blockquote-9\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"랜덤 시드(정수). \",[\"$\",\"code\",\"code-0\",{\"children\":\"None\"}],\"을 입력하면 랜덤 시드를 고정하지 않는다.\"]}],\"\\n\"]}]\n34:[\"$\",\"h3\",\"h3-4\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"랜덤 시드 고정\"}]\n35:[\"$\",\"p\",\"p-9\",{\"children\":\"랜덤 시드를 설정.\"}]\n36:[\"$\",\"p\",\"p-10\",{\"children\":[\"code 1-4는 \",[\"$\",\"code\",\"code-0\",{\"children\":\"args\"}],\"에 지정된 시드로 고정하는 역할을 한다.\"]}]\n37:[\"$\",\"h4\",\"h4-4\",{\"children\":\"code 1-4\"}]\n38:[\"$\",\"pre\",\"pre-7\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" nlpbook\\nnlpbook.set_seed(args)\\n\"]}]}]\n39:[\"$\",\"pre\",\"pre-8\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"set seed: 7\\n\"}]}]\n3a:[\"$\",\"h3\",\"h3-5\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"로거 설정\"}]\n3b:[\"$\",\"p\",\"p-11\",{\"children\":\"각종 로그를 출력하는 로거를 설정.\"}]\n3c:[\"$\",\"h4\",\"h4-5\",{\"children\":\"code 1-5\"}]\n3d:[\"$\",\"pre\",\"pre-9\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"nlpbook.set_logger(args)\\n\"}]}]\n3e:[\"$\",\"pre\",\"pre-10\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='document-classification', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-doccls', max_seq_length=128, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\\n\"}]}]\n3f:[\"$\",\"h2\",\"h2-1\",{\"id\":\"2\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"2. 말뭉치 내려받기\"}]\n40:[\"$\",\"h3\","])</script><script>self.__next_f.push([1,"\"h3-6\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"말뭉치 내려 받기\"}]\n41:[\"$\",\"p\",\"p-12\",{\"children\":[\"NSMC 데이터를 내려받는다. 데이터를 내려받는 도구로 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"코포라\"}],\"(Korpora*)라는 파이썬 오픈소스 패키지를 사용해, corpus_name(nsmc)에 해당하는 말뭉치를 root_dir(/root/Korpora) 아래에 저장해 둔다.\"]}]\n42:[\"$\",\"ul\",\"ul-10\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"Korpora*: github.com/ko-nlp/korpora\"}],\"\\n\"]}]\n43:[\"$\",\"h4\",\"h4-6\",{\"children\":\"code 1-6\"}]\n44:[\"$\",\"pre\",\"pre-11\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" Korpora \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" Korpora\\nKorpora.fetch(\\n    corpus_name=args.downstream_corpus_name,\\n    root_dir=args.downstream_corpus_root_dir,\\n    force_download=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\",\\n) \\n\"]}]}]\n45:[\"$\",\"pre\",\"pre-12\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"[nsmc] download ratings_train.txt: 14.6MB [00:00, 75.6MB/s]                           \\n[nsmc] download ratings_test.txt: 4.90MB [00:00, 33.9MB/s]                           \\n\"}]}]\n46:[\"$\",\"h2\",\"h2-2\",{\"id\":\"3\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"3. 토크나이저 준비하기\"}]\n47:[\"$\",\"h3\",\"h3-7\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"토크나이저 준비\"}]\n48:[\"$\",\"p\",\"p-13\",{\"children\":\"본 프로젝트에서 다루는 데이터의 기본 단위는 텍스트 형태의 문장이다. 토큰화란 문장을 토큰 시퀀스로 분절하는 과정을 가리킨다. 본 실습에서 사용하는 모델은 자연어 문장을 분절한 토큰 시퀀스를 입력 받는다.\"}]\n49:[\"$\",\"p\",\"p-14\",{\"children\":\"code 1-7를 실행해 kcbert-base 모델이 사용하는 토크나이저를 선언한다.\"}]\n4a:[\"$\",\"p\",\"p-15\",{\"children\":\"토크나이저는 토큰화"])</script><script>self.__next_f.push([1,"를 수행하는 프로그램이라는 뜻이다.\"}]\n4b:[\"$\",\"h4\",\"h4-7\",{\"children\":\"code 1-7\"}]\n4c:[\"$\",\"pre\",\"pre-13\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertTokenizer\\ntokenizer = BertTokenizer.from_pretrained(\\n    args.pretrained_model_name,\\n    do_lower_case=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-literal\",\"children\":\"False\"}],\",\\n)\\n\"]}]}]\n4d:[\"$\",\"pre\",\"pre-14\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"Downloading:   0%|          | 0.00/250k [00:00\u003c?, ?B/s]\\n\\n\\n\\nDownloading:   0%|          | 0.00/49.0 [00:00\u003c?, ?B/s]\\n\\n\\n\\nDownloading:   0%|          | 0.00/619 [00:00\u003c?, ?B/s]\\n\"}]}]\n4e:[\"$\",\"h2\",\"h2-3\",{\"id\":\"4\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"4. 데이터 전처리하기\"}]\n4f:[\"$\",\"p\",\"p-16\",{\"children\":[\"딥러닝 모델을 학습하려면 학습 데이터를 배치 단위로 계속 모델에 공급해 주어야 한다. 파이토치에서는 이 역할을 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"데이터 로더\"}],\"(dataloader)가 수행한다.\"]}]\n50:[\"$\",\"p\",\"p-17\",{\"children\":[\"데이터 로더는 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"데이터셋\"}],\"(dataset)이 보유하고 있는 인스턴스를 배치 크기만큼 뽑아서 자료형, 데이터 길이 등 정해진 형식에 맞춰 배치를 만들어 준다.\"]}]\n51:[\"$\",\"h3\",\"h3-8\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"학습 데이터셋 구축\"}]\n52:[\"$\",\"p\",\"p-18\",{\"children\":[\"code 1-8을 통해 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"ClassificationDataset\"}],\"을 만들 수 있다.\\n\",[\"$\",\"strong\",\"strong-1\",{\"children\":\"ClassificationDataset\"}],\"의 가장 큰 역할은 모든 인스턴스를 가지고 있다가 데이터 로더가 배치를 만들 때 인스턴스를 제공하는 일이다.\"]}]\n53:[\"$\",\"h4\",\"h4-8\",{\"children\":\"code 1-8\"}]\n54:[\"$\",\"pre\",\"pre-15\",{\"children\":["])</script><script>self.__next_f.push([1,"\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" NsmcCorpus, ClassificationDataset\\ncorpus = NsmcCorpus()\\ntrain_dataset = ClassificationDataset(\\n    args=args,\\n    corpus=corpus,\\n    tokenizer=tokenizer,\\n    mode=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"\\\"train\\\"\"}],\",\\n)\\n\"]}]}]\n91:T2df5,"])</script><script>self.__next_f.push([1,"INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\nINFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\nINFO:ratsnlp:tokenize sentences, it could take a lot of time...\nINFO:ratsnlp:tokenize sentences [took 42.255 s]\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 아 더빙.. 진짜 짜증나네요 목소리\nINFO:ratsnlp:tokens: [CLS] 아 더 ##빙 . . 진짜 짜증나네 ##요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2170, 832, 5045, 17, 17, 7992, 29734, 4040, 10720, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\nINFO:ratsnlp:tokens: [CLS] 흠 . . . 포 ##스터 ##보고 초딩 ##영화 ##줄 . . . . 오버 ##연기 ##조차 가볍 ##지 않 ##구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 1\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 3521, 17, 17, 17, 3294, 13069, 8190, 10635, 13796, 4006, 17, 17, 17, 17, 17613, 19625, 9790, 17775, 4102, 2175, 8030, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 너무재밓었다그래서보는것을추천한다\nINFO:ratsnlp:tokens: [CLS] 너무 ##재 ##밓 ##었다 ##그래 ##서 ##보는 ##것을 ##추 ##천 ##한다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8069, 4089, 7847, 8217, 9791, 4072, 9136, 8750, 4142, 4244, 8008, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\nINFO:ratsnlp:tokens: [CLS] 교도소 이야기 ##구먼 . . 솔직히 재미 ##는 없다 . . 평 ##점 조정 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 12164, 9089, 9828, 17, 17, 8876, 10827, 4008, 8131, 17, 17, 3288, 4213, 16612, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\nINFO:ratsnlp:tokens: [CLS] 사이 ##몬 ##페 ##그 ##의 익 ##살 ##스런 연기 ##가 돋 ##보 ##였던 영화 ! 스파이 ##더 ##맨 ##에서 늙어 ##보이 ##기만 했던 커 ##스 ##틴 던 ##스트 ##가 너무나도 이뻐 ##보 ##였다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 1\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8538, 4880, 4335, 4313, 4042, 2452, 4471, 10670, 11219, 4009, 870, 4010, 13043, 9376, 5, 24034, 4356, 4617, 7971, 22878, 11980, 9235, 10129, 3010, 4103, 4713, 834, 8795, 4009, 22110, 23997, 4010, 9827, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\nINFO:ratsnlp:Saving features into cached file, it could take a lot of time...\nINFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 23.322 s]\n"])</script><script>self.__next_f.push([1,"55:[\"$\",\"pre\",\"pre-16\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$91\"}]}]\n56:[\"$\",\"h3\",\"h3-9\",{\"id\":\"object-object\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"ClassificationDataset\"}],\" 클래스가 하는 역할\"]}]\n57:[\"$\",\"p\",\"p-19\",{\"children\":[\"이 클래스는 \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"NsmcCorpus\"}],\"와 위에서 선언해 둔 **토크나이저(tokenizer)**를 품고 있다.\"]}]\n58:[\"$\",\"p\",\"p-20\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"NsmcCorpus\"}],\"는 CSV 파일 형식의 NSMC 데이터를 문장과 레이블*(예를 들면 영화 리뷰와 긍정 및 부정)*으로 읽는다.\"]}]\n59:[\"$\",\"p\",\"p-21\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"NsmcCorpus\"}],\"는 \",[\"$\",\"strong\",\"strong-1\",{\"children\":\"ClassificationDataset\"}],\"이 요구하면 이 문장과 레이블을 \",[\"$\",\"strong\",\"strong-2\",{\"children\":\"ClassificationDataset\"}],\"에 제공한다.\"]}]\n5a:[\"$\",\"p\",\"p-22\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"ClassificationDataset\"}],\"은 제공받은 문장과 레이블 각각을 tokenizer를 활용해 모델이 학습할 수 있는 형태(\",[\"$\",\"strong\",\"strong-1\",{\"children\":\"ClassificationFeature\"}],\")로 가공한다.\"]}]\n5b:[\"$\",\"p\",\"p-23\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"ClassificationFeature\"}],\"라는 자료형에는 총 4가지의 정보가 있다.\"]}]\n5c:[\"$\",\"ul\",\"ul-11\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"첫번째는 **\",[\"$\",\"code\",\"code-0\",{\"children\":\"input_id\"}],\"**이다. 인덱스로 변환된 토큰 시퀀스이다.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[\"두번째는 **\",[\"$\",\"code\",\"code-0\",{\"children\":\"attention_mask\"}],\"**로 해당 토큰이 패딩 토큰인지(0) 아닌지(1)를 나타낸다.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[\"\\n\",[\"$\",\"p\",\"p-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"token_type_ids\"}]}],\" 세그먼"])</script><script>self.__next_f.push([1,"트 정보, **\",[\"$\",\"code\",\"code-0\",{\"children\":\"label\"}],\"**은 정수로 바뀐 레이블 정보 이다.\"]}],\"\\n\"]}],\"\\n\"]}]\n5d:[\"$\",\"p\",\"p-24\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"ClassificationFeatures\"}]}],\" 각 구성 요소의 자료형은 다음과 같다.\"]}]\n"])</script><script>self.__next_f.push([1,"5e:[\"$\",\"ul\",\"ul-12\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"input_ids\"}]}],\" : \",[\"$\",\"code\",\"code-0\",{\"children\":\"List[int]\"}]]}],\"\\n\",[\"$\",\"li\",\"li-1\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"attention_mask\"}]}],\" : \",[\"$\",\"code\",\"code-0\",{\"children\":\"List[int]\"}]]}],\"\\n\",[\"$\",\"li\",\"li-2\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"token_type_ids\"}]}],\" : \",[\"$\",\"code\",\"code-0\",{\"children\":\"Listh[int]\"}]]}],\"\\n\",[\"$\",\"li\",\"li-3\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"label\"}]}],\" : \",[\"$\",\"code\",\"code-0\",{\"children\":\"int\"}]]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"5f:[\"$\",\"h3\",\"h3-10\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"학습 데이터 로더 구축\"}]\n60:[\"$\",\"p\",\"p-25\",{\"children\":[\"code 1-9를 통해 학습할 때 쓰이는 데이터 로더를 만들 수 있다. 데이터 로더는 ClassificationDataset클래스가 들고 있는 전체 인스턴스 가운데 배치 크기(\",[\"$\",\"em\",\"em-0\",{\"children\":\"code 1-3에서 정의한\"}],\" \",[\"$\",\"code\",\"code-0\",{\"children\":\"args\"}],[\"$\",\"em\",\"em-1\",{\"children\":\"의\"}],\" \",[\"$\",\"code\",\"code-1\",{\"children\":\"batch_size\"}],\")만큼을 뽑아 배치 형태로 가공(\",[\"$\",\"code\",\"code-2\",{\"children\":\"nlpbook.data_collator\"}],\")하는 역할을 수행한다.\"]}]\n61:[\"$\",\"h4\",\"h4-9\",{\"children\":\"code 1-9\"}]\n"])</script><script>self.__next_f.push([1,"62:[\"$\",\"pre\",\"pre-17\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" torch.utils.data \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" DataLoader, RandomSampler\\ntrain_dataloader = DataLoader(\\n    train_dataset,\\n    batch_size=args.batch_size,\\n    sampler=RandomSampler(train_dataset, replacement=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-literal\",\"children\":\"False\"}],\"),\\n    collate_fn=nlpbook.data_collator,\\n    drop_last=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-literal\",\"children\":\"False\"}],\",\\n    num_workers=args.cpu_workers,\\n)\\n\"]}]}]\n"])</script><script>self.__next_f.push([1,"63:[\"$\",\"p\",\"p-26\",{\"children\":[\"코드를 자세히 보면 \",[\"$\",\"code\",\"code-0\",{\"children\":\"sampler\"}],\"와 \",[\"$\",\"code\",\"code-1\",{\"children\":\"collate_fn\"}],\"이 눈에 띈다.\\n전자는 샘플링 방식을 정의한다.\"]}]\n64:[\"$\",\"p\",\"p-27\",{\"children\":[\"여기서 만든 데이터 로더는 배치를 만들 때 \",[\"$\",\"code\",\"code-0\",{\"children\":\"ClassificationDataset\"}],\"이 들고 있는 전체 인스턴스 가운데 \",[\"$\",\"code\",\"code-1\",{\"children\":\"batch_size\"}],\" 개수만큼 비복원(\",[\"$\",\"strong\",\"strong-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"replacement=False\"}]}],\") 랜덤 추출(RandomSampler)한다.\"]}]\n65:[\"$\",\"p\",\"p-28\",{\"children\":[[\"$\",\"code\",\"code-0\",{\"children\":\"collate_fn\"}],\"은 이렇게 뽑은 인스턴스들을 배치로 만드는 역할을 하는 함수이다. \",[\"$\",\"code\",\"code-1\",{\"children\":\"nlpbook.data_collator\"}],\"는 같은 배치에서 인스턴스가 여럿일 때 이를 \",[\"$\",\"code\",\"code-2\",{\"children\":\"input_ids\"}],\", \",[\"$\",\"code\",\"code-3\",{\"children\":\"attention_mask\"}],\" 등 종류별로 모으고 파이토치가 요구하는 자료형인 텐서(\",[\"$\",\"code\",\"code-4\",{\"children\":\"tensor\"}],\")형태로 바꾸는 역할을 수행한다.\"]}]\n66:[\"$\",\"h3\",\"h3-11\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"평가용 데이터 로더 구축\"}]\n67:[\"$\",\"p\",\"p-29\",{\"children\":[\"평가용 데이터 로더는 학습용 데이터 로더와 달리 **\",[\"$\",\"code\",\"code-0\",{\"children\":\"SequentialSampler\"}],\"**를 사용한다. \",[\"$\",\"code\",\"code-1\",{\"children\":\"SequentialSampler\"}],\"는 인스턴스를 \",[\"$\",\"code\",\"code-2\",{\"children\":\"batch_size\"}],\"만큼 순서대로 추출하는 역할을 한다. 학습 때 배치 구성은 랜덤으로 하는 것이 좋은데, 평가할 때는 평가용 데이터 전체를 사용하므로 굳이 랜덤으로 구성할 이유가 없어 \",[\"$\",\"code\",\"code-3\",{\"children\":\"SequentialSampler\"}],\"를 사용한다.\"]}]\n68:[\"$\",\"p\",\"p-30\",{\"children\":\"code 1-10을 통해 평가용 데이터 로더를 구축"])</script><script>self.__next_f.push([1,"한다.\"}]\n69:[\"$\",\"h4\",\"h4-10\",{\"children\":\"code 1-10\"}]\n"])</script><script>self.__next_f.push([1,"6a:[\"$\",\"pre\",\"pre-18\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" torch.utils.data \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" SequentialSampler\\nval_dataset = ClassificationDataset(\\n    args=args,\\n    corpus=corpus,\\n    tokenizer=tokenizer,\\n    mode=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"\\\"test\\\"\"}],\",\\n)\\nval_dataloader= DataLoader(\\n    val_dataset,\\n    batch_size=args.batch_size,\\n    sampler=SequentialSampler(val_dataset),\\n    collate_fn=nlpbook.data_collator,\\n    drop_last=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-literal\",\"children\":\"False\"}],\",\\n    num_workers=args.cpu_workers,\\n)\\n\"]}]}]\n"])</script><script>self.__next_f.push([1,"92:T2cff,"])</script><script>self.__next_f.push([1,"INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\nINFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\nINFO:ratsnlp:tokenize sentences, it could take a lot of time...\nINFO:ratsnlp:tokenize sentences [took 14.198 s]\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 굳 ㅋ\nINFO:ratsnlp:tokens: [CLS] 굳 ㅋ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 1\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 352, 192, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: GDNTOPCLASSINTHECLUB\nINFO:ratsnlp:tokens: [CLS] G ##D ##N ##TO ##P ##C ##L ##A ##S ##S ##I ##N ##T ##H ##E ##C ##L ##U ##B [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 40, 4452, 4581, 25144, 4579, 4881, 4450, 4580, 4985, 4985, 4506, 4581, 4850, 5121, 4451, 4881, 4450, 5167, 4756, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\nINFO:ratsnlp:tokens: [CLS] 뭐야 이 평 ##점 ##들은 . . . . 나쁘 ##진 않지만 10 ##점 짜리 ##는 더더욱 아니잖아 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 10691, 2451, 3288, 4213, 7977, 17, 17, 17, 17, 10476, 4153, 15426, 8240, 4213, 21394, 4008, 15616, 13439, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\nINFO:ratsnlp:tokens: [CLS] 지 ##루 ##하지는 않은데 완전 막장 ##임 . . . 돈주고 보기에 ##는 . . . . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2688, 4532, 16036, 20879, 8357, 15971, 4252, 17, 17, 17, 13900, 25253, 4008, 17, 17, 17, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:*** Example ***\nINFO:ratsnlp:sentence: 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\nINFO:ratsnlp:tokens: [CLS] 3 ##D ##만 아니었 ##어도 별 다섯 개 줬 ##을텐데 . . 왜 3 ##D ##로 나와서 제 심 ##기를 불편 ##하게 하죠 ? ? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\nINFO:ratsnlp:label: 0\nINFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 22, 4452, 4049, 18851, 8194, 1558, 23887, 220, 2648, 9243, 17, 17, 2332, 22, 4452, 4091, 10045, 2545, 2015, 8313, 10588, 8007, 18566, 32, 32, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\nINFO:ratsnlp:Saving features into cached file, it could take a lot of time...\nINFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 7.800 s]\n"])</script><script>self.__next_f.push([1,"6b:[\"$\",\"pre\",\"pre-19\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$92\"}]}]\n6c:[\"$\",\"h2\",\"h2-4\",{\"id\":\"5\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"5. 모델 불러오기\"}]\n6d:[\"$\",\"h3\",\"h3-12\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"모델 초기화\"}]\n6e:[\"$\",\"p\",\"p-31\",{\"children\":[\"code 1-3**(1. 각종 설정하기-모델 환경 설정)**에서 \",[\"$\",\"code\",\"code-0\",{\"children\":\"pretrained_model_name\"}],\"을 \",[\"$\",\"code\",\"code-1\",{\"children\":\"beomi/kebert-base\"}],\"로 지정했으므로 프리트레인을 마친 BERT로 \",[\"$\",\"code\",\"code-2\",{\"children\":\"kcbert-base\"}],\"를 사용한다.\"]}]\n6f:[\"$\",\"p\",\"p-32\",{\"children\":[\"모델을 초기화하는 코드에서 \",[\"$\",\"code\",\"code-0\",{\"children\":\"BertForSequenceClassification\"}],\"은 프리트레인을 마친 BERT 모델 위에 문서 분류용 태스크 모듈이 덧붙여진 형태의 모델 클래스이다. 이 클래스는 허깅페이스에서 제공하는 \",[\"$\",\"code\",\"code-1\",{\"children\":\"transformers\"}],\" 라이브러리에 포함되어 있다.\"]}]\n70:[\"$\",\"h4\",\"h4-11\",{\"children\":\"code 1-11\"}]\n71:[\"$\",\"pre\",\"pre-20\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertConfig, BertForSequenceClassification\\npretrained_model_config = BertConfig.from_pretrained(\\n    args.pretrained_model_name,\\n    num_labels=corpus.num_labels,\\n)\\nmodel = BertForSequenceClassification.from_pretrained(\\n    args.pretrained_model_name,\\n    config=pretrained_model_config,\\n)\\n\"]}]}]\n93:T508,"])</script><script>self.__next_f.push([1,"Downloading:   0%|          | 0.00/438M [00:00\u003c?, ?B/s]\n\n\nSome weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"])</script><script>self.__next_f.push([1,"72:[\"$\",\"pre\",\"pre-21\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$93\"}]}]\n73:[\"$\",\"h2\",\"h2-5\",{\"id\":\"6\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"6. 모델 학습시키기\"}]\n74:[\"$\",\"p\",\"p-33\",{\"children\":[\"파이토치 라이트닝(pytorch lightning*)이 제공하는 \",[\"$\",\"code\",\"code-0\",{\"children\":\"LightningModule\"}],\" 클래스를 상속받아 태스크(task)를 정의한다. 태스크에는 모델과 옵티마이저, 학습 과정 등이 정의되어 있다.\"]}]\n75:[\"$\",\"ul\",\"ul-13\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"pytorch lightning*: github.com/PyTorchLightning/pytorch-lightning\"}],\"\\n\"]}]\n76:[\"$\",\"h3\",\"h3-13\",{\"id\":\"t\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"Task 정의\"}]\n"])</script><script>self.__next_f.push([1,"77:[\"$\",\"p\",\"p-34\",{\"children\":[\"code 1-3**(1. 각종 설정하기-모델 환경 설정)\",[\"$\",\"strong\",\"strong-0\",{\"children\":[\"에서 만든 학습 설정(\",[\"$\",\"code\",\"code-0\",{\"children\":\"args\"}],\")과 code 1-11\"]}],\"(5. 모델 불러오기-모델초기화)**에서 준비한 모델(\",[\"$\",\"code\",\"code-0\",{\"children\":\"model\"}],\")을 \",[\"$\",\"code\",\"code-1\",{\"children\":\"ClassificationTask\"}],\"에 주입한다. \",[\"$\",\"code\",\"code-2\",{\"children\":\"ClassificationTask\"}],\"에는 \",[\"$\",\"strong\",\"strong-1\",{\"children\":\"옵티마이저\"}],\"(optimizer), \",[\"$\",\"strong\",\"strong-2\",{\"children\":\"러닝 레이트 스케줄러\"}],\"(learnig rate scheduler)가 정의되어 있다. 옵티마이저로는 \",[\"$\",\"strong\",\"strong-3\",{\"children\":\"아담\"}],\"(Adam), 러닝 레이트 스케줄러로는 \",[\"$\",\"code\",\"code-3\",{\"children\":\"ExponentialLR\"}],\"을 사용한다.\"]}]\n"])</script><script>self.__next_f.push([1,"78:[\"$\",\"p\",\"p-35\",{\"children\":\"code1-12를 통해 문서 분류용 태스크를 정의할 수 있다.\"}]\n79:[\"$\",\"h4\",\"h4-12\",{\"children\":\"code 1-12\"}]\n7a:[\"$\",\"pre\",\"pre-22\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" ClassificationTask\\ntask = ClassificationTask(model, args)\\n\"]}]}]\n7b:[\"$\",\"p\",\"p-36\",{\"children\":\"'Do it! 자연어 처리'의 저자 이기창 님의 비유를 인용하자면,\"}]\n7c:[\"$\",\"hr\",\"hr-0\",{}]\n7d:[\"$\",\"p\",\"p-37\",{\"children\":[\"$\",\"em\",\"em-0\",{\"children\":\"모델 학습 과정은 눈을 가린 상태에서 산등성이를 한 걸음씩 내려가는 과정과 같다. 러닝 레이트는 한 번 내려갈 때 얼마나 이동할지 보폭에 해당한다.\"}]}]\n7e:[\"$\",\"hr\",\"hr-1\",{}]\n7f:[\"$\",\"p\",\"p-38\",{\"children\":[\"학습이 진행되는 동안 점차 러닝 레이트를 줄여 세밀하게 탐색하면 좀 더 좋은 모델을 만들 수 있다. 이 역할을 하는 게 바로 러닝 레이트 스케줄러이다. \",[\"$\",\"code\",\"code-0\",{\"children\":\"ExponentialLR\"}],\"은 현재 에포크(epoch*)의 러닝 메이트를 '이전 에포크의 러닝 레이트 x gamma'로 스케줄링 한다. 본 예제에서는 gamma를 0.9로 설정하였다.\"]}]\n80:[\"$\",\"ul\",\"ul-14\",{\"children\":[\"\\n\",[\"$\",\"li\",\"li-0\",{\"children\":\"에포크: 데이터 전체를 학습하는 횟수. 만일 에포크가 3이라면 데이터를 3번 반복 학습한다는 뜻이다.\"}],\"\\n\"]}]\n81:[\"$\",\"h3\",\"h3-14\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"트레이너 정의\"}]\n82:[\"$\",\"p\",\"p-39\",{\"children\":\"code 1-13을 통해 트레이너를 정의할 수 있다. 이 트레이너는 파이토치 라이트닝 라이브러리의 도움을 받아 GPU/TPU 설정, 로그 및 체크포인트 등 귀찮은 설정을 알아서 해 준다.\"}]\n83:[\"$\",\"h4\",\"h4-13\",{\"children\":\"code 1-13\"}]\n84:[\"$\",\"pre\","])</script><script>self.__next_f.push([1,"\"pre-23\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"trainer = nlpbook.get_trainer(args)\\n\"}]}]\n85:[\"$\",\"pre\",\"pre-24\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /gdrive/My Drive/nlpbook/checkpoint-doccls exists and is not empty.\\n  warnings.warn(*args, **kwargs)\\nGPU available: True, used: True\\nTPU available: False, using: 0 TPU cores\\n\"}]}]\n86:[\"$\",\"h3\",\"h3-15\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"학습 개시\"}]\n87:[\"$\",\"p\",\"p-40\",{\"children\":[\"code 1-14처럼 트레이너의 \",[\"$\",\"code\",\"code-0\",{\"children\":\"fit()\"}],\"함수를 호출하면 학습을 시작한다. 학습 시간은 자신의 코랩 환경에 따라 다를 수 있으나 꽤 오래 걸릴 수 있다. 학습이 진행되는 도중 브라우저를 끄면 모델 학습을 비롯한 코랩 실행이 중단되니 주의해야한다.\"]}]\n88:[\"$\",\"h4\",\"h4-14\",{\"children\":\"code 1-14\"}]\n89:[\"$\",\"pre\",\"pre-25\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"trainer.fit(\\n    task,\\n    train_dataloader=train_dataloader,\\n    val_dataloaders=val_dataloader,\\n)\\n\"}]}]\n8a:[\"$\",\"pre\",\"pre-26\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\\n\\n  | Name  | Type                          | Params\\n--------------------------------------------------------\\n0 | model | BertForSequenceClassification | 108 M \\n--------------------------------------------------------\\n108 M     Trainable params\\n0         Non-trainable params\\n108 M     Total params\\n435.680   Total estimated model params size (MB)\\n\\n\\n\\nTraining: 114it [00:00, ?it/s]\\n\\n\\n\\nValidating: 0it [00:00, ?it/s]\\n\\n\\n\\nValidating: 0it [00:00, ?it/s]\\n\"}]}]\n8b:[\"$\",\"hr\",\"hr-2\",{}]\n8c:[\"$\",\"h1\",\"h1-1\",{\"id\":\"object-object\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"문서 분류 모델 학습\"}],\"을 "])</script><script>self.__next_f.push([1,"요약하자면\"]}]\n8d:[\"$\",\"h1\",\"h1-2\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"각종 설정을 마친 뒤 말뭉치를 내려받아 전처리한다. 프리트레인을 마친 모델을 이 데이터에 맞게 파인 튜닝한다.\"}]\n8e:[\"$\",\"$L94\",null,{}]\n96:Td79a,"])</script><script>self.__next_f.push([1,"\n자연어처리의 예제를 학습하여 보자.\n다음은 이전 글에서 설명하였던 문서 분류 모델을 구현한 것이다.\n\n본 파일은 이기창님의 'Do it! 자연어 처리'에 기초하여 작성되었다! :)\n\n# 문서분류 모델 학습하기\n\n## 1. 각종 설정하기\n\n### TPU 관련 패키지 설치\n\n코랩 노트북 초기화 과정에서 하드웨어 가속기로 TPU를 선택했다면 다음 코드를 실행하면 된다.\n그러면 TPU 관련 라이브러리 들을 설치한다.\n\n(참고로 TPU 학습은 라이브러리 지원 등이 GPU보다 불안정한 편이므로 될 수 있으면 GPU를 사용하기를 권함)\n\n#### code 1-0\n\n\n```python\n!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n```\n\n    Collecting torch-xla==1.9\n      Using cached https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)\n    Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n    Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n    Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n    Requirement already satisfied: google-api-core\u003c2dev,\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.26.3)\n    Requirement already satisfied: google-auth\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.35.0)\n    Requirement already satisfied: uritemplate\u003c4dev,\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.1)\n    Requirement already satisfied: six\u003c2dev,\u003e=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.15.0)\n    Requirement already satisfied: google-auth-httplib2\u003e=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.0.4)\n    Requirement already satisfied: httplib2\u003c1dev,\u003e=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.17.4)\n    Requirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.55.0)\n    Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2018.9)\n    Requirement already satisfied: setuptools\u003e=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (57.4.0)\n    Requirement already satisfied: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.17.3)\n    Requirement already satisfied: packaging\u003e=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (21.3)\n    Requirement already satisfied: requests\u003c3.0.0dev,\u003e=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2.23.0)\n    Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.2.8)\n    Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (4.8)\n    Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (4.2.4)\n    Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=14.3-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.7)\n    Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003e=1.4.1-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (0.4.8)\n    Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (3.0.4)\n    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (1.24.3)\n    Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2021.10.8)\n    Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core\u003c2dev,\u003e=1.13.0-\u003egoogle-api-python-client==1.8.0-\u003ecloud-tpu-client==0.10) (2.10)\n    \n\n### 의존성 패키지 설치\n\n다음 코드는 TPU이외에 의존성 있는 패키지를 설치한다. \n\n명령어 맨 앞에 붙은 느낌표(!)는 코랩 환경에서 파이썬이 아닌, 셸(shell)명령을 수행한다는 의미이다.\n\n#### code 1-1\n\n\n```python\n!pip install ratsnlp\n```\n\n    Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\n    Requirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\n    Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\n    Requirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\n    Requirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\n    Requirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\n    Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\n    Requirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n    Requirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\n    Requirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\n    Requirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\n    Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.62.3)\n    Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\n    Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\n    Requirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\n    Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\n    Requirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\n    Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\n    Requirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\n    Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\n    Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.1)\n    Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\n    Requirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\n    Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\n    Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\n    Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\n    Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\n    Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\n    Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\n    Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\n    Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\n    Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\n    Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\n    Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\n    Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\n    Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\n    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\n    Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\n    Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\n    Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\n    Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\n    Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\n    Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\n    Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\n    Requirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\n    Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\n    Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.44.0)\n    Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\n    Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\n    Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\n    Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\n    Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\n    Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\n    Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\n    Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\n    Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\n    Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\n    Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\n    Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\n    Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\n    Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\n    Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\n    Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n    \n\n### 구글 드라이브와 연결\n\n코랩 노트북은 일정시간 사용하지 않으면 당시까지의 모든 결과물이 날아갈 수 있다. 모델 체크포인트 등을 저장해 두기 위해 자신의 구글 드라이브를 코랩 노트북과 연결한다.\n\n#### code 1-2\n\n\n```python\nfrom google.colab import drive\ndrive.mount('/gdrive', force_remount=True)\n```\n\n    Mounted at /gdrive\n    \n\n### 모델 환경 설정\nkcbert-base 모델을 NSMC데이터로 파인튜닝\n\n#### code 1-3\n\n\n```python\nimport torch\nfrom ratsnlp.nlpbook.classification import ClassificationTrainArguments\nargs = ClassificationTrainArguments(\n    pretrained_model_name=\"beomi/kcbert-base\",\n    downstream_corpus_name=\"nsmc\",\n    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",\n    batch_size=32 if torch.cuda.is_available() else 4,\n    learning_rate=5e-5,\n    max_seq_length=128,\n    epochs=3,\n    tpu_cores=0 if torch.cuda.is_available() else 8,\n    seed=7,\n)\n```\n\n참고로 TrainArguments의 각 인자가 하는 역할과 의미는 다음과 같다.\n\n\n\n*    **`pretrained_model_name`**\n\u003e 프리트레인 마친 언어 모델의 이름 (단, 해당 모델은 허깅페이스 모델 허브에 등록되어 있어야 한다.)\n\n*    **`downstream_corpus_name`**\n\u003e 다운스트림 데이터의 이름\n\n*    **`downstream_corpus_root_dir`**\n\u003e 다운스트림 데이터를 내려받을 위치. 입력하지 않으면 /root/Korpora에 저장된다.\n\n*    **`downstream_model_dir`**\n\u003e 파인튜닝된 모델의 체크포인트가 저장될 위치. gdrive/My Drive/nlpbook/checkpoint-doccs로 지정하면 자신의 구글 드라이브 [내 폴더] 아래 npbook/checkpoint-doccls디렉터리에 저장된다.\n\n*    **`batch_size`**\n\u003e 배치 크기. 하드웨어 가속기로 GPU를 선택(`torch.cuda.is_available() == True`)했다면 32, TPU라면(`torch.cuda.is_available() == False`) 4. 코랩 환경에서 TPU는 보통 8개의 코어가 할당되는데 batch_size는 코어별로 적용되는 배치 크기이므로 이렇게 설정해 둔다.\n\n*    **`learning_rate`**\n\u003e 러닝 레이트(보폭). 1회 스텝에서 모델을 얼마나 업데이트할지에 관한 크기를 가리킨다. \n\n*   **`max_seq_length`**\n\u003e 토큰 기준 입력 문장 최대 길이. 이보다 긴 문장은 `max_seq_length`로 자르고, 짧은 문장은 `max_seq_length`가 되도록 스페셜 토큰([PAD])를 붙여준다.\n\n*    **`epochs`**\n\u003e 학습 에포크 수. 3이라면 학습 데이터 전체를 3회 반복 학습합니다.\n\n*    **`tpu_cores`**\n\u003e TPU 코어 수. 하드웨어 가속기로 GPU를 선택했다면 0, TPU라면 8.\n\n*    **`seed`**\n\u003e 랜덤 시드(정수). `None`을 입력하면 랜덤 시드를 고정하지 않는다.\n\n\n\n### 랜덤 시드 고정\n\n랜덤 시드를 설정.\n\ncode 1-4는 `args`에 지정된 시드로 고정하는 역할을 한다.\n\n#### code 1-4\n\n\n```python\nfrom ratsnlp import nlpbook\nnlpbook.set_seed(args)\n```\n\n    set seed: 7\n    \n\n### 로거 설정\n\n각종 로그를 출력하는 로거를 설정.\n\n#### code 1-5\n\n\n```python\nnlpbook.set_logger(args)\n```\n\n    INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='document-classification', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-doccls', max_seq_length=128, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n    \n\n## 2. 말뭉치 내려받기\n\n### 말뭉치 내려 받기\n\nNSMC 데이터를 내려받는다. 데이터를 내려받는 도구로 **코포라**(Korpora*)라는 파이썬 오픈소스 패키지를 사용해, corpus_name(nsmc)에 해당하는 말뭉치를 root_dir(/root/Korpora) 아래에 저장해 둔다.\n\n* Korpora*: github.com/ko-nlp/korpora\n\n#### code 1-6\n\n\n```python\nfrom Korpora import Korpora\nKorpora.fetch(\n    corpus_name=args.downstream_corpus_name,\n    root_dir=args.downstream_corpus_root_dir,\n    force_download=True,\n) \n```\n\n    [nsmc] download ratings_train.txt: 14.6MB [00:00, 75.6MB/s]                           \n    [nsmc] download ratings_test.txt: 4.90MB [00:00, 33.9MB/s]                           \n    \n\n## 3. 토크나이저 준비하기\n\n### 토크나이저 준비\n\n  본 프로젝트에서 다루는 데이터의 기본 단위는 텍스트 형태의 문장이다. 토큰화란 문장을 토큰 시퀀스로 분절하는 과정을 가리킨다. 본 실습에서 사용하는 모델은 자연어 문장을 분절한 토큰 시퀀스를 입력 받는다. \n\ncode 1-7를 실행해 kcbert-base 모델이 사용하는 토크나이저를 선언한다.\n\n토크나이저는 토큰화를 수행하는 프로그램이라는 뜻이다.\n\n#### code 1-7\n\n\n```python\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\n    args.pretrained_model_name,\n    do_lower_case=False,\n)\n```\n\n\n    Downloading:   0%|          | 0.00/250k [00:00\u003c?, ?B/s]\n\n\n\n    Downloading:   0%|          | 0.00/49.0 [00:00\u003c?, ?B/s]\n\n\n\n    Downloading:   0%|          | 0.00/619 [00:00\u003c?, ?B/s]\n\n\n## 4. 데이터 전처리하기\n\n딥러닝 모델을 학습하려면 학습 데이터를 배치 단위로 계속 모델에 공급해 주어야 한다. 파이토치에서는 이 역할을 **데이터 로더**(dataloader)가 수행한다.\n\n데이터 로더는 **데이터셋**(dataset)이 보유하고 있는 인스턴스를 배치 크기만큼 뽑아서 자료형, 데이터 길이 등 정해진 형식에 맞춰 배치를 만들어 준다.\n\n### 학습 데이터셋 구축\n\ncode 1-8을 통해 **ClassificationDataset**을 만들 수 있다.\n**ClassificationDataset**의 가장 큰 역할은 모든 인스턴스를 가지고 있다가 데이터 로더가 배치를 만들 때 인스턴스를 제공하는 일이다.\n\n#### code 1-8\n\n\n```python\nfrom ratsnlp.nlpbook.classification import NsmcCorpus, ClassificationDataset\ncorpus = NsmcCorpus()\ntrain_dataset = ClassificationDataset(\n    args=args,\n    corpus=corpus,\n    tokenizer=tokenizer,\n    mode=\"train\",\n)\n```\n\n    INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n    INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n    INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n    INFO:ratsnlp:tokenize sentences [took 42.255 s]\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 아 더빙.. 진짜 짜증나네요 목소리\n    INFO:ratsnlp:tokens: [CLS] 아 더 ##빙 . . 진짜 짜증나네 ##요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2170, 832, 5045, 17, 17, 7992, 29734, 4040, 10720, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n    INFO:ratsnlp:tokens: [CLS] 흠 . . . 포 ##스터 ##보고 초딩 ##영화 ##줄 . . . . 오버 ##연기 ##조차 가볍 ##지 않 ##구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 1\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 3521, 17, 17, 17, 3294, 13069, 8190, 10635, 13796, 4006, 17, 17, 17, 17, 17613, 19625, 9790, 17775, 4102, 2175, 8030, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 너무재밓었다그래서보는것을추천한다\n    INFO:ratsnlp:tokens: [CLS] 너무 ##재 ##밓 ##었다 ##그래 ##서 ##보는 ##것을 ##추 ##천 ##한다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8069, 4089, 7847, 8217, 9791, 4072, 9136, 8750, 4142, 4244, 8008, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n    INFO:ratsnlp:tokens: [CLS] 교도소 이야기 ##구먼 . . 솔직히 재미 ##는 없다 . . 평 ##점 조정 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 12164, 9089, 9828, 17, 17, 8876, 10827, 4008, 8131, 17, 17, 3288, 4213, 16612, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n    INFO:ratsnlp:tokens: [CLS] 사이 ##몬 ##페 ##그 ##의 익 ##살 ##스런 연기 ##가 돋 ##보 ##였던 영화 ! 스파이 ##더 ##맨 ##에서 늙어 ##보이 ##기만 했던 커 ##스 ##틴 던 ##스트 ##가 너무나도 이뻐 ##보 ##였다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 1\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 8538, 4880, 4335, 4313, 4042, 2452, 4471, 10670, 11219, 4009, 870, 4010, 13043, 9376, 5, 24034, 4356, 4617, 7971, 22878, 11980, 9235, 10129, 3010, 4103, 4713, 834, 8795, 4009, 22110, 23997, 4010, 9827, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n    INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n    INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_BertTokenizer_128_nsmc_document-classification [took 23.322 s]\n    \n\n### **ClassificationDataset** 클래스가 하는 역할\n\n이 클래스는 **NsmcCorpus**와 위에서 선언해 둔 **토크나이저(tokenizer)**를 품고 있다.\n\n**NsmcCorpus**는 CSV 파일 형식의 NSMC 데이터를 문장과 레이블*(예를 들면 영화 리뷰와 긍정 및 부정)*으로 읽는다.\n\n**NsmcCorpus**는 **ClassificationDataset**이 요구하면 이 문장과 레이블을 **ClassificationDataset**에 제공한다.\n\n **ClassificationDataset**은 제공받은 문장과 레이블 각각을 tokenizer를 활용해 모델이 학습할 수 있는 형태(**ClassificationFeature**)로 가공한다.\n\n **ClassificationFeature**라는 자료형에는 총 4가지의 정보가 있다.\n* 첫번째는 **`input_id`**이다. 인덱스로 변환된 토큰 시퀀스이다. \n\n* 두번째는 **`attention_mask`**로 해당 토큰이 패딩 토큰인지(0) 아닌지(1)를 나타낸다. \n\n* **`token_type_ids`** 세그먼트 정보, **`label`**은 정수로 바뀐 레이블 정보 이다.\n\n**`ClassificationFeatures`** 각 구성 요소의 자료형은 다음과 같다.\n\n*   **`input_ids`** : `List[int]`\n*   **`attention_mask`** : `List[int]`\n*   **`token_type_ids`** : `Listh[int]`\n*   **`label`** : `int`\n\n\n\n\n\n\n\n### 학습 데이터 로더 구축\n\ncode 1-9를 통해 학습할 때 쓰이는 데이터 로더를 만들 수 있다. 데이터 로더는 ClassificationDataset클래스가 들고 있는 전체 인스턴스 가운데 배치 크기(*code 1-3에서 정의한* `args`*의* `batch_size`)만큼을 뽑아 배치 형태로 가공(`nlpbook.data_collator`)하는 역할을 수행한다.\n\n#### code 1-9\n\n\n```python\nfrom torch.utils.data import DataLoader, RandomSampler\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=args.batch_size,\n    sampler=RandomSampler(train_dataset, replacement=False),\n    collate_fn=nlpbook.data_collator,\n    drop_last=False,\n    num_workers=args.cpu_workers,\n)\n```\n\n코드를 자세히 보면 `sampler`와 `collate_fn`이 눈에 띈다.\n전자는 샘플링 방식을 정의한다.\n\n 여기서 만든 데이터 로더는 배치를 만들 때 `ClassificationDataset`이 들고 있는 전체 인스턴스 가운데 `batch_size` 개수만큼 비복원(**`replacement=False`**) 랜덤 추출(RandomSampler)한다.\n\n`collate_fn`은 이렇게 뽑은 인스턴스들을 배치로 만드는 역할을 하는 함수이다. `nlpbook.data_collator`는 같은 배치에서 인스턴스가 여럿일 때 이를 `input_ids`, `attention_mask` 등 종류별로 모으고 파이토치가 요구하는 자료형인 텐서(`tensor`)형태로 바꾸는 역할을 수행한다.\n\n### 평가용 데이터 로더 구축\n\n평가용 데이터 로더는 학습용 데이터 로더와 달리 **`SequentialSampler`**를 사용한다. `SequentialSampler`는 인스턴스를 `batch_size`만큼 순서대로 추출하는 역할을 한다. 학습 때 배치 구성은 랜덤으로 하는 것이 좋은데, 평가할 때는 평가용 데이터 전체를 사용하므로 굳이 랜덤으로 구성할 이유가 없어 `SequentialSampler`를 사용한다.\n\ncode 1-10을 통해 평가용 데이터 로더를 구축한다.\n\n#### code 1-10\n\n\n```python\nfrom torch.utils.data import SequentialSampler\nval_dataset = ClassificationDataset(\n    args=args,\n    corpus=corpus,\n    tokenizer=tokenizer,\n    mode=\"test\",\n)\nval_dataloader= DataLoader(\n    val_dataset,\n    batch_size=args.batch_size,\n    sampler=SequentialSampler(val_dataset),\n    collate_fn=nlpbook.data_collator,\n    drop_last=False,\n    num_workers=args.cpu_workers,\n)\n```\n\n    INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n    INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n    INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n    INFO:ratsnlp:tokenize sentences [took 14.198 s]\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 굳 ㅋ\n    INFO:ratsnlp:tokens: [CLS] 굳 ㅋ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 1\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 352, 192, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: GDNTOPCLASSINTHECLUB\n    INFO:ratsnlp:tokens: [CLS] G ##D ##N ##TO ##P ##C ##L ##A ##S ##S ##I ##N ##T ##H ##E ##C ##L ##U ##B [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 40, 4452, 4581, 25144, 4579, 4881, 4450, 4580, 4985, 4985, 4506, 4581, 4850, 5121, 4451, 4881, 4450, 5167, 4756, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n    INFO:ratsnlp:tokens: [CLS] 뭐야 이 평 ##점 ##들은 . . . . 나쁘 ##진 않지만 10 ##점 짜리 ##는 더더욱 아니잖아 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 10691, 2451, 3288, 4213, 7977, 17, 17, 17, 17, 10476, 4153, 15426, 8240, 4213, 21394, 4008, 15616, 13439, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n    INFO:ratsnlp:tokens: [CLS] 지 ##루 ##하지는 않은데 완전 막장 ##임 . . . 돈주고 보기에 ##는 . . . . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 2688, 4532, 16036, 20879, 8357, 15971, 4252, 17, 17, 17, 13900, 25253, 4008, 17, 17, 17, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:*** Example ***\n    INFO:ratsnlp:sentence: 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n    INFO:ratsnlp:tokens: [CLS] 3 ##D ##만 아니었 ##어도 별 다섯 개 줬 ##을텐데 . . 왜 3 ##D ##로 나와서 제 심 ##기를 불편 ##하게 하죠 ? ? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n    INFO:ratsnlp:label: 0\n    INFO:ratsnlp:features: ClassificationFeatures(input_ids=[2, 22, 4452, 4049, 18851, 8194, 1558, 23887, 220, 2648, 9243, 17, 17, 2332, 22, 4452, 4091, 10045, 2545, 2015, 8313, 10588, 8007, 18566, 32, 32, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n    INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n    INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_BertTokenizer_128_nsmc_document-classification [took 7.800 s]\n    \n\n## 5. 모델 불러오기\n\n### 모델 초기화\n\ncode 1-3**(1. 각종 설정하기-모델 환경 설정)**에서 `pretrained_model_name`을 `beomi/kebert-base`로 지정했으므로 프리트레인을 마친 BERT로 `kcbert-base`를 사용한다.\n\n모델을 초기화하는 코드에서 `BertForSequenceClassification`은 프리트레인을 마친 BERT 모델 위에 문서 분류용 태스크 모듈이 덧붙여진 형태의 모델 클래스이다. 이 클래스는 허깅페이스에서 제공하는 `transformers` 라이브러리에 포함되어 있다.\n\n#### code 1-11\n\n\n```python\nfrom transformers import BertConfig, BertForSequenceClassification\npretrained_model_config = BertConfig.from_pretrained(\n    args.pretrained_model_name,\n    num_labels=corpus.num_labels,\n)\nmodel = BertForSequenceClassification.from_pretrained(\n    args.pretrained_model_name,\n    config=pretrained_model_config,\n)\n```\n\n\n    Downloading:   0%|          | 0.00/438M [00:00\u003c?, ?B/s]\n\n\n    Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n    - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n    - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n    Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n    You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n    \n\n## 6. 모델 학습시키기\n\n파이토치 라이트닝(pytorch lightning*)이 제공하는 `LightningModule` 클래스를 상속받아 태스크(task)를 정의한다. 태스크에는 모델과 옵티마이저, 학습 과정 등이 정의되어 있다.\n* pytorch lightning*: github.com/PyTorchLightning/pytorch-lightning \n\n### Task 정의\n\ncode 1-3**(1. 각종 설정하기-모델 환경 설정)**에서 만든 학습 설정(`args`)과 code 1-11**(5. 모델 불러오기-모델초기화)**에서 준비한 모델(`model`)을 `ClassificationTask`에 주입한다. `ClassificationTask`에는 **옵티마이저**(optimizer), **러닝 레이트 스케줄러**(learnig rate scheduler)가 정의되어 있다. 옵티마이저로는 **아담**(Adam), 러닝 레이트 스케줄러로는 `ExponentialLR`을 사용한다.\n\ncode1-12를 통해 문서 분류용 태스크를 정의할 수 있다.\n\n#### code 1-12\n\n\n```python\nfrom ratsnlp.nlpbook.classification import ClassificationTask\ntask = ClassificationTask(model, args)\n```\n\n'Do it! 자연어 처리'의 저자 이기창 님의 비유를 인용하자면,\n\n---\n   *모델 학습 과정은 눈을 가린 상태에서 산등성이를 한 걸음씩 내려가는 과정과 같다. 러닝 레이트는 한 번 내려갈 때 얼마나 이동할지 보폭에 해당한다.*\n\n---\n\n학습이 진행되는 동안 점차 러닝 레이트를 줄여 세밀하게 탐색하면 좀 더 좋은 모델을 만들 수 있다. 이 역할을 하는 게 바로 러닝 레이트 스케줄러이다. `ExponentialLR`은 현재 에포크(epoch*)의 러닝 메이트를 '이전 에포크의 러닝 레이트 x gamma'로 스케줄링 한다. 본 예제에서는 gamma를 0.9로 설정하였다.\n* 에포크: 데이터 전체를 학습하는 횟수. 만일 에포크가 3이라면 데이터를 3번 반복 학습한다는 뜻이다.\n\n\n### 트레이너 정의\n\ncode 1-13을 통해 트레이너를 정의할 수 있다. 이 트레이너는 파이토치 라이트닝 라이브러리의 도움을 받아 GPU/TPU 설정, 로그 및 체크포인트 등 귀찮은 설정을 알아서 해 준다.\n\n#### code 1-13\n\n\n```python\ntrainer = nlpbook.get_trainer(args)\n```\n\n    /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Checkpoint directory /gdrive/My Drive/nlpbook/checkpoint-doccls exists and is not empty.\n      warnings.warn(*args, **kwargs)\n    GPU available: True, used: True\n    TPU available: False, using: 0 TPU cores\n    \n\n### 학습 개시\n\ncode 1-14처럼 트레이너의 `fit()`함수를 호출하면 학습을 시작한다. 학습 시간은 자신의 코랩 환경에 따라 다를 수 있으나 꽤 오래 걸릴 수 있다. 학습이 진행되는 도중 브라우저를 끄면 모델 학습을 비롯한 코랩 실행이 중단되니 주의해야한다.\n\n#### code 1-14\n\n\n```python\ntrainer.fit(\n    task,\n    train_dataloader=train_dataloader,\n    val_dataloaders=val_dataloader,\n)\n```\n\n    LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n    \n      | Name  | Type                          | Params\n    --------------------------------------------------------\n    0 | model | BertForSequenceClassification | 108 M \n    --------------------------------------------------------\n    108 M     Trainable params\n    0         Non-trainable params\n    108 M     Total params\n    435.680   Total estimated model params size (MB)\n    \n\n\n    Training: 114it [00:00, ?it/s]\n\n\n\n    Validating: 0it [00:00, ?it/s]\n\n\n\n    Validating: 0it [00:00, ?it/s]\n\n\n\n\n---\n\n\n# **문서 분류 모델 학습**을 요약하자면\n\n# 각종 설정을 마친 뒤 말뭉치를 내려받아 전처리한다. 프리트레인을 마친 모델을 이 데이터에 맞게 파인 튜닝한다.\n\n"])</script><script>self.__next_f.push([1,"8f:[\"$\",\"$L95\",null,{\"content\":\"$96\"}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"8:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Sehoon's Workspace\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Welcome to my page!\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"d:\"$8:metadata\"\n"])</script></body></html>
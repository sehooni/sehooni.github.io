<!DOCTYPE html><!--8lJiHtAmlyU3nNFMbG8_k--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg" as="image"/><link rel="preload" href="https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png" as="image"/><link rel="stylesheet" href="/_next/static/chunks/2f40a2027cd59172.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/b9ef641e76e3a351.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/475fa0f5a019bf38.js"/><script src="/_next/static/chunks/aa5e9022907a8769.js" async=""></script><script src="/_next/static/chunks/42fbd80a90fec4a2.js" async=""></script><script src="/_next/static/chunks/5cdb1f5564fc8217.js" async=""></script><script src="/_next/static/chunks/turbopack-f5bb12e1c2d48879.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/865c404e1d9a0c65.js" async=""></script><script src="/_next/static/chunks/6b8d09032578b975.js" async=""></script><title>Sehoon&#x27;s Workspace</title><meta name="description" content="Welcome to my page!"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="min-h-screen flex flex-col font-sans"><div hidden=""><!--$--><!--/$--></div><div class="flex gap-10"><article class="flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none"><header class="mb-8 not-prose border-b pb-8"><h1 class="text-4xl font-bold mb-4">[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…</h1><div class="flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400"><time dateTime="Wed Mar 23 2022 09:00:00 GMT+0900 (ëŒ€í•œë¯¼êµ­ í‘œì¤€ì‹œ)">March 23, 2022</time></div></header><p>ì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?</p>
<p>ë³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ &#x27;Do it! ìì—°ì–´ ì²˜ë¦¬&#x27;ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)</p>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">í•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°</h1>
<p>í•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg" alt="pair_classification_map"/>
<strong>ê·¸ë¦¼ 1.</strong> ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤</p>
<p>ì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´</p>
<p><strong>[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]</strong>
ì„ ê³„ì‚°í•œë‹¤.</p>
<p>ì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.</p>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">ì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°</h1>
<h2 id="1" class="text-2xl font-bold mt-8 mb-4">1. í™˜ê²½ ì„¤ì •í•˜ê¸°</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜</h3>
<p>pip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.</p>
<h4>code 4-0</h4>
<pre><code class="hljs language-python">!pip install ratsnlp
</code></pre>
<pre><code>Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)
Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)
Requirement already satisfied: Korpora&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)
Requirement already satisfied: flask&gt;=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)
Requirement already satisfied: flask-cors&gt;=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)
Requirement already satisfied: torch&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)
Requirement already satisfied: flask-ngrok&gt;=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)
Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)
Requirement already satisfied: future&gt;=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.18.2)
Requirement already satisfied: tensorboard!=2.5.0,&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2.8.0)
Requirement already satisfied: fsspec[http]&gt;=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2022.2.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (21.3)
Requirement already satisfied: torchmetrics&gt;=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.7.2)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (1.21.5)
Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (0.3.0)
Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (4.63.0)
Requirement already satisfied: PyYAML&lt;=5.4.1,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (5.4.1)
Requirement already satisfied: huggingface-hub&gt;=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.4.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (3.6.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (4.11.2)
Requirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.10.3)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2.23.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2019.12.20)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (0.0.47)
Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (2.11.3)
Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.0.1)
Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.1.0)
Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (7.1.2)
Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors&gt;=3.0.10-&gt;ratsnlp) (1.15.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.8.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&gt;=0.0.12-&gt;transformers==4.10.0-&gt;ratsnlp) (3.10.0.2)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;flask&gt;=1.1.4-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: dataclasses&gt;=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (0.6)
Requirement already satisfied: xlrd&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora&gt;=0.2.0-&gt;ratsnlp) (2.0.1)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.0.7)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (3.0.4)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.6)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.6.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (57.4.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.44.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.35.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.17.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.0.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.8.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.3.6)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.37.1)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.8)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.2.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.2.4)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers==4.10.0-&gt;ratsnlp) (3.7.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.2.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (21.4.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.7.2)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (2.0.12)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.2.0)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.0.2)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (6.0.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.13.0)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==4.10.0-&gt;ratsnlp) (1.1.0)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™</h3>
<p>í•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.</p>
<h4>code 4-1</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">&#x27;/gdrive&#x27;</span>, force_remount=<span class="hljs-literal">True</span>)
</code></pre>
<pre><code>Mounted at /gdrive
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì¸í¼ëŸ°ìŠ¤ ì„¤ì •</h3>
<p>ê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. <code>pretrained_model_name</code>ê³¼ <code>max_seq_length</code>, <code>downstream_model_dir</code> ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.</p>
<h4>code 4-2</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.classification <span class="hljs-keyword">import</span> ClassificationDeployArguments
args = ClassificationDeployArguments(
    pretrained_model_name=<span class="hljs-string">&quot;beomi/kcbert-base&quot;</span>,
    downstream_model_dir=<span class="hljs-string">&quot;/gdrive/My Drive/nlpbook/checkpoint-paircls&quot;</span>,
    max_seq_length=<span class="hljs-number">64</span>,
)
</code></pre>
<pre><code>downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt
</code></pre>
<h2 id="2" class="text-2xl font-bold mt-8 mb-4">2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">í† í¬ë‚˜ì´ì € ë¡œë“œ</h3>
<p>code 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.</p>
<h4>code 4-3</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer
tokenizer = BertTokenizer.from_pretrained(
    args.pretrained_model_name,
    do_lower_case=<span class="hljs-literal">False</span>,
)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ</h3>
<p>code 4-4ëŠ” <code>pair_classification_train.ipynb</code>ì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.</p>
<h4>code 4-4</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> torch
fine_tuned_model_ckpt = torch.load(
    args.downstream_model_checkpoint_fpath,
    map_location=torch.device(<span class="hljs-string">&quot;cpu&quot;</span>),
)
</code></pre>
<h3 id="b" class="text-xl font-bold mt-6 mb-3">BERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”</h3>
<p>code 4-5ëŠ” <code>pair_classification_train.ipynb</code>ì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ <code>pretrained_model_name</code>ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.</p>
<h4>code 4-5</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig
pretrained_model_config = BertConfig.from_pretrained(
    args.pretrained_model_name,
    num_labels=fine_tuned_model_ckpt[<span class="hljs-string">&#x27;state_dict&#x27;</span>][<span class="hljs-string">&#x27;model.classifier.bias&#x27;</span>].shape.numel(),
)
</code></pre>
<h4>code 4-6</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertForSequenceClassification
model = BertForSequenceClassification(pretrained_model_config)
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°</h3>
<p>code 4-7ì€ ì´ˆê¸°í™”í•œ <strong>BERT</strong>ëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤</p>
<h4>code 4-7</h4>
<pre><code class="hljs language-python">model.load_state_dict({k.replace(<span class="hljs-string">&quot;model.&quot;</span>,<span class="hljs-string">&quot;&quot;</span>): v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> fine_tuned_model_ckpt[<span class="hljs-string">&#x27;state_dict&#x27;</span>].items()})
</code></pre>
<pre><code>&lt;All keys matched successfully&gt;
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">í‰ê°€ ëª¨ë“œë¡œ ì „í™˜</h3>
<p>ì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. <strong>ë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• </strong>ì„ í•œë‹¤.</p>
<h4>code 4-8</h4>
<pre><code class="hljs language-python">model.<span class="hljs-built_in">eval</span>()
</code></pre>
<pre><code>BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30000, 768, padding_idx=0)
      (position_embeddings): Embedding(300, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=3, bias=True)
)
</code></pre>
<h2 id="3" class="text-2xl font-bold mt-8 mb-4">3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°</h2>
<p>code 4-9ëŠ” <strong>ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜</strong>ì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>ë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.</p>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜</h3>
<h4>code 4-9</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">inference_fn</span>(<span class="hljs-params">premise, hypothesis</span>):
  <span class="hljs-comment"># ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°</span>
  inputs = tokenizer(
      [(premise, hypothesis)],
      max_length=args.max_seq_length,
      padding=<span class="hljs-string">&quot;max_length&quot;</span>,
      truncation=<span class="hljs-literal">True</span>,
  )
  <span class="hljs-keyword">with</span> torch.no_grad():
    <span class="hljs-comment"># ëª¨ë¸ ê³„ì‚°í•˜ê¸°</span>
    outputs = model(**{k: torch.tensor(v) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()})  <span class="hljs-comment"># {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°</span>

    <span class="hljs-comment"># ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°</span>
    prob = outputs.logits.softmax(dim=<span class="hljs-number">1</span>)

    <span class="hljs-comment"># í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼</span>
    entailment_prob = <span class="hljs-built_in">round</span>(prob[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].item(), <span class="hljs-number">2</span>)
    contradiction_prob = <span class="hljs-built_in">round</span>(prob[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].item(), <span class="hljs-number">2</span>)
    neutral_prob = <span class="hljs-built_in">round</span>(prob[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>].item(), <span class="hljs-number">2</span>)

    <span class="hljs-comment"># ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°</span>
    <span class="hljs-keyword">if</span> torch.argmax(prob) == <span class="hljs-number">0</span>:
      pred = <span class="hljs-string">&quot;ì°¸ (entailment)&quot;</span>
    <span class="hljs-keyword">elif</span> torch.argmax(prob) == <span class="hljs-number">1</span>:
      pred = <span class="hljs-string">&quot;ê±°ì§“ (contradiction)&quot;</span>
    <span class="hljs-keyword">else</span>:
      pred = <span class="hljs-string">&quot;ì¤‘ë¦½ (neutral)&quot;</span>
  
  <span class="hljs-keyword">return</span> {
      <span class="hljs-string">&#x27;premise&#x27;</span>: premise,
      <span class="hljs-string">&#x27;hypothesis&#x27;</span>: hypothesis,
      <span class="hljs-string">&#x27;prediction&#x27;</span>: pred,
      <span class="hljs-string">&#x27;entailment_data&#x27;</span>: <span class="hljs-string">f&quot;ì°¸ <span class="hljs-subst">{entailment_prob}</span>&quot;</span>,
      <span class="hljs-string">&#x27;contradiction_data&#x27;</span>: <span class="hljs-string">f&quot;ê±°ì§“ <span class="hljs-subst">{contradiction_prob}</span>&quot;</span>,
      <span class="hljs-string">&#x27;neutral_data&#x27;</span>: <span class="hljs-string">f&quot;ì¤‘ë¦½ <span class="hljs-subst">{neutral_prob}</span>&quot;</span>,
      <span class="hljs-string">&#x27;entailment_width&#x27;</span>: <span class="hljs-string">f&quot;<span class="hljs-subst">{entailment_prob * <span class="hljs-number">100</span>}</span>%&quot;</span>,
      <span class="hljs-string">&#x27;contradiction_width&#x27;</span>: <span class="hljs-string">f&quot;<span class="hljs-subst">{contradiction_prob * <span class="hljs-number">100</span>}</span>%&quot;</span>,
      <span class="hljs-string">&#x27;neutral_width&#x27;</span>: <span class="hljs-string">f&quot;<span class="hljs-subst">{neutral_prob * <span class="hljs-number">100</span>}</span>%&quot;</span>
  }
</code></pre>
<p>**ëª¨ë¸ ì¶œë ¥ê°’(<code>output.logits</code>)**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ &#x27;<strong>ì°¸ (entailment)</strong>&#x27;, ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° &#x27;<strong>ê±°ì§“ (contradiction)</strong>&#x27;, ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° &#x27;<strong>ì¤‘ë¦½ (neutral)</strong>&#x27;ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.</p>
<p>code 4-9ì—ì„œ <code>entailment_width</code>, <code>contradiction_width</code>, <code>neutral_width</code>ëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.</p>
<h2 id="4" class="text-2xl font-bold mt-8 mb-4">4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h2>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„</h3>
<p><code>ngrok</code>ì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. <code>ngrok</code>ì„ ì‹¤í–‰í•˜ë ¤ë©´ <a href="https://dashboard.ngrok.com/get-started/setup">íšŒì›ê°€ì…</a> í›„ <a href="https://dashboard.ngrok.com/get-started/setup">ë¡œê·¸ì¸</a>ì„ í•œ ë’¤ <a href="https://dashboard.ngrok.com/get-started/your-authtoken">ì´ê³³</a>ì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤.</p>
<p>ì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ <code>authtoken</code>ì´ <code>test123</code>ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.</p>
<p>** !mkdir /root/.ngrok2 &amp;&amp; echo &quot;authtoken: test123&quot; &gt; /root/.ngrok2/ngrok.yml**</p>
<h4>code 4-10</h4>
<pre><code class="hljs language-python">!mkdir /root/.ngrok2 &amp;&amp; echo <span class="hljs-string">&quot;authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)&quot;</span> &gt; /root/.ngrok2/ngrok.yml
</code></pre>
<pre><code>mkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists
</code></pre>
<h3 id="" class="text-xl font-bold mt-6 mb-3">ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°</h3>
<p>code 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ <code>inference_fn</code>ì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.</p>
<h4>code 4-11</h4>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> ratsnlp.nlpbook.paircls <span class="hljs-keyword">import</span> get_web_service_app
app = get_web_service_app(inference_fn)
app.run()
</code></pre>
<pre><code> * Serving Flask app &quot;ratsnlp.nlpbook.paircls.deploy&quot; (lazy loading)
 * Environment: production
[31m   WARNING: This is a development server. Do not use it in a production deployment.[0m
[2m   Use a production WSGI server instead.[0m
 * Debug mode: off


 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)


 * Running on http://0163-35-238-180-140.ngrok.io
 * Traffic stats available on http://127.0.0.1:4040


127.0.0.1 - - [04/Mar/2022 09:14:48] &quot;[37mGET / HTTP/1.1[0m&quot; 200 -
127.0.0.1 - - [04/Mar/2022 09:14:49] &quot;[33mGET /favicon.ico HTTP/1.1[0m&quot; 404 -
127.0.0.1 - - [04/Mar/2022 09:14:49] &quot;[37mGET / HTTP/1.1[0m&quot; 200 -
127.0.0.1 - - [04/Mar/2022 09:15:01] &quot;[37mPOST /api HTTP/1.1[0m&quot; 200 -
</code></pre>
<h1 id="" class="text-3xl font-bold mt-8 mb-4">ì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</h1>
<p><img src="https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png" alt="pair_classification"/></p><div class="mt-10 border-t pt-10"></div></article></div><!--$--><!--/$--><script src="/_next/static/chunks/475fa0f5a019bf38.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n3:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n5:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"OutletBoundary\"]\n6:\"$Sreact.suspense\"\n8:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"ViewportBoundary\"]\na:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"MetadataBoundary\"]\nc:I[68027,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/865c404e1d9a0c65.js\"],\"default\"]\n:HL[\"/_next/static/chunks/2f40a2027cd59172.css\",\"style\"]\n:HL[\"/_next/static/chunks/b9ef641e76e3a351.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"8lJiHtAmlyU3nNFMbG8_k\",\"c\":[\"\",\"2022-03-23-pair_classification_service\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"2022-03-23-pair_classification_service\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/2f40a2027cd59172.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"min-h-screen flex flex-col font-sans\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/b9ef641e76e3a351.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/6b8d09032578b975.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@7\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L8\",null,{\"children\":\"$@9\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@b\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,":HL[\"https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg\",\"image\"]\nd:T2695,"])</script><script>self.__next_f.push([1,"Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\nRequirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\nRequirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\nRequirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\nRequirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\nRequirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\nRequirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\nRequirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\nRequirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\nRequirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\nRequirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\nRequirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\nRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\nRequirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\nRequirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.63.0)\nRequirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\nRequirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.2)\nRequirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\nRequirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\nRequirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\nRequirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\nRequirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\nRequirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\nRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\nRequirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\nRequirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\nRequirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\nRequirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\nRequirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\nRequirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\nRequirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\nRequirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\nRequirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.44.0)\nRequirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\nRequirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\nRequirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\nRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\nRequirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\nRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\nRequirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\nRequirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\nRequirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\nRequirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\nRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\nRequirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\nRequirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\nRequirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\nRequirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\nRequirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\nRequirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\nRequirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\nRequirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\nRequirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"flex gap-10\",\"children\":[[\"$\",\"article\",null,{\"className\":\"flex-1 min-w-0 prose prose-slate dark:prose-invert max-w-none\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8 not-prose border-b pb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold mb-4\",\"children\":\"[NLP] ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ ì‹¤ì „ íˆ¬ì…\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4 text-sm text-gray-500 dark:text-gray-400\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"$D2022-03-23T00:00:00.000Z\",\"children\":\"March 23, 2022\"}],\"$undefined\"]}]]}],[[\"$\",\"p\",\"p-0\",{\"children\":\"ì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?\"}],\"\\n\",[\"$\",\"p\",\"p-1\",{\"children\":\"ë³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ 'Do it! ìì—°ì–´ ì²˜ë¦¬'ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)\"}],\"\\n\",[\"$\",\"h1\",\"h1-0\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"í•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°\"}],\"\\n\",[\"$\",\"p\",\"p-2\",{\"children\":\"í•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.\"}],\"\\n\",[\"$\",\"p\",\"p-3\",{\"children\":[[\"$\",\"img\",\"img-0\",{\"src\":\"https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg\",\"alt\":\"pair_classification_map\"}],\"\\n\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"ê·¸ë¦¼ 1.\"}],\" ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤\"]}],\"\\n\",[\"$\",\"p\",\"p-4\",{\"children\":\"ì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´\"}],\"\\n\",[\"$\",\"p\",\"p-5\",{\"children\":[[\"$\",\"strong\",\"strong-0\",{\"children\":\"[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]\"}],\"\\nì„ ê³„ì‚°í•œë‹¤.\"]}],\"\\n\",[\"$\",\"p\",\"p-6\",{\"children\":\"ì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.\"}],\"\\n\",[\"$\",\"h1\",\"h1-1\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"ì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°\"}],\"\\n\",[\"$\",\"h2\",\"h2-0\",{\"id\":\"1\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"1. í™˜ê²½ ì„¤ì •í•˜ê¸°\"}],\"\\n\",[\"$\",\"h3\",\"h3-0\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜\"}],\"\\n\",[\"$\",\"p\",\"p-7\",{\"children\":\"pip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\"}],\"\\n\",[\"$\",\"h4\",\"h4-0\",{\"children\":\"code 4-0\"}],\"\\n\",[\"$\",\"pre\",\"pre-0\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":\"!pip install ratsnlp\\n\"}]}],\"\\n\",[\"$\",\"pre\",\"pre-1\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$d\"}]}],\"\\n\",\"$Le\",\"\\n\",\"$Lf\",\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\"],\"$L47\"]}],\"$L48\"]}]\n"])</script><script>self.__next_f.push([1,"51:I[24170,[\"/_next/static/chunks/6b8d09032578b975.js\"],\"default\"]\n52:I[55132,[\"/_next/static/chunks/6b8d09032578b975.js\"],\"default\"]\n:HL[\"https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png\",\"image\"]\ne:[\"$\",\"h3\",\"h3-1\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™\"}]\nf:[\"$\",\"p\",\"p-8\",{\"children\":\"í•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.\"}]\n10:[\"$\",\"h4\",\"h4-1\",{\"children\":\"code 4-1\"}]\n11:[\"$\",\"pre\",\"pre-2\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" google.colab \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" drive\\ndrive.mount(\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"'/gdrive'\"}],\", force_remount=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\")\\n\"]}]}]\n12:[\"$\",\"pre\",\"pre-3\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"Mounted at /gdrive\\n\"}]}]\n13:[\"$\",\"h3\",\"h3-2\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì¸í¼ëŸ°ìŠ¤ ì„¤ì •\"}]\n14:[\"$\",\"p\",\"p-9\",{\"children\":[\"ê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. \",[\"$\",\"code\",\"code-0\",{\"children\":\"pretrained_model_name\"}],\"ê³¼ \",[\"$\",\"code\",\"code-1\",{\"children\":\"max_seq_length\"}],\", \",[\"$\",\"code\",\"code-2\",{\"children\":\"downstream_model_dir\"}],\" ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.\"]}]\n15:[\"$\",\"h4\",\"h4-2\",{\"children\":\"code 4-2\"}]\n16:[\"$\",\"pre\",\"pre-4\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.classification \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" ClassificationDeployArguments\\nargs = ClassificationDeployArguments(\\n    pretrained_model_name=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"\\\"beomi/kcbert-base\\\"\"}],\",\\n    downstream_model_dir=\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-string\",\"children\":\"\\\"/gdrive/My Drive/nlpbook/checkpoint-paircls\\\"\"}],\",\\n    max_seq_length=\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-number\",\"children\":\"64\"}],\",\\n)\\n\"]}]}]\n17:[\"$\",\"pre\",\"pre-5\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt\\n\"}]}]\n18:[\"$\",\"h2\",\"h2-1\",{\"id\":\"2\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"}]\n19:[\"$\",\"h3\",\"h3-3\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"í† í¬ë‚˜ì´ì € ë¡œë“œ\"}]\n1a:[\"$\",\"p\",\"p-10\",{\"children\":\"code 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.\"}]\n1b:[\"$\",\"h4\",\"h4-3\",{\"children\":\"code 4-3\"}]\n1c:[\"$\",\"pre\",\"pre-6\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertTokenizer\\ntokenizer = BertTokenizer.from_pretrained(\\n    args.pretrained_model_name,\\n    do_lower_case=\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-literal\",\"children\":\"False\"}],\",\\n)\\n\"]}]}]\n1d:[\"$\",\"h3\",\"h3-4\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\"}]\n1e:[\"$\",\"p\",\"p-11\",{\"children\":[\"code 4-4ëŠ” \",[\"$\",\"code\",\"code-0\",{\"children\":\"pair_classification_train.ipynb\"}],\"ì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.\"]}]\n1f:[\"$\",\"h4\",\"h4-4\",{\"children\":\"code 4-4\"}]\n20:[\"$\",\"pre\",\"pre-7\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" torch\\nfine_tuned_model_ckpt = torch.load(\\n    args.downstream_model_checkpoint_fpath,\\n    map_location=torch.device(\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-string\",\"children\":\"\\\"cpu\\\"\"}"])</script><script>self.__next_f.push([1,"],\"),\\n)\\n\"]}]}]\n21:[\"$\",\"h3\",\"h3-5\",{\"id\":\"b\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"BERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”\"}]\n22:[\"$\",\"p\",\"p-12\",{\"children\":[\"code 4-5ëŠ” \",[\"$\",\"code\",\"code-0\",{\"children\":\"pair_classification_train.ipynb\"}],\"ì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ \",[\"$\",\"code\",\"code-1\",{\"children\":\"pretrained_model_name\"}],\"ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.\"]}]\n23:[\"$\",\"h4\",\"h4-5\",{\"children\":\"code 4-5\"}]\n24:[\"$\",\"pre\",\"pre-8\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertConfig\\npretrained_model_config = BertConfig.from_pretrained(\\n    args.pretrained_model_name,\\n    num_labels=fine_tuned_model_ckpt[\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-string\",\"children\":\"'state_dict'\"}],\"][\",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-string\",\"children\":\"'model.classifier.bias'\"}],\"].shape.numel(),\\n)\\n\"]}]}]\n25:[\"$\",\"h4\",\"h4-6\",{\"children\":\"code 4-6\"}]\n26:[\"$\",\"pre\",\"pre-9\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" transformers \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" BertForSequenceClassification\\nmodel = BertForSequenceClassification(pretrained_model_config)\\n\"]}]}]\n27:[\"$\",\"h3\",\"h3-6\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°\"}]\n28:[\"$\",\"p\",\"p-13\",{\"children\":[\"code 4-7ì€ ì´ˆê¸°í™”í•œ \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"BERT\"}],\"ëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤\"]}]\n29:[\"$\",\"h4\",\"h4-7\",{\"children\":\"code 4-7\"}]\n2a:[\"$\",\"pre\",\"pre-10\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"model.load_state_dict({k.replace(\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-string\",\"children\":\"\\\"model.\\\"\"}],\",\",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-string\",\"children\":\"\\\"\\\"\"}],\"): v \",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-keyword\",\"children\":\"for\"}],\" k, v \",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-keyword\",\"children\":\"in\"}],\" fine_tuned_model_ckpt[\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-string\",\"children\":\"'state_dict'\"}],\"].items()})\\n\"]}]}]\n2b:[\"$\",\"pre\",\"pre-11\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"\u003cAll keys matched successfully\u003e\\n\"}]}]\n2c:[\"$\",\"h3\",\"h3-7\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\"}]\n2d:[\"$\",\"p\",\"p-14\",{\"children\":[\"ì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"ë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• \"}],\"ì„ í•œë‹¤.\"]}]\n2e:[\"$\",\"h4\",\"h4-8\",{\"children\":\"code 4-8\"}]\n2f:[\"$\",\"pre\",\"pre-12\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"model.\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-built_in\",\"children\":\"eval\"}],\"()\\n\"]}]}]\n49:T348e,"])</script><script>self.__next_f.push([1,"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)\n"])</script><script>self.__next_f.push([1,"30:[\"$\",\"pre\",\"pre-13\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"$49\"}]}]\n31:[\"$\",\"h2\",\"h2-2\",{\"id\":\"3\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°\"}]\n32:[\"$\",\"p\",\"p-15\",{\"children\":[\"code 4-9ëŠ” \",[\"$\",\"strong\",\"strong-0\",{\"children\":\"ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜\"}],\"ì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ \",[\"$\",\"code\",\"code-0\",{\"children\":\"input_ids\"}],\", \",[\"$\",\"code\",\"code-1\",{\"children\":\"attention_mask\"}],\", \",[\"$\",\"code\",\"code-2\",{\"children\":\"token_type_ids\"}],\"ë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.\"]}]\n33:[\"$\",\"h3\",\"h3-8\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜\"}]\n34:[\"$\",\"h4\",\"h4-9\",{\"children\":\"code 4-9\"}]\n"])</script><script>self.__next_f.push([1,"35:[\"$\",\"pre\",\"pre-14\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"def\"}],\" \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-title function_\",\"children\":\"inference_fn\"}],\"(\",[\"$\",\"span\",\"span-2\",{\"className\":\"hljs-params\",\"children\":\"premise, hypothesis\"}],\"):\\n  \",[\"$\",\"span\",\"span-3\",{\"className\":\"hljs-comment\",\"children\":\"# ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°\"}],\"\\n  inputs = tokenizer(\\n      [(premise, hypothesis)],\\n      max_length=args.max_seq_length,\\n      padding=\",[\"$\",\"span\",\"span-4\",{\"className\":\"hljs-string\",\"children\":\"\\\"max_length\\\"\"}],\",\\n      truncation=\",[\"$\",\"span\",\"span-5\",{\"className\":\"hljs-literal\",\"children\":\"True\"}],\",\\n  )\\n  \",[\"$\",\"span\",\"span-6\",{\"className\":\"hljs-keyword\",\"children\":\"with\"}],\" torch.no_grad():\\n    \",[\"$\",\"span\",\"span-7\",{\"className\":\"hljs-comment\",\"children\":\"# ëª¨ë¸ ê³„ì‚°í•˜ê¸°\"}],\"\\n    outputs = model(**{k: torch.tensor(v) \",[\"$\",\"span\",\"span-8\",{\"className\":\"hljs-keyword\",\"children\":\"for\"}],\" k, v \",[\"$\",\"span\",\"span-9\",{\"className\":\"hljs-keyword\",\"children\":\"in\"}],\" inputs.items()})  \",[\"$\",\"span\",\"span-10\",{\"className\":\"hljs-comment\",\"children\":\"# {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°\"}],\"\\n\\n    \",[\"$\",\"span\",\"span-11\",{\"className\":\"hljs-comment\",\"children\":\"# ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°\"}],\"\\n    prob = outputs.logits.softmax(dim=\",[\"$\",\"span\",\"span-12\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\")\\n\\n    \",[\"$\",\"span\",\"span-13\",{\"className\":\"hljs-comment\",\"children\":\"# í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼\"}],\"\\n    entailment_prob = \",[\"$\",\"span\",\"span-14\",{\"className\":\"hljs-built_in\",\"children\":\"round\"}],\"(prob[\",[\"$\",\"span\",\"span-15\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"][\",[\"$\",\"span\",\"span-16\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"].item(), \",[\"$\",\"span\",\"span-17\",{\"className\":\"hljs-number\",\"children\":\"2\"}],\")\\n    contradiction_prob = \",[\"$\",\"span\",\"span-18\",{\"className\":\"hljs-built_in\",\"children\":\"round\"}],\"(prob[\",[\"$\",\"span\",\"span-19\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"][\",[\"$\",\"span\",\"span-20\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\"].item(), \",[\"$\",\"span\",\"span-21\",{\"className\":\"hljs-number\",\"children\":\"2\"}],\")\\n    neutral_prob = \",[\"$\",\"span\",\"span-22\",{\"className\":\"hljs-built_in\",\"children\":\"round\"}],\"(prob[\",[\"$\",\"span\",\"span-23\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\"][\",[\"$\",\"span\",\"span-24\",{\"className\":\"hljs-number\",\"children\":\"2\"}],\"].item(), \",[\"$\",\"span\",\"span-25\",{\"className\":\"hljs-number\",\"children\":\"2\"}],\")\\n\\n    \",[\"$\",\"span\",\"span-26\",{\"className\":\"hljs-comment\",\"children\":\"# ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°\"}],\"\\n    \",[\"$\",\"span\",\"span-27\",{\"className\":\"hljs-keyword\",\"children\":\"if\"}],\" torch.argmax(prob) == \",[\"$\",\"span\",\"span-28\",{\"className\":\"hljs-number\",\"children\":\"0\"}],\":\\n      pred = \",[\"$\",\"span\",\"span-29\",{\"className\":\"hljs-string\",\"children\":\"\\\"ì°¸ (entailment)\\\"\"}],\"\\n    \",[\"$\",\"span\",\"span-30\",{\"className\":\"hljs-keyword\",\"children\":\"elif\"}],\" torch.argmax(prob) == \",[\"$\",\"span\",\"span-31\",{\"className\":\"hljs-number\",\"children\":\"1\"}],\":\\n      pred = \",[\"$\",\"span\",\"span-32\",{\"className\":\"hljs-string\",\"children\":\"\\\"ê±°ì§“ (contradiction)\\\"\"}],\"\\n    \",[\"$\",\"span\",\"span-33\",{\"className\":\"hljs-keyword\",\"children\":\"else\"}],\":\\n      pred = \",[\"$\",\"span\",\"span-34\",{\"className\":\"hljs-string\",\"children\":\"\\\"ì¤‘ë¦½ (neutral)\\\"\"}],\"\\n  \\n  \",[\"$\",\"span\",\"span-35\",{\"className\":\"hljs-keyword\",\"children\":\"return\"}],\" {\\n      \",[\"$\",\"span\",\"span-36\",{\"className\":\"hljs-string\",\"children\":\"'premise'\"}],\": premise,\\n      \",[\"$\",\"span\",\"span-37\",{\"className\":\"hljs-string\",\"children\":\"'hypothesis'\"}],\": hypothesis,\\n      \",[\"$\",\"span\",\"span-38\",{\"className\":\"hljs-string\",\"children\":\"'prediction'\"}],\": pred,\\n      \",[\"$\",\"span\",\"span-39\",{\"className\":\"hljs-string\",\"children\":\"'entailment_data'\"}],\": \",[\"$\",\"span\",\"span-40\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"ì°¸ \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":\"{entailment_prob}\"}],\"\\\"\"]}],\",\\n      \",[\"$\",\"span\",\"span-41\",{\"className\":\"hljs-string\",\"children\":\"'contradiction_data'\"}],\": \",[\"$\",\"span\",\"span-42\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"ê±°ì§“ \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":\"{contradiction_prob}\"}],\"\\\"\"]}],\",\\n      \",[\"$\",\"span\",\"span-43\",{\"className\":\"hljs-string\",\"children\":\"'neutral_data'\"}],\": \",\"$L4a\",\",\\n      \",\"$L4b\",\": \",\"$L4c\",\",\\n      \",\"$L4d\",\": \",\"$L4e\",\",\\n      \",\"$L4f\",\": \",\"$L50\",\"\\n  }\\n\"]}]}]\n"])</script><script>self.__next_f.push([1,"36:[\"$\",\"p\",\"p-16\",{\"children\":[\"**ëª¨ë¸ ì¶œë ¥ê°’(\",[\"$\",\"code\",\"code-0\",{\"children\":\"output.logits\"}],\")**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ '\",[\"$\",\"strong\",\"strong-0\",{\"children\":\"ì°¸ (entailment)\"}],\"', ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° '\",[\"$\",\"strong\",\"strong-1\",{\"children\":\"ê±°ì§“ (contradiction)\"}],\"', ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° '\",[\"$\",\"strong\",\"strong-2\",{\"children\":\"ì¤‘ë¦½ (neutral)\"}],\"'ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.\"]}]\n37:[\"$\",\"p\",\"p-17\",{\"children\":[\"code 4-9ì—ì„œ \",[\"$\",\"code\",\"code-0\",{\"children\":\"entailment_width\"}],\", \",[\"$\",\"code\",\"code-1\",{\"children\":\"contradiction_width\"}],\", \",[\"$\",\"code\",\"code-2\",{\"children\":\"neutral_width\"}],\"ëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.\"]}]\n38:[\"$\",\"h2\",\"h2-3\",{\"id\":\"4\",\"className\":\"text-2xl font-bold mt-8 mb-4\",\"children\":\"4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\"}]\n39:[\"$\",\"h3\",\"h3-9\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„\"}]\n3a:[\"$\",\"p\",\"p-18\",{\"children\":[[\"$\",\"code\",\"code-0\",{\"children\":\"ngrok\"}],\"ì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. \",[\"$\",\"code\",\"code-1\",{\"children\":\"ngrok\"}],\"ì„ ì‹¤í–‰í•˜ë ¤ë©´ \",[\"$\",\"a\",\"a-0\",{\"href\":\"https://dashboard.ngrok.com/get-started/setup\",\"children\":\"íšŒì›ê°€ì…\"}],\" í›„ \",[\"$\",\"a\",\"a-1\",{\"href\":\"https://dashboard.ngrok.com/get-started/setup\",\"children\":\"ë¡œê·¸ì¸\"}],\"ì„ í•œ ë’¤ \",[\"$\",\"a\",\"a-2\",{\"href\":\"https://dashboard.ngrok.com/get-started/your-authtoken\",\"children\":\"ì´ê³³\"}],\"ì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤.\"]}]\n3b:[\"$\",\"p\",\"p-19\",{\"children\":[\"ì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ \",[\"$\",\"code\",\"code-0\",{\"children\":\"authtoken\"}],\"ì´ \",[\"$\",\"code\",\"code-1\",{\"children\":\"test123\"}],\"ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.\"]}]\n3c:[\"$\",\"p\",\"p-20\",{\"children\":\"** !mkdir /root/.ngrok2 \u0026\u0026 echo \\\"authtoken: test123\\\" \u003e /root/.ngrok2/ngrok.yml**\"}]\n3d:[\"$\",\"h4\",\"h4-10\",{\"children\":\"code 4-10\"}]\n3e:[\"$\",\"pre\",\"pre-15\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[\"!mkdir /root/.ngrok2 \u0026\u0026 echo \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-string\",\"children\":\"\\\"authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)\\\"\"}],\" \u003e /root/.ngrok2/ngrok.yml\\n\"]}]}]\n3f:[\"$\",\"pre\",\"pre-16\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\"mkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists\\n\"}]}]\n40:[\"$\",\"h3\",\"h3-10\",{\"id\":\"\",\"className\":\"text-xl font-bold mt-6 mb-3\",\"children\":\"ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\"}]\n41:[\"$\",\"p\",\"p-21\",{\"children\":[\"code 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ \",[\"$\",\"code\",\"code-0\",{\"children\":\"inference_fn\"}],\"ì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.\"]}]\n42:[\"$\",\"h4\",\"h4-11\",{\"children\":\"code 4-11\"}]\n43:[\"$\",\"pre\",\"pre-17\",{\"children\":[\"$\",\"code\",\"code-0\",{\"className\":\"hljs language-python\",\"children\":[[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-keyword\",\"children\":\"from\"}],\" ratsnlp.nlpbook.paircls \",[\"$\",\"span\",\"span-1\",{\"className\":\"hljs-keyword\",\"children\":\"import\"}],\" get_web_service_app\\napp = get_web_service_app(inference_fn)\\napp.run()\\n\"]}]}]\n44:[\"$\",\"pre\",\"pre-18\",{\"children\":[\"$\",\"code\",\"code-0\",{\"children\":\" * Serving Flask app \\\"ratsnlp.nlpbook.paircls.deploy\\\" (lazy loading)\\n * Environment: production\\n\\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\\u001b[0m\\n\\u001b[2m   Use a production WSGI server instead.\\u001b[0m\\n * Debug mode: off\\n\\n\\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\\n\\n\\n * Running on http://0163-35-238-180-140.ngrok.io\\n * Traffic stats available on http://127.0.0.1:4040\\n\\n\\n127.0.0.1 - - [04/Mar/2022 09:14:48] \\\"\\u001b[37mGET / HTTP/1.1\\u001b[0m\\\" 200 -\\n127.0.0.1 - - [04"])</script><script>self.__next_f.push([1,"/Mar/2022 09:14:49] \\\"\\u001b[33mGET /favicon.ico HTTP/1.1\\u001b[0m\\\" 404 -\\n127.0.0.1 - - [04/Mar/2022 09:14:49] \\\"\\u001b[37mGET / HTTP/1.1\\u001b[0m\\\" 200 -\\n127.0.0.1 - - [04/Mar/2022 09:15:01] \\\"\\u001b[37mPOST /api HTTP/1.1\\u001b[0m\\\" 200 -\\n\"}]}]\n45:[\"$\",\"h1\",\"h1-2\",{\"id\":\"\",\"className\":\"text-3xl font-bold mt-8 mb-4\",\"children\":\"ì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\"}]\n46:[\"$\",\"p\",\"p-22\",{\"children\":[\"$\",\"img\",\"img-0\",{\"src\":\"https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png\",\"alt\":\"pair_classification\"}]}]\n47:[\"$\",\"$L51\",null,{}]\n53:T82c0,"])</script><script>self.__next_f.push([1,"\nì, ê·¸ëŸ¼ í•™ìŠµì„ ë§ˆì¹œ ëª¨ë¸ì„ ì–´ë–»ê²Œ ì‚¬ìš©í• ê¹Œ?\n\në³¸ íŒŒì¼ì€ ì´ê¸°ì°½ë‹˜ì˜ 'Do it! ìì—°ì–´ ì²˜ë¦¬'ì— ê¸°ì´ˆí•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ë¯¸ë¦¬ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤! :)\n\n# í•™ìŠµ ë§ˆì¹œ ëª¨ë¸ì„ ì‹¤ì „ íˆ¬ì…í•˜ê¸°\n\ní•™ìŠµì„ ë§ˆì¹œ ë¬¸ì¥ ìŒ ë¶„ë¥˜ ëª¨ë¸ì„ ì¸í¼ëŸ°ìŠ¤í•˜ëŠ” ê³¼ì •ì„ ì‹¤ìŠµí•´ë³¸ë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ë§Œë“œëŠ” ì›¹ ì„œë¹„ìŠ¤ì˜ ê°œë…ë„ëŠ” ì•„ë˜ ê·¸ë¦¼ 1ê³¼ ê°™ë‹¤.\n\n![pair_classification_map](https://user-images.githubusercontent.com/84653623/160080095-e1ad18ac-7b05-4b62-b7bb-42de6dfcd904.jpg)\n**ê·¸ë¦¼ 1.** ë¬¸ì¥ ìŒ ë¶„ë¥˜ ì›¹ ì„œë¹„ìŠ¤\n\nì „ì œì™€ ê°€ì„¤ ë¬¸ì¥ì„ ë°›ì•„ ë‹µë³€í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì´ë‹¤. ì „ì œì™€ ê°€ì„¤ ê°ê°ì„ í† í°í™”, ì¸ë±ì‹±í•œ ë’¤ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ëª¨ë¸ì— ë„£ì–´ \n\n**[ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì°¸ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ê±°ì§“ì¼ í™•ë¥ , ì „ì œì— ëŒ€í•´ ê°€ì„¤ì´ ì¤‘ë¦½ì¼ í™•ë¥ ]**\nì„ ê³„ì‚°í•œë‹¤.\n\nì´í›„ ì•½ê°„ì˜ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí•˜ëŠ” ë°©ì‹ì´ë‹¤.\n\n# ì „ì œì™€ ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°\n\n## 1. í™˜ê²½ ì„¤ì •í•˜ê¸°\n\n### ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜\n\npip ëª…ë ¹ì–´ë¥¼ í†µí•´ ì˜ì¡´ì„±ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\n#### code 4-0\n\n\n```python\n!pip install ratsnlp\n```\n\n    Requirement already satisfied: ratsnlp in /usr/local/lib/python3.7/dist-packages (1.0.1)\n    Requirement already satisfied: transformers==4.10.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (4.10.0)\n    Requirement already satisfied: Korpora\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.2.0)\n    Requirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n    Requirement already satisfied: flask-cors\u003e=3.0.10 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (3.0.10)\n    Requirement already satisfied: torch\u003e=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\n    Requirement already satisfied: flask-ngrok\u003e=0.0.25 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (0.0.25)\n    Requirement already satisfied: pytorch-lightning==1.3.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.3.4)\n    Requirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.18.2)\n    Requirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2.8.0)\n    Requirement already satisfied: fsspec[http]\u003e=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (2022.2.0)\n    Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (21.3)\n    Requirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.7.2)\n    Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (1.21.5)\n    Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (0.3.0)\n    Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (4.63.0)\n    Requirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-\u003eratsnlp) (5.4.1)\n    Requirement already satisfied: huggingface-hub\u003e=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.4.0)\n    Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.6.0)\n    Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (4.11.2)\n    Requirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.10.3)\n    Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.23.0)\n    Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2019.12.20)\n    Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-\u003eratsnlp) (0.0.47)\n    Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\n    Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\n    Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\n    Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\n    Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\n    Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.8.1)\n    Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0-\u003eratsnlp) (3.10.0.2)\n    Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: dataclasses\u003e=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (0.6)\n    Requirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (2.0.1)\n    Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.0.7)\n    Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\n    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\n    Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2021.10.8)\n    Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (3.0.4)\n    Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.6)\n    Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.6.1)\n    Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (57.4.0)\n    Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.44.0)\n    Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.35.0)\n    Requirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.17.3)\n    Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.0.0)\n    Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.8.1)\n    Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.3.6)\n    Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.37.1)\n    Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.8)\n    Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.2.8)\n    Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.2.4)\n    Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.1)\n    Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0-\u003eratsnlp) (3.7.0)\n    Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.4.8)\n    Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (3.2.0)\n    Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (21.4.0)\n    Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.3.0)\n    Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.7.2)\n    Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (2.0.12)\n    Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (1.2.0)\n    Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (4.0.2)\n    Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (6.0.2)\n    Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]\u003e=2021.4.0-\u003epytorch-lightning==1.3.4-\u003eratsnlp) (0.13.0)\n    Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.1.0)\n    \n\n### êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™\n\ní•™ìŠµí•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥í•´ ë‘ì—ˆìœ¼ë¯€ë¡œ, code 4-1ì„ ì‹¤í–‰í•˜ì—¬ ì½”ë© ë…¸íŠ¸ë¶ê³¼ ìì‹ ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì—°ë™í•œë‹¤.\n\n#### code 4-1\n\n\n```python\nfrom google.colab import drive\ndrive.mount('/gdrive', force_remount=True)\n```\n\n    Mounted at /gdrive\n    \n\n### ì¸í¼ëŸ°ìŠ¤ ì„¤ì •\n\nê°ì¢… ì¸í¼ëŸ°ìŠ¤ ì„¤ì •ì„ ìˆ˜í–‰í•œë‹¤. `pretrained_model_name`ê³¼ `max_seq_length`, `downstream_model_dir` ëª¨ë‘ ì• íŠ¸ë ˆì¸ì—ì„œ ì ìš©í•œ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì—¬ì•¼ í•œë‹¤.\n\n#### code 4-2\n\n\n```python\nfrom ratsnlp.nlpbook.classification import ClassificationDeployArguments\nargs = ClassificationDeployArguments(\n    pretrained_model_name=\"beomi/kcbert-base\",\n    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-paircls\",\n    max_seq_length=64,\n)\n```\n\n    downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-paircls/epoch=1-val_loss=0.82.ckpt\n    \n\n## 2. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n\n### í† í¬ë‚˜ì´ì € ë¡œë“œ\n\ncode 4-3ì„ ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ì´ˆê¸°í™”í•œë‹¤.\n\n#### code 4-3\n\n\n```python\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\n    args.pretrained_model_name,\n    do_lower_case=False,\n)\n```\n\n### ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n\ncode 4-4ëŠ” `pair_classification_train.ipynb`ì—ì„œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì½ì–´ ë“¤ì¸ë‹¤.\n\n#### code 4-4\n\n\n```python\nimport torch\nfine_tuned_model_ckpt = torch.load(\n    args.downstream_model_checkpoint_fpath,\n    map_location=torch.device(\"cpu\"),\n)\n```\n\n### BERT ì„¤ì • ë¡œë“œ ë° BERT ëª¨ë¸ ì´ˆê¸°í™”\n\ncode 4-5ëŠ” `pair_classification_train.ipynb`ì˜ íŒŒì¸íŠœë‹ ë•Œ ì‚¬ìš©í•œ `pretrained_model_name`ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ì„ ì½ì–´ë“¤ì´ë©°, code 4-6ì„ ì‹¤í–‰í•˜ë©´ í•´ë‹¹ ê°’ëŒ€ë¡œ BERT ëª¨ë¸ì„ ì´ˆê¸°í™” í•œë‹¤.\n\n#### code 4-5\n\n\n```python\nfrom transformers import BertConfig\npretrained_model_config = BertConfig.from_pretrained(\n    args.pretrained_model_name,\n    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n)\n```\n\n#### code 4-6\n\n\n```python\nfrom transformers import BertForSequenceClassification\nmodel = BertForSequenceClassification(pretrained_model_config)\n```\n\n### ì²´í¬í¬ì¸íŠ¸ ì£¼ì…í•˜ê¸°\n\ncode 4-7ì€ ì´ˆê¸°í™”í•œ **BERT**ëª¨ë¸ì— code 4-4ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì£¼ì…í•œë‹¤\n\n#### code 4-7\n\n\n```python\nmodel.load_state_dict({k.replace(\"model.\",\"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n```\n\n\n\n\n    \u003cAll keys matched successfully\u003e\n\n\n\n### í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n\nì´ì–´ì„œ code 4-8ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ê²Œ ëœë‹¤. **ë“œë¡­ì•„ì›ƒ ë“± í•™ìŠµ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤ì„ ë¬´íš¨í™”í•˜ëŠ” ì—­í• **ì„ í•œë‹¤.\n\n#### code 4-8\n\n\n```python\nmodel.eval()\n```\n\n\n\n\n    BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30000, 768, padding_idx=0)\n          (position_embeddings): Embedding(300, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (1): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (2): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (3): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (4): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (5): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (6): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (7): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (8): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (9): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (10): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (11): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): Linear(in_features=768, out_features=3, bias=True)\n    )\n\n\n\n## 3. ëª¨ë¸ ì¶œë ¥ê°’ ë§Œë“¤ê³  í›„ì²˜ë¦¬ í•˜ê¸°\n\ncode 4-9ëŠ” **ì¸í¼ëŸ°ìŠ¤ ê³¼ì •ì„ ì •ì˜í•œ í•¨ìˆ˜**ì´ë‹¤. ì „ì œ(premise)ì™€ ê°€ì„¤(hypothesis)ì„ ì…ë ¥ë°›ì•„ ê°ê° í† í°í™”, ì¸ë±ì‹±ì„ ìˆ˜í–‰í•œ ë’¤ `input_ids`, `attention_mask`, `token_type_ids`ë¥¼ ë§Œë“ ë‹¤. ì´ë“¤ ì••ë ¥ê°’ì„ íŒŒì´í† ì¹˜ í…ì„œ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜í•œ ë’¤ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.\n\n### ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜\n\n#### code 4-9\n\n\n```python\ndef inference_fn(premise, hypothesis):\n  # ì „ì œì™€ ê°€ì„¤ì„ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ë§Œë“¤ê¸°\n  inputs = tokenizer(\n      [(premise, hypothesis)],\n      max_length=args.max_seq_length,\n      padding=\"max_length\",\n      truncation=True,\n  )\n  with torch.no_grad():\n    # ëª¨ë¸ ê³„ì‚°í•˜ê¸°\n    outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})  # {}ì•ˆ = inputsë¥¼ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë°”ê¾¸ê¸°\n\n    # ë¡œì§“ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ ì·¨í•˜ê¸°\n    prob = outputs.logits.softmax(dim=1)\n\n    # í™•ë¥ ì„ ì†Œìˆ˜ì  ë‘ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼\n    entailment_prob = round(prob[0][0].item(), 2)\n    contradiction_prob = round(prob[0][1].item(), 2)\n    neutral_prob = round(prob[0][2].item(), 2)\n\n    # ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ ìœ„ì¹˜ì— ë”°ë¼ pred ë§Œë“¤ê¸°\n    if torch.argmax(prob) == 0:\n      pred = \"ì°¸ (entailment)\"\n    elif torch.argmax(prob) == 1:\n      pred = \"ê±°ì§“ (contradiction)\"\n    else:\n      pred = \"ì¤‘ë¦½ (neutral)\"\n  \n  return {\n      'premise': premise,\n      'hypothesis': hypothesis,\n      'prediction': pred,\n      'entailment_data': f\"ì°¸ {entailment_prob}\",\n      'contradiction_data': f\"ê±°ì§“ {contradiction_prob}\",\n      'neutral_data': f\"ì¤‘ë¦½ {neutral_prob}\",\n      'entailment_width': f\"{entailment_prob * 100}%\",\n      'contradiction_width': f\"{contradiction_prob * 100}%\",\n      'neutral_width': f\"{neutral_prob * 100}%\"\n  }\n```\n\n**ëª¨ë¸ ì¶œë ¥ê°’(`output.logits`)**ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ì´ì „ì˜ ë¡œì§“ í˜•íƒœì´ë‹¤. ì—¬ê¸°ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì¨ì„œ ëª¨ë¸ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë°”ê¾¼ë‹¤. ê·¸ë¦¬ê³  ì•½ê°„ í›„ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ“ê°’ì´ ì°¸ ìœ„ì¹˜(0)ì¼ ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì´ '**ì°¸ (entailment)**', ê±°ì§“ ìœ„ì¹˜(1)ì¼ ê²½ìš° '**ê±°ì§“ (contradiction)**', ì¤‘ë¦½ ìœ„ì¹˜(2)ì¼ ê²½ìš° '**ì¤‘ë¦½ (neutral)**'ì´ ë˜ë„ë¡ pred ê°’ì„ ë§Œë“ ë‹¤.\n\ncode 4-9ì—ì„œ `entailment_width`, `contradiction_width`, `neutral_width`ëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì°¸, ê±°ì§“, ì¤‘ë¦½ ë§‰ëŒ€ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ í¬ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šì•„ë„ ëœë‹¤.\n\n## 4. ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\n\n### ì›¹ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸° ì¤€ë¹„\n\n`ngrok`ì€ ì½”ë© ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•´ì£¼ëŠ” ë„êµ¬ì´ë‹¤. `ngrok`ì„ ì‹¤í–‰í•˜ë ¤ë©´ [íšŒì›ê°€ì…](https://dashboard.ngrok.com/get-started/setup) í›„ [ë¡œê·¸ì¸](https://dashboard.ngrok.com/get-started/setup)ì„ í•œ ë’¤ [ì´ê³³](https://dashboard.ngrok.com/get-started/your-authtoken)ì— ì ‘ì†í•´ ì¸ì¦í† í°(authtoken)ì„ í™•ì¸í•´ì•¼ í•œë‹¤. \n\nì˜ˆë¥¼ ë“¤ì–´ í™•ì¸ëœ `authtoken`ì´ `test123`ì´ë¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰ ëœë‹¤.\n\n** !mkdir /root/.ngrok2 \u0026\u0026 echo \"authtoken: test123\" \u003e /root/.ngrok2/ngrok.yml**\n\n#### code 4-10\n\n\n```python\n!mkdir /root/.ngrok2 \u0026\u0026 echo \"authtoken: (ì—¬ê¸° ì±„ìš°ì„¸ìš”)\" \u003e /root/.ngrok2/ngrok.yml\n```\n\n    mkdir: cannot create directory â€˜/root/.ngrok2â€™: File exists\n    \n\n### ì›¹ ì„œë¹„ìŠ¤ ì‹œì‘í•˜ê¸°\n\ncode 4-9ì—ì„œ ì •ì˜í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜ `inference_fn`ì„ ê°€ì§€ê³  code 4-11ì„ ì‹¤í–‰í•˜ë©´ ì›¹ ì„œë¹„ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤. íŒŒì´ì¬ì˜ í”Œë¼ìŠ¤í¬ë¥¼ í™œìš©í•œ ì•±ì´ë‹¤.\n\n#### code 4-11\n\n\n```python\nfrom ratsnlp.nlpbook.paircls import get_web_service_app\napp = get_web_service_app(inference_fn)\napp.run()\n```\n\n     * Serving Flask app \"ratsnlp.nlpbook.paircls.deploy\" (lazy loading)\n     * Environment: production\n    \u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n    \u001b[2m   Use a production WSGI server instead.\u001b[0m\n     * Debug mode: off\n    \n\n     * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n    \n\n     * Running on http://0163-35-238-180-140.ngrok.io\n     * Traffic stats available on http://127.0.0.1:4040\n    \n\n    127.0.0.1 - - [04/Mar/2022 09:14:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n    127.0.0.1 - - [04/Mar/2022 09:14:49] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n    127.0.0.1 - - [04/Mar/2022 09:14:49] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n    127.0.0.1 - - [04/Mar/2022 09:15:01] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n    \n\n# ì›¹ì‚¬ì´íŠ¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n![pair_classification](https://user-images.githubusercontent.com/84653623/160079951-83a22799-e4d8-4254-845b-61b55a1ec40d.png)\n"])</script><script>self.__next_f.push([1,"48:[\"$\",\"$L52\",null,{\"content\":\"$53\"}]\n"])</script><script>self.__next_f.push([1,"4a:[\"$\",\"span\",\"span-44\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"ì¤‘ë¦½ \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":\"{neutral_prob}\"}],\"\\\"\"]}]\n4b:[\"$\",\"span\",\"span-45\",{\"className\":\"hljs-string\",\"children\":\"'entailment_width'\"}]\n4c:[\"$\",\"span\",\"span-46\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":[\"{entailment_prob * \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"100\"}],\"}\"]}],\"%\\\"\"]}]\n4d:[\"$\",\"span\",\"span-47\",{\"className\":\"hljs-string\",\"children\":\"'contradiction_width'\"}]\n4e:[\"$\",\"span\",\"span-48\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":[\"{contradiction_prob * \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"100\"}],\"}\"]}],\"%\\\"\"]}]\n4f:[\"$\",\"span\",\"span-49\",{\"className\":\"hljs-string\",\"children\":\"'neutral_width'\"}]\n50:[\"$\",\"span\",\"span-50\",{\"className\":\"hljs-string\",\"children\":[\"f\\\"\",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-subst\",\"children\":[\"{neutral_prob * \",[\"$\",\"span\",\"span-0\",{\"className\":\"hljs-number\",\"children\":\"100\"}],\"}\"]}],\"%\\\"\"]}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"title\",\"0\",{\"children\":\"Sehoon's Workspace\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Welcome to my page!\"}]]\n7:null\n"])</script></body></html>
---
title:  "[ML Study] 머신러닝 첫걸음: Classification 모델 완전정복 (1)"
excerpt: ""
categories:
  - AI, DL, ML
tags:
  - AI, DL, ML
toc: true
toc_sticky: true
use_math: true
date: 2025-09-30
last_modified_at: 2025-09-30
---
<!--
⚠️ Math Rendering Rules ⚠️
1. Do NOT wrap math expressions in backticks (` `).
   - INCORRECT: `$x + y$`
   - CORRECT: $x + y$
2. Do NOT wrap math delimiters (`$`) in bold (`**`) or italics (`*`).
   - INCORRECT: **$x$**
   - CORRECT: $x$ or $\mathbf{x}$
3. Format exponents using math mode (e.g., for 2 to the power of n).
   - INCORRECT: 2^n
   - CORRECT: $2^n$
4. Use $ for inline math and $$ for block math.
-->


## Introduction

컴퓨터가 주어진 사진을 보고 고양이와 강아지를 구별해내는 것을 상상해 보세요. 우리에게는 너무나 직관적인 일이지만, 기계에게는 복잡한 학습 과정이 필요합니다. 이렇게 데이터를 특정 카테고리로 나누는 작업을 '분류(Classification)'라고 부르며, 이는 현대 인공지능의 가장 기본적이면서도 핵심적인 능력 중 하나입니다.

이 글은 한국기초과학지원연구원(KBSI)의 AI/ML 스터디 자료를 바탕으로, 인공지능과 머신러닝의 기본 개념부터 시작하여, 실제로 분류 모델을 어떻게 훈련하고 그 성능을 정교하게 평가하는지 단계별로 안내합니다. 머신러닝을 처음 접하는 입문자부터 개념을 다시 정리하고 싶은 실무자까지, 모두에게 유용한 가이드가 될 것입니다.

본문에서는 다음과 같은 주제들을 순서대로 다룰 예정입니다.

1. AI, 머신러닝, 딥러닝의 관계
2. 첫 번째 과제: MNIST 손 글씨 숫자 분류
3. 이진 분류기 훈련 방법
4. 모델 성능 측정의 모든 것


## 1. AI, 머신러닝(Machine Learning) & 딥러닝(Deep Learning)의 세계

인공지능 시대를 살아가면서 AI, 머신러닝, 딥러닝이라는 용어를 자주 접하게 됩니다. 이들은 단순한 유행어가 아니라, 명확한 범위와 관계를 가진 기술 분야입니다. 성공적인 머신러닝 모델을 구축하기 위해서는 이들의 관계를 정확히 이해하는 것이 첫걸음입니다.

### 개념의 계층 구조

AI, 머신러닝, 딥러닝은 포함 관계를 가집니다. 가장 넓은 개념은 **인공지능(AI)**이며, **머신러닝(ML)**은 그 핵심적인 하위 분야입니다. 그리고 **딥러닝(DL)**은 머신러닝의 여러 기법 중 하나로, 더욱 전문화된 영역입니다.

* 인공지능 (Artificial Intelligence, AI): 인간의 지능을 모방하여, 사람이 수행하는 일을 컴퓨터가 할 수 있도록 구현하는 가장 포괄적인 기술입니다.
* 머신러닝 (Machine Learning, ML): AI를 구현하는 대표적인 방법론입니다. 기계가 데이터로부터 스스로 학습하여 특정 작업을 수행하는 기술을 의미합니다. 대표적인 알고리즘으로는 인공 신경망, 서포트 벡터 머신(SVM), 결정 트리 등이 있습니다.
* 딥러닝 (Deep Learning, DL): 머신러닝의 한 분야로, 인공 신경망을 깊게(여러 층으로) 쌓아올려 복잡한 패턴을 학습하는 기술입니다. CNN, RNN, RBM 등이 여기에 속합니다.


### 머신러닝(ML)과 딥러닝(DL)의 결정적 차이

가장 큰 차이점은 '특성 추출(Feature Extraction)' 과정에 있습니다.

* 머신러닝(ML): 사람이 직접 데이터의 중요한 특징(예: 자동차의 바퀴, 핸들)을 추출하여 모델에 입력해야 합니다. 이 과정에서 사람의 전문 지식과 개입이 중요합니다.
* 딥러닝(DL): 모델이 데이터로부터 직접 주요 특징을 학습하고 분류까지 자동으로 수행합니다. 사람의 개입을 최소화하고 데이터 자체의 패턴을 깊이 있게 파악합니다.


두 기술의 차이점을 표로 정리하면 다음과 같습니다.
![ML_versus_DL](/assets/images/2025-09-30-ML_Classification/image.png)


### Total process of Machine Learning

머신러닝 프로젝트는 크게 두 단계로 나뉩니다.

1. 학습 단계 (Training Phase): 정답이 있는 데이터(Label)를 사용하여 모델을 훈련시킵니다. 데이터에서 특징을 추출하고, 머신러닝 알고리즘을 적용하여 분류 또는 예측 모델을 생성합니다. 이 모델은 반복적인 학습을 통해 점차 정교해집니다.
2. 예측 단계 (Prediction Phase): 학습이 완료된 모델에 새로운 데이터를 입력합니다. 모델은 학습된 패턴을 기반으로 이 새로운 데이터에 대한 결과를 예측합니다.


### 머신러닝의 3가지 유형

머신러닝은 학습 방식에 따라 크게 세 가지로 분류됩니다.

* 지도 학습 (Supervised Learning): 정답(레이블)이 있는 데이터를 사용하여 모델을 학습시킵니다. 스팸 메일 분류처럼, 각 데이터가 어떤 범주에 속하는지 명확히 알려주고 패턴을 배우게 하는 방식입니다.
* 비지도 학습 (Unsupervised Learning): 정답이 없는 데이터를 사용합니다. 데이터 내에 숨겨진 구조나 패턴, 그룹을 스스로 찾아내도록 합니다. 예를 들어, 사용자들을 비슷한 성향의 그룹으로 묶는 군집화(Clustering)가 있습니다.
* 강화 학습 (Reinforcement Learning): 에이전트(Agent)가 특정 환경 내에서 행동하고, 그 결과로 얻는 보상(Reward)과 벌점(Penalty)을 통해 최적의 행동 정책을 학습하는 방식입니다.

이제 이러한 기본 지식을 바탕으로, 실제 데이터를 다루며 개념을 구체화해 보겠습니다.


## 2. 첫 번째 과제: MNIST 손 글씨 숫자 분류

머신러닝 분야에는 모델의 성능을 시험하고 비교하기 위한 표준 데이터셋들이 존재합니다. 그중 MNIST 데이터셋은 이미지 분류를 처음 시작하는 모든 이들이 거쳐 가는 'Hello, World!'와 같은 존재입니다.

### MNIST 데이터셋이란?

MNIST는 0부터 9까지의 손으로 쓴 숫자 이미지 70,000개로 구성된 대규모 데이터베이스입니다. 이 데이터셋의 구조는 다음과 같습니다.

* 총 데이터 수: 70,000개의 이미지
* 이미지 크기: 각 이미지는 28x28 픽셀의 흑백 이미지입니다.
* 특성 (Features): 각 이미지는 28 * 28 = 784개의 픽셀로 이루어져 있으며, 각 픽셀의 밝기(강도) 값이 하나의 특성이 됩니다.

따라서 데이터는 (70000, 784) 형태의 배열로 표현되며, 이는 70,000개의 샘플 각각이 784개의 특성을 가지고 있음을 의미합니다. 각 샘플에 해당하는 실제 숫자 값(레이블)은 (70000,) 형태의 배열에 저장됩니다.

# 데이터의 형태 확인
X.shape, y.shape
# 출력: (70000, 784), (70000,)


이제 데이터가 준비되었으니, "주어진 이미지가 특정 숫자인지 아닌지"와 같은 간단한 분류 문제를 어떻게 해결할 수 있을지 알아보겠습니다.


--------------------------------------------------------------------------------


## 3. 이진 분류기 (Binary Classifier) 훈련하기

**이진 분류기(Binary Classifier)**는 가장 단순하면서도 강력한 분류 모델 중 하나입니다. 이름 그대로, 데이터를 '예' 또는 '아니오'의 두 가지 범주 중 하나로 분류하는 역할을 합니다.

개념을 현실로: '5-탐지기' 만들기

MNIST 데이터셋을 활용하여 이 개념을 구체화해 봅시다. 0부터 9까지 모든 숫자를 한 번에 구별하는 것은 다소 복잡할 수 있으니, 문제를 단순화하여 "이 이미지는 숫자 5인가, 아닌가?"를 판별하는 '5-탐지기' 모델을 만들어 보겠습니다.

이 모델의 임무는 명확합니다.

* '5' (Positive): 이미지가 숫자 5일 경우
* '5 아님' (Negative): 이미지가 5가 아닌 다른 숫자일 경우

이렇게 10개의 클래스(0~9)를 분류하는 다중 클래스 문제를 두 개의 클래스('5' vs 'not-5')로 분류하는 이진 분류 문제로 바꾸어 접근하면, 모델 훈련과 평가의 핵심 원리를 더 쉽게 이해할 수 있습니다.

모델 훈련이 끝났다면, 가장 중요한 단계가 남아있습니다. 바로 이 모델이 얼마나 잘 작동하는지 엄격하게 평가하는 것입니다.


--------------------------------------------------------------------------------


## 4. 모델 성능, 어떻게 측정할까? (Performance Measures)

모델을 만드는 것만큼이나 중요한 것은 그 모델의 성능을 객관적으로 측정하는 것입니다. 모델은 그것을 측정하는 지표만큼만 가치가 있으며, 단 하나의 숫자만 보고 성능을 판단하는 것은 매우 위험할 수 있습니다. 이 섹션에서는 모델 성능을 정확하게 측정하는 데 필수적인 도구들을 살펴보겠습니다.

1. 교차 검증 (Cross-Validation)

데이터를 훈련(train) 세트와 테스트(test) 세트로 단 한 번만 나누어 평가하면, 그 결과가 우연히 좋거나 나쁜 데이터 분할에 의해 좌우될 수 있습니다. 이러한 문제를 해결하기 위한 기법이 바로 교차 검증입니다.

가장 널리 쓰이는 **k-겹 교차 검증 (k-fold cross-validation)**은 다음과 같이 동작합니다.

1. 훈련 데이터를 k개의 동일한 부분(fold)으로 나눕니다.
2. 첫 번째 fold를 검증(validation) 세트로 사용하고, 나머지 k-1개 fold로 모델을 훈련시킵니다.
3. 두 번째 fold를 검증 세트로 사용하는 등, k번의 훈련과 검증을 반복합니다.
4. 최종 성능은 k번의 검증 결과의 평균으로 계산하여, 훨씬 안정적이고 신뢰도 높은 평가를 제공합니다.



2. 오차 행렬 (Confusion Matrix)

오차 행렬은 분류 모델의 성능을 상세하게 분석하는 가장 기본적인 도구입니다. 모델의 예측 값이 실제 값과 얼마나 일치하는지를 표 형태로 보여주어, 모델이 어떤 종류의 실수를 저지르는지 명확히 파악할 수 있게 합니다.

'5-탐지기' 예시를 바탕으로 오차 행렬의 네 가지 핵심 요소를 정의하면 다음과 같습니다.

* True Positive (TP): 실제 '5'를 '5'라고 올바르게 예측한 경우.
* True Negative (TN): 실제 '5 아님'을 '5 아님'이라고 올바르게 예측한 경우.
* False Positive (FP): 실제 '5 아님'을 '5'라고 잘못 예측한 경우.
* False Negative (FN): 실제 '5'를 '5 아님'이라고 잘못 예측한 경우.



3. 핵심 성능 지표

오차 행렬을 기반으로 다양한 성능 지표를 계산할 수 있습니다. 각 지표는 서로 다른 관점에서 모델을 평가합니다.

* 정확도 (Accuracy)
  * 공식: (TP + TN) / (TP + TN + FP + FN)
  * 의미: "전체 예측 중 얼마나 정확하게 맞혔는가?"
  * 가장 직관적인 지표지만, 데이터가 불균형할 경우(예: 1000개의 이메일 중 스팸이 10개뿐인 경우, 모든 메일을 '정상'으로 예측해도 정확도가 99%에 달함) 성능을 왜곡할 수 있습니다.
* 정밀도 (Precision)
  * 공식: TP / (TP + FP)
  * 의미: "모델이 'Positive'라고 예측한 것들 중, 실제 'Positive'인 비율은 얼마인가?"
  * Positive 예측의 신뢰도를 나타냅니다. 정밀도가 높을수록 모델의 Positive 판정은 믿을 만합니다.
* 재현율 (Recall / Sensitivity / TPR)
  * 공식: TP / (TP + FN)
  * 의미: "실제 모든 'Positive' 중에서, 모델이 얼마나 많이 찾아냈는가?"
  * 모델이 실제 Positive 샘플을 놓치지 않는 능력을 측정합니다.
* F1-Score
  * 공식: 2 * (정밀도 * 재현율) / (정밀도 + 재현율)
  * 의미: 정밀도와 재현율의 조화 평균.
  * 두 지표를 모두 고려하여 균형 잡힌 성능을 평가할 때 사용됩니다. 정밀도와 재현율이 모두 높을 때 F1-Score도 높아집니다.

4. 정밀도와 재현율의 트레이드오프 (Tradeoff)

정밀도와 재현율은 일반적으로 반비례 관계에 있습니다. 즉, 하나를 높이면 다른 하나가 낮아지는 경향이 있습니다. 이 관계는 **결정 임계값(Decision Threshold)**에 의해 조절됩니다.

* 임계값을 낮추면: 모델이 더 많은 샘플을 Positive로 분류하게 되어, 재현율은 올라가지만(더 많은 실제 Positive를 찾음) 정밀도는 떨어집니다(잘못된 Positive 예측 증가).
* 임계값을 높이면: 모델이 더 엄격하게 Positive를 판정하게 되어, 정밀도는 올라가지만 재현율은 떨어집니다(까다로운 기준으로 인해 실제 Positive를 놓칠 수 있음).

이 트레이드오프는 문제의 성격에 따라 중요도가 달라집니다. 예를 들어, 암 진단 모델에서는 실제 암 환자를 놓치는 경우(FN)가 거짓 양성 판정(FP)보다 훨씬 치명적이므로, 재현율을 최대한 높이는 것이 중요합니다.



## 5. ROC 곡선과 AUC

ROC(Receiver Operating Characteristic) 곡선은 이진 분류 모델의 성능을 시각적으로 평가하는 중요한 도구입니다.

ROC 곡선의 축은 다음과 같이 구성됩니다. Y축은 **진양성 비율(True Positive Rate, TPR)**로, 우리가 이미 살펴본 **재현율(Recall)**과 동일한 지표입니다. X축은 **위양성 비율(False Positive Rate, FPR)**입니다.

* Y축: 진양성 비율 (True Positive Rate, TPR) - 실제 Positive 중 Positive로 올바르게 예측한 비율. 공식은 TP / (TP + FN) 입니다.
* X축: 위양성 비율 (False Positive Rate, FPR) - 실제 Negative 중 Positive로 잘못 예측한 비율. 공식은 FPR = FP / (FP + TN) 입니다.

곡선 해석:

* 곡선이 좌측 상단에 가까울수록 모델의 성능이 우수함을 의미합니다.
* 대각선 점선은 무작위로 추측하는 분류기(성능이 없는 모델)를 나타냅니다.



**AUC (Area Under the Curve)**는 ROC 곡선 아래의 면적을 나타내는 값으로, 0과 1 사이의 값을 가집니다. AUC는 모델의 전반적인 성능을 단일 숫자로 요약해 줍니다.

* AUC = 1.0: 완벽한 분류기
* AUC = 0.5: 무작위 분류기와 동일한 성능

올바른 성능 지표를 선택하는 것은 기술적인 절차를 넘어, 해결하고자 하는 문제의 목표와 직결된 전략적인 결정입니다.


--------------------------------------------------------------------------------


## 맺음말: 분류를 넘어 다음 단계로

지금까지 우리는 인공지능, 머신러닝, 딥러닝의 기본 개념을 정립하고, MNIST 데이터셋을 통해 이진 분류 모델을 훈련하는 과정을 살펴보았습니다. 더 나아가, 단순 정확도를 넘어 정밀도, 재현율, F1-Score, ROC/AUC와 같은 정교한 지표들을 통해 모델의 성능을 다각적으로 평가하는 방법까지 학습했습니다.

효과적인 머신러닝은 단순히 모델을 구축하는 것에서 끝나지 않습니다. 실제 문제의 맥락 속에서 모델의 성능을 올바르게 측정하고 해석하는 능력이 무엇보다 중요합니다. 오늘 배운 개념들을 바탕으로 직접 데이터를 다루며 실험해 보시길 바랍니다.

다음 "분류 (2)" 포스트에서는 여러 클래스를 동시에 분류하는 다중 클래스 분류와 더 다양한 알고리즘에 대해 알아보겠습니다.


---
긴 글 읽어주셔서 감사합니다! 

저에게 연락을 주고 싶으신 것이 있으시다면 
- LinkedIn : www.linkedin.com/in/sehoon-park-575b8b22a
- Github : https://github.com/sehooni
- Email : 74sehoon@gmail.com
- 블로그 댓글
으로 연락 주시면 감사하겠습니다.